#format:table
#title:AWS SAP
#question_count:5
#shuffle_questions:true
#shuffle_choices:true
Test4-01. <p id="yui_3_17_2_1_1533874312776_759">As a solution architect professional, you have been requested to launch 20 Large EC2 instances which will all be used to process huge amounts of data. There is also a requirement that these instances will need to transfer data back and forth among each other. Which of the following would be the most efficient setup to achieve this? <br></p><p>Choose the correct option from the below:</p> | <p id = "yui_3_17_2_1_1533874312776_759">ソリューションアーキテクトのプロフェッショナルとして、大量のデータを処理するために使用される20個のLarge EC2インスタンスを起動するように要求されました。また、これらのインスタンスが相互にデータをやりとりする必要があるという要件もあります。これを達成するための最も効率的なセットアップは次のどれですか？<br> </p> <p>以下から正しいオプションを選択してください：</p>	sa:	Use Placement Groups and ensure that all instances are launched at the same time. <br>  プレースメントグループを使用して、すべてのインスタンスが同時に起動されていることを確認します。|<p><br></p><p>Option A is incorrect because being in the same region would not mean that the data transfer between the instances would be any faster. In fact, the instances would experience network latency.</p><p>Option B is incorrect because just being in the same AZ is not sufficient; they should be added to a Placement Group to benefit from the low network latency.</p><p>Option C is CORRECT because Placement Group enables applications to get the low-latency network performance necessary for tightly-coupled node-to-node communication typical of many high-performance computing applications.&nbsp;</p><p>Option D is incorrect because despite being of largest size, the EC2 instances would still experience network latency if they are not part of a Placement Group.</p><p><br></p><p><b>More information on Placement Groups:</b></p><p>A&nbsp;<em>placement group</em>&nbsp;is a logical grouping of instances within a single Availability Zone. Placement groups are recommended for applications that benefit from low network latency, high network throughput, or both. To provide the lowest latency, and the highest packet-per-second network performance for your placement group, choose an instance type that supports enhanced networking</p><p><br></p><p>For more information on Placement Groups, please visit the URL:</p><p></p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html</a><br><br><p></p>	Ensure that all instances are placed in the same availability zone. <br>  すべてのインスタンスが同じ可用性ゾーンに配置されていることを確認します。	Ensure that all the instances are placed in the same region. <br>  すべてのインスタンスが同じリージョンに配置されていることを確認します。	Use the largest EC2 instances currently available on AWS and make sure they are spread across multiple availability zones. <br>  AWSで現在利用可能な最大のEC2インスタンスを使用し、それらが複数の可用性ゾーンに分散していることを確認します。
Test4-02. <p>Due to a lot of your EC2 services going offline at least once a week for no apparent reason your security officer has told you that you need to tighten up the logging of all events that occur on your AWS account. He wants to be able to access all events that occur on the account across all regions quickly and in the simplest way possible. He also wants to make sure he is the only person that has access to these events in the most secure way possible. Which of the following would be the best solution to assure his requirements are met?&nbsp; <br></p><p>Choose the correct answer from the below options:<br></p> | <p>多くのEC2サービスが少なくとも週に一度はオフラインになっているため、セキュリティ担当者からAWSアカウントで発生したすべてのイベントのログを強化する必要があることが示されています。彼はすべての地域のアカウントで発生したすべてのイベントに、簡単かつ迅速にアクセスできるようにしたいと考えています。彼はまた、可能な限り安全な方法でこれらのイベントにアクセスできる唯一の人物であることを確認したいと考えています。彼の要件が満たされていることを保証する最も良い解決策はどれでしょうか？＆nbsp; <br> </p> <p>以下のオプションから正解を選択します：<br> </p>	sa:	Use CloudTrail to log all events to one S3 bucket. Make this S3 bucket only accessible by your security officer with a bucket policy that restricts access to his user only and also add MFA to the policy for a further level of security. <br>  CloudTrailを使用して、すべてのイベントを1つのS3バケットに記録します。このS3バケットは、セキュリティ管理者がアクセスできるのはバケットポリシーだけで、彼のユーザへのアクセスを制限し、セキュリティレベルをさらに高めるためにポリシーに追加します。|<p><br></p><p></p><p>The main points to consider in this scenario are: (1)&nbsp; the security officer needs to access all events that occur on the account&nbsp;<b>across all the regions</b>, and (2) only that security officer should have the access.</p><p>&nbsp;</p><p>Option A is CORRECT because it configures only one S3 bucket for all the CloudTrail log events on the account across all the regions. It also restricts the access to the security officer only via the bucket policy. See the images below:</p><p><img src="https://s3.amazonaws.com/awssap/4_2_1.png" alt="" width="857" height="214" role="presentation" class="img-responsive atto_image_button_text-bottom"><br><!--[endif]--></p><p><img src="https://s3.amazonaws.com/awssap/4_2_2.png" alt="" width="969" height="276" role="presentation" class="img-responsive atto_image_button_text-bottom"><br><!--[endif]--></p><p>Option B is incorrect because it uses Amazon Glacier vaults which is an archival solution and not used for storing the CloudTrail logs .</p><p>Option C is incorrect because sending the API calls to CloudWatch is unnecessary. Also notifying the security officer via email is not a good nor a secure architecture.</p><p>Option D is incorrect because CloudTrail provides with an option where are all the logs get delivered to a single S3 bucket. Putting all the logs in separate buckets is an overhead .</p><p>&nbsp;</p><p><b>More information on AWS CloudTrail</b></p><p>AWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account. With CloudTrail, you can log, continuously monitor, and retain events related to API calls across your AWS infrastructure. CloudTrail provides a history of AWS API calls for your account, including API calls made through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. This history simplifies security analysis, resource change tracking, and troubleshooting.</p><p>You can design CloudTrail to send all logs to a central S3 bucket.</p><p>For more information on CloudTrail, please visit the below URL</p>  <a href="https://aws.amazon.com/cloudtrail/" target="_blank">https://aws.amazon.com/cloudtrail/</a><br><p></p><p><br></p><ul></ul><p></p>	Use CloudTrail to log all events to an Amazon Glacier Vault. Make sure the vault access policy only grants access to the security officer's IP address. <br>  CloudTrailを使用して、すべてのイベントをAmazon Glacier Vaultに記録します。ボールトアクセスポリシーでは、セキュリティ担当者のIPアドレスへのアクセスのみが許可されていることを確認してください。	Use CloudTrail to send all API calls to CloudWatch and send an email to the security officer every time an API call is made. Make sure the emails are encrypted. <br>  CloudTrailを使用してCloudWatchにすべてのAPI呼び出しを送信し、API呼び出しが行われるたびにセキュリティ担当者に電子メールを送信します。電子メールが暗号化されていることを確認してください。	Use CloudTrail to log all events to a separate S3 bucket in each region as CloudTrail cannot write to a bucket in a different region. Use MFA and bucket policies on all the different buckets. <br>  CloudTrailを使用すると、CloudTrailが別の地域のバケットに書き込むことができないため、すべてのイベントを各地域の別々のS3バケットに記録できます。すべての異なるバケットでMFAとバケットポリシーを使用します。
Test4-03. <p>An auditor needs read-only access to all AWS resources and logs of all the events that have occurred on AWS. What is the best way for creating this sort of access? <br></p><p>Choose the correct answer from the options below:<br></p> | <p>監査人は、AWSで発生したすべてのイベントのログとすべてのAWSリソースへの読み取り専用アクセス権が必要です。この種のアクセスを作成する最良の方法は何ですか？<br> </p> <p>以下のオプションから正解を選択します：<br> </p>	sa:	Enable CloudTrail logging and create an IAM user who has read-only permissions to the required AWS resources, including the bucket containing the CloudTrail logs. <br>  CloudTrailログを有効にし、CloudTrailログを含むバケットを含む、必要なAWSリソースへの読み取り専用アクセス権を持つIAMユーザーを作成します。|<p>&nbsp;</p><p>Option A is incorrect because just creating a role in not sufficient. CloudTrail logging needs to be enabled as well.</p><p>Option B is incorrect because sending the logs via email is not a good architecture.</p><p>Option C is incorrect because granting the auditor access to AWS resources is not AWS's responsibility. It is the AWS user or account owner's responsibility.</p><p>Option D is CORRECT because you need to enable the CloudTrail logging in order to generate the logs with information about all the activities related to the AWS account and resources. It also creates an IAM user that has permissions to read the logs that are stored in the S3 bucket.</p><p>&nbsp;</p><p><b>More information on AWS CloudTrail</b></p><p>AWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account. With CloudTrail, you can log, continuously monitor, and retain events related to API calls across your AWS infrastructure. CloudTrail provides a history of AWS API calls for your account, including API calls made through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. This history simplifies security analysis, resource change tracking, and troubleshooting.</p><p>For more information on CloudTrail, please visit the below URL:</p><p></p><p></p><a href="https://aws.amazon.com/cloudtrail/" target="_blank" style="font-size: 1rem;">https://aws.amazon.com/cloudtrail/</a><br><br><p></p>	Create an SNS notification that sends the CloudTrail log files to the auditor's email when CloudTrail delivers the logs to S3, but do not allow the auditor access to the AWS environment. <br>  CloudTrailがS3にログを配信するが、監査人がAWS環境にアクセスすることを許可していないときに、CloudTrailログファイルを監査人の電子メールに送信するSNS通知を作成する。	The company should contact AWS as part of the shared responsibility model, and AWS will grant required access to the third-party auditor. <br>  会社は共有責任モデルの一環としてAWSに連絡し、AWSは第三者監査人に必要なアクセス権を付与します。	Create a role that has the required permissions for the auditor. <br>  監査人に必要な権限を持つ役割を作成します。
Test4-04. <p>An online gaming server in which you have recently increased it's IOPS performance, by creating a RAID 0 configuration has now started to have bottleneck problems due to your instance bandwidth. Which of the following would be the best solution for this to increase throughput? <br></p><p>Choose the correct answer from the below options:<br></p> | <p> RAID 0構成を作成して、インスタンス帯域幅のためにボトルネックの問題が発生し始めた最近のIOPSパフォーマンスを向上させたオンラインゲームサーバー。次のうち、スループットを向上させるための最良のソリューションはどれですか？<br> </p> <p>以下のオプションから正解を選択します：<br> </p>	sa:	Use Single Root I/O Virtualization (SR-IOV) on all the instances. <br>  すべてのインスタンスで単一ルートI / O仮想化（SR-IOV）を使用します。|<p><span style="font-size: 1rem;"><br></span></p><p>Option A is CORRECT because SR-IOV helps in achieving higher network throughput, lower CPU utilization, and lower network latency which can translate into supporting more VMs per host, delivering increased network bandwidth utilization on the host, and providing greater performance predictability to the instances.</p><p>Option B is incorrect because having all the instances in the same AZ does not necessarily increase the throughput.</p><p>Option C is incorrect because RAID 1 configuration which has data mirroring, provides redundancy of data for high availability; it does not increase the throughput.</p><p><span style=""></span></p><p>Option D is incorrect because this option will help in achieving high availability, not increased throughput.</p><p><br></p><p><b>More information on SR-IOV:</b></p><p><span style="font-size: 1rem;">Enhanced networking uses single root I/O virtualization (SR-IOV) to provide high-performance networking capabilities on supported instance types. SR-IOV is a method of device virtualization that provides higher I/O performance and lower CPU utilization when compared to traditional virtualized network interfaces. Enhanced networking provides higher bandwidth, higher packet per second (PPS) performance, and consistently lower inter-instance latency.&nbsp;</span></p><p></p><div><span style="font-size: 1rem;">Reference Link:</span></div><div><span style="font-size: 1rem;"><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html" target="_blank">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html</a><br></span></div><br><p></p>	Move all your EC2 instances to the same availability zone. <br>  すべてのEC2インスタンスを同じ可用性ゾーンに移動します。	Use a RAID 1 configuration instead of RAID 0. <br>  RAID 0ではなくRAID 1構成を使用してください。	Use instance store backed instances and stripe the attached ephemeral storage devices and use DRBD Asynchronous Replication. <br>  インスタンス・ストアでサポートされているインスタンスを使用して、接続されている一時記憶域デバイスをストライプ化し、DRBD非同期レプリケーションを使用します。
Test4-05. <p>You are designing multi-region architecture and you want to send users to a geographic location based on latency-based routing, which seems simple enough; however, you also want to use weighted-based routing among resources within that region. Which of the below setups would best accomplish this? <br></p><p>Choose the correct answer from the below options:<br></p> | <p>マルチリージョンアーキテクチャを設計しており、レイテンシーベースのルーティングに基づいてユーザーを地理的な場所に送りたいと思っています。ただし、その領域内のリソース間で重み付けベースのルーティングを使用する場合もあります。この中で最も効果的な設定はどれですか？<br> </p> <p>以下のオプションから正解を選択します：<br> </p>	sa:	You will need to use complex routing (nested record sets) and ensure that you define the weighted resource record sets first. <br>  複雑なルーティング（ネストされたレコードセット）を使用して、まず重み付きリソースレコードセットを定義する必要があります。|<p><br></p><p>Option A is incorrect because you need to define the record set to be pointed to (in this case weighted) before creating the top level record set (in this case latency).</p><p>Option B is CORRECT because you need to create the weighted policies first because you are going to use those record sets as the alias pointing to in the latency record sets.</p><p>Option C is incorrect because you can create the nested record sets to accomplish this.</p><p>Option D is incorrect because use of IPv6 is not mandatory in this configuration (and it does not mention any latency based routing - which is one of the requirements).</p><p><br></p><p>Please refer to the below documentation from AWS for an example where you can define complex routing</p><p>&nbsp;<img src="https://s3.amazonaws.com/awssap/4_5_1.png" alt="" role="presentation" class="img-responsive atto_image_button_text-bottom" height="448" width="743"></p><p>Please find the below link for complex based routing:</p><p></p><a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html</a><br><p></p>	You will need to use complex routing (nested record sets) and ensure that you define the latency based records first <br>  複雑なルーティング（ネストされたレコードセット）を使用し、最初にレイテンシベースのレコードを定義する必要があります	This cannot be done. You can't use different routing records together. <br>  これはできません。異なるルーティングレコードを一緒に使用することはできません。	You will need to use AAAA - IPv6 addresses when you define your weighted based record sets. <br>  加重ベースのレコードセットを定義するときは、AAAA  -  IPv6アドレスを使用する必要があります。
Test4-06. <p>An Amazon Redshift cluster with four nodes is running 24/7/365 and expects potentially to add one on-demand node for one to two days once during the year. Which architecture would have the lowest possible cost for the cluster requirement?</p><p>Choose the correct answer from the below options:<br></p> | <p> 4ノードのAmazon Redshiftクラスタは24時間365日稼動しており、オンデマンドノードを1年に1回〜2日間追加する可能性があります。</p> <p>以下のオプションから正しい答えを選択してください：<br> </p>	sa:	Purchase 4 reserved nodes and rely on on-demand instances for the fifth node, if required. <br>  必要に応じて4つの予約済みノードを購入し、5番目のノードのオンデマンドインスタンスに頼ります。|<p><br></p><p>Option A is CORRECT because (a) the application requires 4 nodes throughout the year and reserved instances would save the cost, and (b) since the need of the other node is not assured, on-demand instance(s) can be purchased if and when needed.</p><p>Option B is incorrect because reserving 5th node is unnecessary.&nbsp;</p><p>Option C is incorrect because, even though the spot instances are cheaper than on-demand instances, they should only be used if the application is tolerant of sudden termination of them. Since the question does not mention this, purchasing spot instance(s) may not be a good option.</p><p>Option D is incorrect because reserving only 2 instances would not be sufficient.</p><p><br></p><p>Please find the below link for Reserved Instances:</p><p></p><a href="https://aws.amazon.com/ec2/pricing/reserved-instances/" target="_blank" style="font-size: 1rem;">https://aws.amazon.com/ec2/pricing/reserved-instances/</a><br><p></p>	Purchase 5 reserved nodes to cover all possible usage during the year. <br>  年内に可能なすべての使用をカバーするために5つの予約済みノードを購入します。	Purchase 4 reserved nodes and bid on spot instances for the extra node if required. <br>  必要に応じて4つの予約済みノードを購入し、余分なノードのスポットインスタンスに入札します。	Purchase 2 reserved nodes and utilize 3 on-demand nodes only for peak usage times. <br>  2つの予約済みノードを購入し、最大使用時間の間のみ3つのオンデマンドノードを使用します。
Test4-07. <p>A company has placed a set of on-premise resources with an AWS Direct Connect provider. After establishing connections to a local AWS region in the US, the company needs to establish a low latency dedicated connection to an S3 public endpoint over the Direct Connect dedicated low latency connection. What steps need to be taken to accomplish configuring a direct connection to a public S3 endpoint? <br></p><p>Choose the correct answer from the options given below:<br></p> | <p>企業はAWS Direct Connectプロバイダに一連のオンプレミスリソースを配置しました。米国のローカルAWS地域への接続を確立した後、Direct Connect専用低遅延接続を介してS3公開エンドポイントへの低レイテンシ専用接続を確立する必要があります。パブリックS3エンドポイントへの直接接続を設定するためには、どのような手順をとる必要がありますか？<br> </p> <p>以下のオプションから正解を選んでください：<br> </p>	sa:	Configure a public virtual interface to connect to a public S3 endpoint resource. <br>  パブリックS3エンドポイントリソースに接続するようにパブリック仮想インターフェイスを構成します。|<p><br></p><p></p><p>You can create a public virtual interface to connect to public resources or a private virtual interface to connect to your VPC. You can configure multiple virtual interfaces on a single AWS Direct Connect connection, and you'll need one private virtual interface for each VPC to connect to. Each virtual interface needs a VLAN ID, interface IP address, ASN, and BGP key. See the image below:</p><p><span style="font-size: 1rem;">&nbsp;</span><img src="https://s3.amazonaws.com/awssap/4_7_1.jpg" alt="" width="638" height="359" role="presentation" class="img-responsive atto_image_button_text-bottom" style="font-size: 1rem;"></p><p>Option A is CORRECT because, as mentioned above, it creates a public virtual interface to connect to S3 endpoint.</p><p>Option B is incorrect because to connect to S3 endpoint, a public virtual interface needs to be created, not VPN.</p><p>Option C is incorrect because to connect to S3 endpoint, a&nbsp;<b>public&nbsp;</b>virtual interface needs to be created,&nbsp;<b>not</b>&nbsp;<b>private</b>.</p><p>Option D is incorrect because this setup will not help connecting to the S3 endpoint.</p><p>&nbsp;</p><p>For more information on virtual interfaces, please visit the below URL</p>  <a href="http://docs.aws.amazon.com/directconnect/latest/UserGuide/WorkingWithVirtualInterfaces.html" target="_blank">http://docs.aws.amazon.com/directconnect/latest/UserGuide/WorkingWithVirtualInterfaces.html</a><br><p></p>	Establish a VPN connection from the VPC to the public S3 endpoint. <br>  VPCからパブリックS3エンドポイントへのVPN接続を確立します。	Configure a private virtual interface to connect to the public S3 endpoint via the Direct Connect connection. <br>  直接接続接続を介してパブリックS3エンドポイントに接続するようにプライベート仮想インターフェイスを設定します。	Add a BGP route as part of the on-premise router; this will route S3 related traffic to the public S3 endpoint to dedicated AWS region. <br>  BGPルートをオンプレミスルータの一部として追加します。S3関連のトラフィックをパブリックS3エンドポイントに専用のAWS領域にルーティングします。
Test4-08. <p></p><p>Your company is hosting a web application on AWS. According tothe architectural best practices, the application must be highly available,scalable, cost effective, with high-performance and should require minimalhuman intervention. You have deployed the web servers and database servers inpublic and private subnet of the VPC respectively. While testing theapplication via web browser, you noticed that the application is notaccessible. Which configuration settings you must do to tackle this problem?</p>Choose 2 options from below:<p><br></p> | <p> </p> <p>あなたの会社はAWSでウェブアプリケーションをホストしています。アーキテクチャ上のベストプラクティスによれば、アプリケーションは高可用性、スケーラビリティ、コスト効率、高性能でなければならず、人的介入を最小限に抑える必要があります。VPCの公開サブネットとプライベートサブネットにそれぞれWebサーバーとデータベースサーバーを展開しました。Webブラウザ経由でアプリケーションをテストしているときに、アプリケーションにアクセスできないことに気付きました。この問題を解決するには、どの設定を行う必要がありますか？</p>下記の2つのオプションを選択してください：<p> <br> </p>	ma:	x:Configure a NAT instance in your VPC and create a default route via the NAT instance and associate it with all subnets. Configure a DNS A record that points to the NAT instance public IP address. <br>  VPCでNATインスタンスを設定し、NATインスタンス経由でデフォルトルートを作成し、すべてのサブネットに関連付けます。NATインスタンスのパブリックIPアドレスを指すDNS Aレコードを設定します。|<p><br></p><p>Option A is incorrect because (a) NAT instance is ideally used to route traffic from a private subnet to the internet via a public subnet, (b) NAT instance is not managed by AWS and requires to be configured and maintained by the user; hence, adding to the overhead, and (c) if not scaled, can cause performance bottleneck. NAT Gateway is a preferred option over NAT instances.</p><p>Option B is recommending us to use AWS CloudFront and configure the distributions Origin to the web server and then use a AWS Route 53 ‘CNAME’ for the CloudFront Distribution. Even though CloudFront is highly available and is accessible to the Internet, it would work better if the Origin for the AWS CloudFront Distribution was pointed to an AWS ELB rather than to the Web Server itself. The question does not mention the presence of an ELB.&nbsp;</p><p>Since the Origin would only be a Web Server, if this server goes offline for a period of time, the web site would become unavailable the content is not cached at the Edge location or if the TTL for the content expires.&nbsp;</p><p>So, Option B is incorrect as well.</p><p>Option C is CORRECT. Because, (a) if the web servers are behind an ELB, the load on the web servers will be uniformly distributed. Hence, if any of the web servers goes offline or becomes non-responsive, the traffic would be routed to other online web servers; making the application highly available, and (b) You can use Route53 to set the ALIAS record that points to the ELB endpoint.</p><p><img src="https://s3.amazonaws.com/awssap/4_8_1.PNG" alt="" width="522" height="534" role="presentation" class="img-responsive atto_image_button_text-bottom"><br><!--[endif]--></p><p>Option D is CORRECT. Because, (a) if the web servers are behind an ELB, the load on the web servers will be uniformly distributed. Hence, if any of the web servers goes offline or becomes non-responsive, the traffic would be routed to other online web servers; making the application highly available, (b) In Route53, you can either resolve the DNS query via creating an ALIAS record pointing to the ELB endpoint or an A record pointing to the IP Addresses of the application. As the EIPs are static (will not be changed) and can be assigned to new web servers if any of the web servers becomes offline, the EIPs can be used in the A record. The health check would ensure that Route53 checks the health of the record set before the failover to other web servers.</p><p><img src="https://s3.amazonaws.com/awssap/4_8_2.PNG" alt="" width="476" height="746" role="presentation" class="img-responsive atto_image_button_text-bottom"><br><!--[endif]--></p><p><br></p><p><br></p><ul></ul><p></p>	x:Configure a CloudFront distribution and configure the origin to point to the private IP addresses of your Web servers. Configure a Route53 CNAME record to your CloudFront distribution. <br>  CloudFrontディストリビューションを設定し、WebサーバーのプライベートIPアドレスを指すように起点を設定します。CloudFrontディストリビューションにRoute53 CNAMEレコードを設定します。	o:Place all your web servers behind ELB. Configure a Route53 ALIAS-Record to point to the ELB DNS name. <br>  すべてのWebサーバーをELBの後ろに置きます。ELB DNS名を指すようにRoute53 ALIAS-Recordを設定します。	o:Assign EIP's to all web servers. Configure a Route53 A-Record set with all EIPs with health checks and DNS failover. <br>  EIPをすべてのWebサーバーに割り当てます。ヘルスチェックとDNSフェールオーバーを備えたすべてのEIPでRoute53 Aレコードセットを設定します。
Test4-09. <p></p><span id="docs-internal-guid-846a0cce-319f-2911-af4e-f0f62c83e72c">You have launched an EC2 instance with four (4) 500 GB EBS Provisioned IOPS volumes attached. The EC2 instance is EBS-Optimized and supports 500 Mbps throughput between EC2 and EBS. The EBS volumes are configured as a single RAID 0 device, and each Provisioned IOPS volume is provisioned with 4,000 IOPS (4,000 16KB reads or writes) for a total of 16,000 random IOPS on the instance. The EC2 instance initially delivers the expected 16,000 IOPS random read and write performance. Sometime later in order to increase the total random I/O performance of the instance, you add an additional two 500 GB EBS Provisioned IOPS volumes to the RAID. Each volume is provisioned to 4,000 lOPs like the original four for a total of 24,000 IOPS on the EC2 instance. Monitoring shows that the EC2 instance CPU utilization increased from 50% to 70%. but the total random IOPS measured at the instance level did not increase at all. What is the problem and a valid solution?</span><p><br></p> | </p> <span id = "docs-internal-guid-846a0cce-319f-2911-af4e-f0f62c83e72c"> 500 GBのEBSプロビジョニングIOPSボリュームを4つ接続してEC2インスタンスを起動しました。EC2インスタンスはEBS-Optimizedで、EC2とEBSの間で500 Mbpsのスループットをサポートします。EBSボリュームは1つのRAID 0デバイスとして構成され、プロビジョニングされた各IOPSボリュームには4,000 IOPS（4,000 16KBの読み取りまたは書き込み）がプロビジョニングされ、合計16,000のランダムIOPSがインスタンスに与えられます。EC2インスタンスは、最初は16,000 IOPSのランダムな読み取りおよび書き込みパフォーマンスを提供します。インスタンスのランダムI / Oパフォーマンスを向上させるために、500 GBのEBSプロビジョニングIOPSボリュームをRAIDに2つ追加します。各ボリュームは、元の4つのように4,000のlOPsに合計24でプロビジョニングされ、EC2インスタンスの000 IOPS。監視は、EC2インスタンスのCPU使用率が50％から70％に増加したことを示しています。インスタンスレベルで測定された合計ランダムIOPSはまったく増加しませんでした。問題と有効な解決策は何ですか？</ span> <p> <br> </p>	sa:	The EBS-Optimized throughput limits the total IOPS that can be utilized; hence, use an EBS-Optimized instance that provides larger throughput. <br>  EBS-Optimizedスループットは、利用可能なIOPSの合計を制限します。したがって、より大きなスループットを提供するEBS最適化インスタンスを使用します。|<br><p dir="ltr" style="">Option A is incorrect because increasing the volume size may not be sufficient; you will not get the higher IOPS unless the volumes are attached to EBS-optimized instance types with larger throughput (e.g. 8xlarge or higher).</p><p dir="ltr" style="">Option B is CORRECT because EC2 Instance types have limit on max throughput and would require 8xlarge or higher instance types to provide 24000 or more IOPS.</p><p dir="ltr" style="">Option C is incorrect because this option will not increase the IOPS.</p><p dir="ltr" style="">Option D is incorrect because the reasoning given for the issue (RAID 0 only scaling for 4 volumes) is not true.</p><p dir="ltr" style="">Option E is incorrect because it already has sufficient number of volumes with 4,000 PIOPS attached. So, changing the root volume to a 4,000 PIOPS will not be useful.</p><br><br><p dir="ltr" style=""><b>More information on the topic from AWS documentation:</b></p><p dir="ltr" style="">Launching an instance that is EBS-optimized provides you with a dedicated connection between your EC2 instance and your EBS volume. However, it is still possible to provision EBS volumes that exceed the available bandwidth for certain instance types, especially when multiple volumes are striped in a RAID configuration. Be sure to choose an EBS-optimized instance that provides more dedicated EBS throughput than your application needs; otherwise, the Amazon EBS to Amazon EC2 connection will become a performance bottleneck.</p><br><p dir="ltr" style="">For more information on IOPS, please visit the link below:</p><p dir="ltr" style=""><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-ec2-config.html" target="_blank">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-ec2-config.html</a></p><i>"In order to get the most performance out of your EBS volumes, you should attach them to an instance with enough bandwidth to support your volumes, such as an EBS-optimized instance or an instance with 10 Gigabit network connectivity. This is especially important when you stripe multiple volumes together in a RAID configuration."</i><br></span><br><p></p>	Larger storage volumes support higher Provisioned IOPS rates; hence, increase the provisioned volume storage of each of the 6 EBS volumes to 1TB. <br>  ストレージ容量が大きいほど、プロビジョニングされたIOPSレートが高くなります。したがって、6つのEBSボリュームのそれぞれのプロビジョニングされたボリュームストレージを1TBに増やします。	Small block sizes cause performance degradation, limiting the I/O throughput; hence, configure the instance device driver and file system to use 64KB blocks to increase throughput. <br>  ブロックサイズが小さいとパフォーマンスが低下し、I / Oスループットが制限されます。したがって、64 KBブロックを使用してスループットを向上させるようにインスタンス・デバイス・ドライバーとファイル・システムを構成してください。	RAID 0 only scales linearly to about 4 devices, use RAID 0 with 4 EBS Provisioned IOPS volumes but increase each Provisioned IOPS EBS volume to 6,000 IOPS. <br>  RAID 0は、約4つのデバイスに直線的に拡張するだけで、4つのEBSプロビジョニングIOPSボリュームでRAID 0を使用しますが、各プロビジョニングIOPS EBSボリュームを6,000 IOPSに増やします。	The standard EBS instance root volume limits the total IOPS rate; hence, change the instant root volume to also be a 500GB 4,000 Provisioned IOPS volume. <br>  標準のEBSインスタンスルートボリュームは、合計IOPSレートを制限します。したがって、インスタントルートボリュームを500 GB 4,000のプロビジョニングIOPSボリュームに変更します。
Test4-10. <p><span id="docs-internal-guid-846a0cce-312e-fb79-5120-99db98e6cd27">Your company plans to host a large donation website on Amazon Web Services (AWS). You anticipate a large and undetermined amount of traffic that will create many database writes. To be certain that you do not drop any writes to a database hosted on AWS. Which service should you use? </span></p> | <p> <span id = "docs-internal-guid-846a0cce-312e-fb79-5120-99db98e6cd27"> Amazon Web Services（AWS）で大規模な寄付Webサイトをホストする予定です。多くのデータベース書き込みを作成する大量の不確定量のトラフィックが予想されます。AWSでホストされているデータベースへの書き込みをドロップしないことを確実にする。どのサービスを使用しますか？</ span> </p>	sa:	Amazon Simple Queue Service (SQS) for capturing the writes and draining the queue to write to the database. <br>  Amazon Simple Queue Service（SQS）は、書き込みをキャプチャし、データベースに書き込むためにキューを排除します。|<br><p dir="ltr" style="">Option A and D are incorrect because the peak amount of traffic is undetermined; so you cannot provision the “provisioned IOPS” beforehand.</p><p dir="ltr" style="">Option B is CORRECT because SQS is AWS managed and highly scalable service that can hold the database write requests in the queue, and ensure that no writes will be dropped.</p><p dir="ltr" style="">Option C is incorrect because ElastiCache is used for read-heavy applications to reduce the load on the database (not to cache the writes).</p><br><p dir="ltr" style="">For more information on SQS, please read the related questions in the FAQs</p></span><a href="https://aws.amazon.com/sqs/faqs/" target="_blank">https://aws.amazon.com/sqs/faqs/</a><br><br>	Amazon RDS with provisioned IOPS up to the anticipated peak write throughput. <br>  予想される最大書き込みスループットまでプロビジョニングされたIOPSを備えたAmazon RDS。	Amazon ElastiCache to store the writes until the writes are committed to the database. <br>  Amazon ElastiCacheは、書き込みがデータベースにコミットされるまで書き込みを格納します。	Amazon DynamoDB with provisioned write throughput up to the anticipated peak write throughput. <br>  予期されるピーク書き込みスループットまでプロビジョニングされた書き込みスループットを備えたAmazon DynamoDB
Test4-11. <p>As an IT administrator, you have been tasked to develop a reliable and durable logging solution to track changes made to your EC2, IAM and RDS resources. The solution must ensure the integrity and confidentiality of your log data. Which of these solutions would you implement?</p> | <p> IT管理者は、EC2、IAM、およびRDSリソースの変更を追跡するための信頼性の高い耐久性のあるロギングソリューションを開発する必要があります。ソリューションでは、ログデータの整合性と機密性を確保する必要があります。どのソリューションを実装しますか？</p>	sa:	Create a new CloudTrail trail with one new S3 bucket to store the logs and with the global services option selected. Use IAM roles S3 bucket policies and Multi Factor Authentication (MFA). Delete on the S3 bucket that stores your logs. <br>  1つの新しいS3バケットを使用して新しいCloudTrailトレイルを作成し、ログを保存し、グローバルサービスオプションを選択します。IAMロールS3バケットポリシーとマルチファクタ認証（MFA）を使用します。あなたのログを保存するS3バケットで削除してください。|<p><br></p><p></p><p>For the scenarios where the application is tracking (or needs to track) the changes made by any AWS service, resource, or API, always think about AWS CloudTrail service.</p><p>AWS Identity and Access Management (IAM) is integrated with AWS CloudTrail, a service that logs AWS events made by or on behalf of your AWS account. CloudTrail logs authenticated AWS API calls and also AWS sign-in events, and collects this event information in files that are delivered to Amazon S3 buckets.&nbsp;</p><p>The most important points in this question are (a)&nbsp;S3 bucket with global services option enabled, (b) Data integrity, and (c) Confidentiality.</p><p><br></p><p>Option A is CORRECT because (a) it uses AWS CloudTrail with Global Option enabled, (b) a single new S3 bucket and IAM Roles so that it has the confidentiality, (c)&nbsp; MFA on Delete on S3 bucket so that it maintains the data integrity. See the AWS CloudTrail setting below which sets the option to apply the trail to all regions (global).</p><p><span style="font-size: 1rem;"><img src="https://s3.amazonaws.com/awssap/4_11_1.png" alt="" width="808" height="184" role="presentation" class="img-responsive atto_image_button_text-bottom"><br></span></p><p><span style="font-size: 1rem;">Options B is incorrect because (a) although&nbsp;it uses AWS CloudTrail,&nbsp;the Global Option is not enabled, and (b) SNS notifications can be an overhead in this situation.</span></p><p>Option C is incorrect because (a) as an existing S3 bucket is used, it may already be accessed to the user, hence not maintaining the confidentiality, and (b) it is not using IAM roles.</p><p>Option D is incorrect because (a)&nbsp;although&nbsp;it uses AWS CloudTrail,&nbsp;the Global Option is not enabled, and (b) three S3 buckets are not needed.</p><p><br></p><p>For more information on CloudTrail, please visit the below URL:</p><p><a href="https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-concepts.html#cloudtrail-concepts-global-service-events" target="_blank">https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-concepts.html#cloudtrail-concepts-global-service-events</a></p>  <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/cloudtrail-integration.html" target="_blank">http://docs.aws.amazon.com/IAM/latest/UserGuide/cloudtrail-integration.html</a><br><p></p><ul></ul><p></p>	Create a new CloudTrail with one new S3 bucket to store the logs. Configure SNS to send log file delivery notifications to your management system. Use IAM roles and S3 bucket policies on the S3 bucket that stores your logs. <br>  1つの新しいS3バケットで新しいCloudTrailを作成し、ログを保存します。ログファイル配信通知を管理システムに送信するようにSNSを設定します。ログを格納するS3バケットにIAMロールとS3バケットポリシーを使用します。	Create a new CloudTrail trail with an existing S3 bucket to store the logs and with the global services option selected. Use S3 ACLs and Multi Factor Authentication (MFA). Delete on the S3 bucket that stores your logs. <br>  既存のS3バケットを使用して新しいCloudTrailトレイルを作成して、ログを保存し、グローバルサービスオプションを選択します。S3 ACLとマルチファクタ認証（MFA）を使用します。あなたのログを保存するS3バケットで削除してください。	Create three new CloudTrail trails with three new S3 buckets to store the logs one for the AWS Management console, one for AWS SDKs and one for command line tools. Use IAM roles and S3 bucket policies on the S3 buckets that store your logs. <br>  AWS管理コンソール用、AWS SDK用、コマンドラインツール用のログを格納する3つの新しいS3バケットを備えた3つの新しいCloudTrailトレイルを作成します。ログを格納するS3バケットにIAMロールとS3バケットポリシーを使用します。
Test4-12. <p>You have just developed a new mobile application that handles analytics workloads on large-scale datasets that are stored on Amazon Redshift. Consequently, the application needs to access Amazon Redshift tables. Which of the below methods would be the best for both practically and security-wise to access the tables? <br></p><p>Choose the correct answer from the below options:<br></p> | <p> Amazon Redshiftに保存されている大規模データセットの分析ワークロードを処理する新しいモバイルアプリケーションを開発しました。したがって、アプリケーションはAmazonのRedshiftテーブルにアクセスする必要があります。以下の方法のどれが、テーブルにアクセスするのに事実上およびセキュリティ上の両方で最適なのでしょうか？<br> </p> <p>以下のオプションから正解を選択します：<br> </p>	sa:	Use roles that allow a web identity federated user to assume a role that allows access to the Redshift table by providing temporary credentials. <br>  Web IDフェデレーションユーザーが一時的な資格情報を提供することによってRedshiftテーブルにアクセスできる役割を引き受ける役割を使用します。|<p><br></p><p>Tip: When a service, user, or application needs to access any AWS resource, always prefer creating an IAM Role over creating an IAM User.</p><p><span style="font-size: 1rem;"><br></span></p><p><span style="font-size: 1rem;">Option A is incorrect because embedding keys in the application to access AWS resource is not a good architectural practice as it creates security concerns.</span></p><p><span style="font-size: 1rem;">Option B is incorrect because HSM certificate is used by Redshift cluster to connect to the client's HSM in order to store and retrieve the keys used to encrypt the cluster databases.</span></p><p><span style="font-size: 1rem;">Option C is incorrect because read-only policy is insufficient and embedding keys in the application to access AWS resource is not a good architectural practice as it creates security concerns.</span></p><p><span style="font-size: 1rem;">Option D is CORRECT because (a) IAM role allows the least privileged access to the AWS resource, (b) web identity federation ensures the identity of the user, and (c) the user is given temporary credentials to access the AWS resource.</span></p><p><br></p><p>For more information on IAM policies please refer to the below link:</p><p><span style="font-size: 1rem;"><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html" target="_blank">http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html</a><br></span></p><p><span style="font-size: 1rem;"><br></span></p><p></p><p>Next, for any web application, you need to use web identity federation. Hence option D is the right option. This along with the usage of roles is highly stressed in the AWS documentation.</p><p>&nbsp;<img src="https://s3.amazonaws.com/awssap/4_12_1.png" alt="" role="presentation" class="img-responsive atto_image_button_text-bottom" height="137" width="734"></p><p>For more information on web identity federation please refer to the below link</p><p></p><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html</a><br><br><p></p>	Create a HSM client certificate in Redshift and authenticate using this certificate. <br>  RedshiftでHSMクライアント証明書を作成し、この証明書を使用して認証します。	Create a Redshift read-only access policy in IAM and embed those credentials in the application. <br>  Redshift読み取り専用アクセスポリシーをIAMで作成し、これらの資格情報をアプリケーションに埋め込みます。	Create an IAM user and generate encryption keys for that user. Create a policy for Redshift read-only access. Embed the keys in the application. <br>  IAMユーザーを作成し、そのユーザーの暗号化キーを生成します。Redshift読み取り専用アクセスのポリシーを作成します。アプリケーションにキーを埋め込みます。
Test4-13. <p>Which of the following must be done while generating a pre-signed URL in S3 in order to ensure that the user who is given the pre-signed URL has the permission to upload the object?</p> | <p>事前署名されたURLを与えられたユーザーにオブジェクトをアップロードする権限があることを確認するために、S3で事前署名されたURLを生成する際には、次のうちどれを実行する必要がありますか？</p>	sa:	Ensure that the person who has created the pre-signed URL has the permission to upload the object to the appropriate S3 bucket. <br>  事前に署名されたURLを作成したユーザーに、オブジェクトを適切なS3バケットにアップロードする権限があることを確認します。|<p><br></p><p>Option A is incorrect because if the person who has created the pre-signed URL does not have write permission to S3, the person who is given the pre-signed URL will not have it either.</p><p>Option A is incorrect because if the person who has created the pre-signed URL does not have read permission to S3, the person who is given the pre-signed URL will not have it either.</p><p>Option C is CORRECT because in order to successfully upload an object to S3, the pre-signed URL must be created by someone who has permission to perform the operation that the pre-signed URL is based upon.</p><p>Option D is incorrect because CloudFront distribution is not needed in this scenario.</p><p><br></p><p>For more information on pre-signed URL’s, please visit the below URL</p><p></p><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/PresignedUrlUploadObject.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AmazonS3/latest/dev/PresignedUrlUploadObject.html</a><br><br><p></p>	Ensure the user has read permission to S3. <br>  ユーザーがS3に対する読み取り権限を持っていることを確認します。	Ensure the user has write permission to S3. <br>  ユーザーにS3に対する書き込み権限があることを確認します。	Create a Cloudfront distribution. <br>  Cloudfrontディストリビューションを作成します。
Test4-14. <p></p><span id="docs-internal-guid-846a0cce-31a3-89f7-e995-df1e6d4854da">A customer needs corporate IT governance and cost oversight of all AWS resources consumed by its divisions. The divisions want to maintain administrative control of the discrete AWS resources they consume and keep those resources separate from the resources of other divisions. Which of the following options, when used together, will support the autonomy/control of divisions while enabling corporate IT to maintain governance and cost oversight? Choose 2 answers </span><p><br></p> | 顧客は、企業のITガバナンスと、その部門が消費するすべてのAWSリソースのコスト監視を必要としています。 部門は、消費する個別のAWSリソースの管理上の管理を維持し、これらのリソースを他の部門のリソースから分離して保持する必要があります。 次のオプションのどれを一緒に使用すると、企業ITがガバナンスとコスト監視を維持できるようにしながら、部門の自律性/制御をサポートしますか？ 2つの回答を選択<p> <span id = "docs-internal-guid-846a0cce-31a3-89f7-e995-df1e6d4854da" 部門は、消費する個別のAWSリソースの管理上の管理を維持し、これらのリソースを他の部門のリソースから分離して保持する必要があります。次のオプションのどれを一緒に使用すると、企業ITがガバナンスとコスト監視を維持できるようにしながら、部門の自律性/制御をサポートしますか？2つの回答を選択する</ span> <p> <br> </p>	ma:	x:Use AWS Consolidated Billing and disable AWS root account access for the child accounts. <br>  AWS Consolidated Billingを使用して、子アカウントのAWSルートアカウントアクセスを無効にします。|<br><p dir="ltr" style="">We need to satisfy 2 requirements here.<br>1. To provide either autonomy or control of divisions while maintaining IT Governance<br>2. To evaluate the overall cost<br><br><br>AWS Organizations has two available feature sets:&nbsp;<b>consolidated billing features and all features.</b>&nbsp;All organizations support consolidated billing, which provides basic management tools that you can use to centrally manage the accounts in your organization.&nbsp;<br><br>If you enable&nbsp;<b>all features,</b>&nbsp;you continue to get all the consolidated billing features plus a set of advanced features such as service control policies (SCPs), which give you fine-grained control over which services and actions that member accounts can access.<br><br>When you start the process to enable all features, AWS Organizations sends a request to every member account that you&nbsp;<i>invited</i>&nbsp;to join your organization. Every invited account must approve enabling all features by accepting the request. Only then can you complete the process to enable all features in your organization. If an account declines the request, you must either remove the account from your organization or resend the request and get it accepted before you can complete the process to enable all features. Accounts that you&nbsp;<i>created</i>&nbsp;using AWS Organizations don't get a request because they don't need to approve the additional control.<br><br><a href="https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html" rel="noreferrer">https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html</a><br><a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_org_support-all-features.html" rel="noreferrer">https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_org_support-all-features.html</a><br><br>With options B&amp;C the two requirements of the scenario are not met.<br></p></span><ul></ul><p></p>	o:Enable IAM cross-account access for all corporate IT administrators in each child account. <br>  各子アカウントのすべての企業IT管理者にIAMクロスアカウントアクセスを有効にします。	x:Create separate VPCs for each division within the corporate IT AWS account. <br>  企業のIT AWSアカウント内の部門ごとに個別のVPCを作成します。	o:Use AWS Consolidated Billing to link the divisions' accounts to a parent corporate account. <br>  部門の勘定科目を親会社の勘定科目にリンクするには、AWS Consolidated Billingを使用します。	x:Write all child AWS CloudTrail and Amazon CloudWatch logs to each child account's Amazon S3 'Log' bucket. <br>  すべての子AWS CloudTrailログとAmazon CloudWatchログを各子アカウントのAmazon S3 'Log'バケットに書き込みます。
Test4-15. <p>A user has launched a large EBS backed EC2 instance in the US-East-1a region. The user wants to achieve Disaster Recovery (DR) for that instance by creating another small instance in Europe. How can the user achieve DR?</p> | <p>ユーザーは、US-East-1a地域で大きなEBSバックアップEC2インスタンスを開始しました。ユーザーは、ヨーロッパで別の小さなインスタンスを作成して、そのインスタンスのDR（災害復旧）を達成したいと考えています。ユーザーはどのようにDRを達成できますか？</p>	sa:	Create an AMI of the instance and copy the AMI to the EU region. Then launch the instance from the EU AMI. <br>  インスタンスのAMIを作成し、AMIをEU地域にコピーします。その後、EU AMIからインスタンスを起動します。|<p><br></p><p>Option A and C are incorrect because you cannot directly copy the instance. You need to create AMI of each instance.</p><p><span style="font-size: 1rem;">Option B is CORRECT because if you need an AMI across multiple regions, then you have to copy the AMI across regions. Note that by default AMI’s that you have created will not be available across all regions.</span></p><p><span style="font-size: 1rem;">Option D is incorrect because using "Launch More Like This..." enables you to use a current instance as a base for launching other instances in the same availability zone. It does not clone your selected instance; it only replicates some configuration details. To create a copy of your instance, first create an AMI from it, then launch more instances from the AMI.</span></p><p><br></p><p>For the entire details to copy AMI’s, please visit the link -&nbsp;</p><p><span style="font-size: 1rem;"><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html" target="_blank">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html</a></span></p><p><br></p><ul></ul><p></p>	Copy the running instance using the “Instance Copy” command to the EU region. <br>  "Instance Copy"コマンドを使用して実行中のインスタンスをEU地域にコピーします。	Copy the instance from the US East region to the EU region. <br>  インスタンスを米国東部地域からEU地域にコピーします。	Use the “Launch more like this” option to copy the instance from one region to another. <br>  ある地域から別の地域にインスタンスをコピーするには、「これ以上起動する」オプションを使用します。
Test4-16. <p>A user has setup Auto Scaling with ELB on the EC2 instances. The user wants to configure that whenever the CPU utilization is below 10%, Auto Scaling should remove one instance. How can the user configure this?</p> | <p>ユーザーは、EC2インスタンスでELBを使用して自動スケーリングを設定しています。ユーザーは、CPU使用率が10％を下回るたびにAuto Scalingが1つのインスタンスを削除するように設定する必要があります。ユーザーはどのようにこれを設定できますか？</p>	sa:	Configure a CloudWatch alarm in the execution policy that notifies the Auto Scaling group when the CPU Utilization is less than 10%, and configure the Auto Scaling policy to remove the instance. <br>  CPU使用率が10％未満のときに自動スケーリンググループに通知する実行ポリシーでCloudWatchアラームを設定し、インスタンスを削除するように自動スケーリングポリシーを設定します。|<p><br></p><p>Option A is incorrect because for the user to get the notification, they have to configure CloudWatch which triggers a notification to Auto Scaling Group to terminate the instance. Updating the desired capacity will not work in this case.</p><p>Option B is incorrect because scheduled scaling is used to scale your application in response to predictable load changes, not upon any notification.</p><p>Option C is incorrect because the notification should be sent to Auto Scaling Group, not the launch configuration.</p><p>Option D is CORRECT because the notification is sent to Auto Scaling Group which then removes an instance from the running instances.</p><p><br></p><p><b>More information on Auto Scaling, Scheduled Actions:</b></p><p>Auto Scaling helps you maintain application availability and allows you to scale your Amazon EC2 capacity up or down automatically according to conditions you define. You can use Auto Scaling to help ensure that you are running your desired number of Amazon EC2 instances. Auto Scaling can also automatically increase the number of Amazon EC2 instances during demand spikes to maintain performance and decrease capacity during lulls to reduce costs.</p><p>For more information on AutoScaling, please visit the link –</p><p></p><a href="https://aws.amazon.com/autoscaling/" target="_blank" style="font-size: 1rem;">https://aws.amazon.com/autoscaling/</a><br><a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/schedule_time.html" target="_blank">https://docs.aws.amazon.com/autoscaling/ec2/userguide/schedule_time.html</a><br><br><p></p>	Use CloudWatch to monitor the data and Auto Scaling to remove the instances using scheduled actions. <br>  CloudWatchを使用してデータを監視し、自動スケーリングを使用してスケジュールされたアクションを使用してインスタンスを削除します。	Configure a CloudWatch alarm in the execution policy that notifies the Auto Scaling Launch configuration when the CPU utilization is less than 10%, and configure the Auto Scaling policy to remove the instance. <br>  実行ポリシーでCloudWatchアラームを設定して、CPU使用率が10％未満のときにAuto Scaling Launch設定を通知し、Auto Scalingポリシーを設定してインスタンスを削除します。	The user can get an email using SNS when the CPU utilization is less than 10%. The user can use the desired capacity of Auto Scaling to remove the instance. <br>  CPU使用率が10％未満の場合、SNSを使用して電子メールを取得できます。ユーザーは、Auto Scalingの望ましい容量を使用してインスタンスを削除できます。
Test4-17. <p>An organization has added 3 of his AWS accounts to consolidated billing. One of the AWS accounts has purchased a Reserved Instance (RI) of a small instance size in the US-East-1a zone. All other AWS accounts are running instances of a small size in the same zone. What will happen in this case for the RI pricing?</p> | <p>組織はAWSアカウントのうち3つを統合請求に追加しました。AWSアカウントの1つが、US-East-1aゾーンで小さなインスタンスサイズのリザーブドインスタンス（RI）を購入しました。他のすべてのAWSアカウントは、同じゾーン内で小さなサイズのインスタンスを実行しています。この場合、RIの料金設定についてはどうなりますか？</p>	sa:	Any single instance from all the three accounts can get the benefit of AWS RI pricing if they are running in the same zone and are of the same size. <br>  同じゾーンで実行されていて同じサイズのAWS RI価格設定の利点を得るには、3つのすべてのアカウントのインスタンスを1つでも使用できます。|<p><br></p><p>Option A is incorrect because the price benefit of the reserved instances is applicable to all the accounts that are part of the consolidated billing group, not just the payer account (or the account that has reserved the instance) - for the total number of instances reserved.&nbsp;</p><p>Option B is incorrect because, since only a single instance is reserved, any one instance across all the accounts will receive the reserved instance price benefit.</p><p>Option C is CORRECT because the reserved price benefit will be applied to a single EC2 instance across all the accounts.&nbsp;</p><p>Option D is incorrect because the total number of instances that will receive the cost benefit will be same as the total number of reserved instances (in this case it's one).</p><p><br></p><p><b>More information on Consolidated Billing:</b></p><p>As per the AWS documentation for billing purposes, AWS treats all the accounts on the consolidated bill as if they were one account. Some services, such as Amazon EC2 and Amazon S3, have volume pricing tiers across certain usage dimensions that give you lower prices when you use the service more. With consolidated billing, AWS combines the usage from all accounts to determine which volume pricing tiers to apply, giving you a lower overall price whenever possible.</p><p>For more information on Consolidated billing, please visit the URL:</p><p></p><a href="http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html</a><br><p></p>	One instance of a small size and running in the US-East-1a zone of each AWS account will get the benefit of RI pricing. <br>  小規模で、各AWSアカウントのUS-East-1aゾーンで実行される1つのインスタンスは、RI価格設定の恩恵を受けるでしょう。	Only the account that has purchased the RI will get the advantage of RI pricing. <br>  RIを購入したアカウントのみRIの価格設定の利点を得るでしょう。	If there are more than one instances of a small size running across multiple accounts in the same zone no one will get the benefit of RI. <br>  同じゾーン内の複数のアカウントにまたがって実行されている小規模のインスタンスが複数存在する場合、誰もRIの利益を得ることはできません。
Test4-18. <p>A user has configured an SSL listener at ELB as well as on the back-end instances. Which of the below-mentioned statements helps the user understand ELB traffic handling with respect to the SSL listener?</p> | <p>ユーザはELBとバックエンドインスタンスでSSLリスナを設定しました。以下のステートメントのどれが、SSLリスナーに関してELBのトラフィック処理を理解するのに役立ちますか？</p>	sa:	ELB will not modify the headers. <br>  ELBはヘッダーを変更しません。|<p><br></p><p>Option A is invalid because if the front-end connection uses TCP or SSL, then your back-end connections can use either TCP or SSL. If the front-end connection uses HTTP or HTTPS, then your back-end connections can use either HTTP or HTTPS.</p><p><span style="font-size: 1rem;">Option B is invalid because when you use TCP/SSL for both front-end and back-end connections, your load balancer forwards the request to the back-end instances without modifying the headers.</span></p><p><span style="font-size: 1rem;">Option C is invalid because with this configuration you do not receive cookies for session stickiness. But, when you use HTTP/HTTPS, you can enable sticky sessions on your load balancer.</span></p><p>Option D is CORRECT because with SSL configuration, the load balancer will forward the request to the back-end instances without modifying the headers.</p><p><br></p><p>For more information on ELB, please visit the link:</p><p></p><a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html</a><br><br><p></p>	ELB will modify headers to add requestor details. <br>  ELBはリクエスタの詳細を追加するためにヘッダーを変更します。	ELB will intercept the request to add the cookie details if sticky session is enabled. <br>  スティッキセッションが有効な場合、ELBはクッキーの詳細を追加する要求をインターセプトします。	It is not possible to have the SSL listener both at ELB and back-end instances. <br>  ELBとバックエンドの両方のインスタンスでSSLリスナを使用することはできません。
Test4-19. <p>A user is using CloudFormation to launch an EC2 instance and then configure an application after the instance is launched. The user wants the stack creation of ELB and AutoScaling to wait until the EC2 instance is launched and configured properly. How can the user configure this?</p> | <p>ユーザーがCloudFormationを使用してEC2インスタンスを起動し、インスタンスの起動後にアプリケーションを構成しています。ユーザーは、ELBと自動スケーリングのスタック作成が、EC2インスタンスが起動され、正しく構成されるまで待機する必要があります。ユーザーはどのようにこれを設定できますか？</p>	sa:	The user can use the WaitCondition resource to hold the creation of the other dependent resources. <br>  ユーザーはWaitConditionリソースを使用して、他の従属リソースの作成を保持できます。|<p><br></p><p>You can use a wait condition for situations like the following:</p> <ul> <li>To coordinate stack resource creation with configuration actions that are external to the stack creation</li> <li>To track the status of a configuration process</li> </ul> <p><br></p><p>For more information on CloudFormation Wait condition please visit the link</p><p></p><a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-waitcondition.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-waitcondition.html</a><br><p></p>	The user can use the HoldCondition resource to wait for the creation of the other dependent resources. <br>  ユーザーはHoldConditionリソースを使用して、他の従属リソースの作成を待機することができます。	The user can use the DependentCondition resource to hold the creation of the other dependent resources. <br>  ユーザーはDependentConditionリソースを使用して、他の従属リソースの作成を保持できます。	It is not possible that the stack creation will wait until one service is created and launched. <br>  スタックの作成は、1つのサービスが作成されて起動されるまで待つことはできません。
Test4-20. <p>An organization has created one IAM user and applied the below-mentioned policy to the user. What entitlements do the IAM users avail with this policy?</p><p>{</p><p>&nbsp; &nbsp; "Version": "2012-10-17",</p><p>&nbsp; &nbsp; "Statement": [</p><p>&nbsp; &nbsp; &nbsp; &nbsp; {</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "Sid": "VisualEditor0",</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "Effect": "Allow",</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "Action": [</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "ec2:Describe*"</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ],</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "Resource": "*"</p><p>&nbsp; &nbsp; &nbsp; &nbsp; },</p><p>&nbsp; &nbsp; &nbsp; &nbsp; {</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "Sid": "VisualEditor0",</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "Effect": "Allow",</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "Action": [</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "autoscaling:Describe*"</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ],</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "Resource": "*"</p><p>&nbsp; &nbsp; &nbsp; &nbsp; },</p><p>&nbsp; &nbsp; &nbsp; &nbsp; {</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "Sid": "VisualEditor0",</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "Effect": "Allow",</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "Action": [</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "cloudwatch:ListMetrics",</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "cloudwatch:Describe*",</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "cloudwatch:GetMetricStatistics"</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ],</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "Resource": "*"</p><p>&nbsp; &nbsp; &nbsp; &nbsp; }</p><p>&nbsp; &nbsp; ]</p><p>}</p> | <p>組織は1人のIAMユーザーを作成し、下記のポリシーをユーザーに適用しました。IAMユーザーがこのポリシーを利用するにはどのような権限がありますか？</p> <p> {</p> <p>＆nbsp; ＆nbsp; "バージョン"： "2012-10-17"、</p> <p>＆nbsp; ＆nbsp; "声明"：[</p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; {</p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; "Sid"： "VisualEditor0"、</p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; "効果"： "許可"、</p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; "アクション"：[</p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; "ec2：Describe *" </p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ]、</p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; "リソース"： "*" </p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; }、</p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; {</p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; "Sid"： "VisualEditor0"、</p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; "効果"： "許可"、</p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; "アクション"：[</p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; "オートスケーリング：<p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; "cloudwatch：Describe *"、</p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; "cloudwatch：GetMetricStatistics" </p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ]、</p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; "リソース"： "*" </p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; } </p> <p>＆nbsp; ＆nbsp; ] </p> <p>} </p> "cloudwatch：GetMetricStatistics" </p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ]、</p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; "リソース"： "*" </p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; } </p> <p>＆nbsp; ＆nbsp; ] </p> <p>} </p> "cloudwatch：GetMetricStatistics" </p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ]、</p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; "リソース"： "*" </p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; } </p> <p>＆nbsp; ＆nbsp; ] </p> <p>} </p>	sa:	The policy will allow the user to perform all read-only activities on the EC2 services except load Balancing. <br>  このポリシーにより、ユーザーはロードバランシング以外のEC2サービスですべての読み取り専用アクティビティを実行できます。|<p>AWS Identity and Access Management is a web service which allows organizations to manage users and user permissions for various AWS services. If an organization wants to setup read only access to EC2 for a particular user, they should mention the action in the IAM policy which entitles the user for Describe rights for EC2, CloudWatch, Auto Scaling and ELB. In the policy shown below, the user will have read only access for EC2, CloudWatch and Auto Scaling. Since ELB is not mentioned as a part of the list, the user will not have access to ELB.<br></p><p>The above policy will allow the user to view EC2 instances, look at AutoScaling and CloudWatch but not allow the user access to Load Balancing. For the access to load balancing, you need to add the following statements as well.</p><br><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Effect": "Allow",</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Action": "elasticloadbalancing:Describe*",</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Resource": "*"</p><p><br></p><p>For more information on IAM policy , please visit the URL:</p><p></p><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html</a><br><br><p></p>	The policy will allow the user to list all the EC2 resources except EBS. <br>  このポリシーにより、ユーザーはEBS以外のすべてのEC2リソースを一覧表示できます。	The policy will allow the user to perform all read and write activities on the EC2 services. <br>  このポリシーにより、ユーザーはEC2サービスのすべての読み取りおよび書き込みアクティビティを実行できます。	The policy will allow the user to perform all read-only activities on the EC2 services. <br>  このポリシーにより、ユーザーはEC2サービスですべての読み取り専用アクティビティを実行できます。
Test4-21. <p>A user has created a VPC with CIDR 20.0.0.0/16 using the wizard. The user has created a public subnet CIDR (20.0.0.0/24) and VPN only subnets CIDR (20.0.1.0/24) along with the VPN gateway (vgw-12345) to connect to the user’s data center. The user’s data center has CIDR 172.28.0.0/12. The user has also setup a NAT instance (i-12345) to allow traffic to the internet from the VPN subnet. Which of the below-mentioned options is not a valid entry for the main route table in this scenario?</p> | <p>ウィザードを使用して、CIDR 20.0.0.0/16のVPCを作成しました。ユーザーは、パブリックサブネットCIDR（20.0.0.0/24）およびVPN専用サブネットCIDR（20.0.1.0/24）をVPNゲートウェイ（vgw-12345）と共に作成して、ユーザーのデータセンターに接続しました。ユーザーのデータセンターのCIDRは172.28.0.0/12です。また、VPNサブネットからインターネットへのトラフィックを許可するNATインスタンス（i-12345）も設定しています。以下のオプションのどれがこのシナリオのメインルートテーブルの有効なエントリではありませんか？</p>	sa:	Destination: 20.0.1.0/24 and Target: i-12345 <br>  目的地：20.0.1.0/24および対象：i-12345|<p><br></p><p>Option A is CORRECT because the destination of private subnet with NAT instance as target is not needed in the route table. This is an invalid entry.</p><p><span style="font-size: 1rem;">Option B is incorrect because you would need this entry to be able to communicate with the internet via NAT instance (e.g. for patch updates).</span></p><p><span style="font-size: 1rem;">Option C is incorrect because you need this entry for communicating with customer network via the virtual private gateway.</span></p><p><span style="font-size: 1rem;">Option D is incorrect because this entry is present by default to allow the resources in the VPC to communicate with each other.</span></p><p><span style="font-size: 1rem;"><br></span></p><p><span style="font-size: 1rem;">The below diagram shows how a typical setup for a VPC with VPN and Internet gateway would look like. The only routing option which should have access to the internet gateway should be the 0.0.0.0/0 address. So Option A is the right answer.</span></p><p>&nbsp;<img src="https://s3.amazonaws.com/awssap/4_21_1.png" alt="" role="presentation" class="img-responsive atto_image_button_text-bottom" height="532" width="702"></p><p><br></p><p>For more information on VPC with the option of VPN, please visit the link</p><p></p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario3.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario3.html</a><br><br><p></p>	Destination: 0.0.0.0/0 and Target: i-12345 <br>  送り先：0.0.0.0/0、ターゲット：i-12345	Destination: 172.28.0.0/12 and Target: vgw-12345 <br>  送信先：172.28.0.0/12およびターゲット：vgw-12345	Destination: 20.0.0.0/16 and Target: local <br>  目的地：20.0.0.0/16および対象：ローカル
Test4-22. <p>An organization has configured Auto Scaling with ELB. There is a memory issue in the application which is causing CPU utilization to go above 90%. The higher CPU usage triggers an event for Auto Scaling as per the scaling policy. If the user wants to find the root cause inside the application without triggering a scaling activity, how can he achieve this?</p> | <p>組織がELBで自動スケーリングを設定しました。CPU使用率が90％を超える原因となっているメモリの問題がアプリケーションにあります。CPU使用率が高いほどスケーリングポリシーに従って自動スケーリングのイベントが発生します。ユーザがスケーリングアクティビティをトリガせずにアプリケーション内の根本原因を見つけたい場合、どのようにこれを達成できますか？</p>	sa:	Suspend the scaling process until research is completed. <br>  研究が完了するまでスケーリングプロセスを一時停止する。|<p><br></p><p>In this scenario, the user wants to investigate the problem during the AutoScaling process without triggering the scaling activity. For this, the user can leverage the suspend and resume option available on AutoScaling.</p><p><br></p><p>Option A is incorrect because the scaling process need not be stopped, it can be suspended so that it can be resumed.</p><p>Option B is incorrect because scaling can be momentarily suspended until the investigation is completed.</p><p>Option C is incorrect because AutoScaling group is totally unnecessary in this scenario.</p><p>Option D is CORRECT because you can suspend and then resume one or more of the scaling processes for your Auto Scaling group if you want to investigate a configuration problem or other issue with your web application and then make changes to your application, without triggering the scaling processes.</p><p><br></p><p>For more information on suspending AutoScaling processes, please visit the link</p><p></p><span style="font-size: 1rem;"><a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-suspend-resume-processes.html" target="_blank">http://docs.aws.amazon.com/autoscaling/latest/userguide/as-suspend-resume-processes.html</a><br></span><br><p></p>	It is not possible to find the root cause from that instance without triggering scaling. <br>  そのインスタンスからスケーリングをトリガーせずに根本原因を見つけることはできません。	Delete AutoScaling group until research is completed. <br>  研究が完了するまでオートスケーリンググループを削除します。	Stop the scaling process until research is completed. <br>  研究が完了するまでスケーリングプロセスを停止します。
Test4-23. <p>A company has 2 accounts- one is a development account and the other is the production account. There are 20 people on the development account who now need various levels of access provided to them on the production account. 10 of them need read-only access to all resources on the production account, 5 of them need read/write access to EC2 resources, and the remaining 5 only need read-only access to S3 buckets. Which of the following options would be the best way for both practically and security-wise to accomplish this task? <br></p><p>Choose the correct answer from the below options:</p> | <p>会社には2つのアカウントがあります.1つは開発アカウントで、もう1つは運用アカウントです。開発アカウントには、プロダクションアカウントでさまざまなレベルのアクセスが必要な20人のユーザーがいます。それらのうち10個は本番アカウント上のすべてのリソースへの読み取り専用アクセスを必要とし、5個はEC2リソースへの読み取り/書き込みアクセスが必要で、残りの5個はS3バケットへの読み取り専用アクセスのみが必要です。このタスクを達成するために、実質的にもセキュリティでも、次のオプションのどれが最良の方法でしょうか？<br> </p> <p>以下のオプションから正解を選んでください：</p>	sa:	Create 3 roles in the production account with a different policy for each of the access levels needed. Add permissions to each IAM User on the developer account based on the type of access needed. <br>  プロダクションアカウントでは、必要なアクセスレベルごとに異なるポリシーで3つのロールを作成します。必要なアクセスの種類に基づいて、開発者アカウントの各IAMユーザーにアクセス許可を追加します。|<p><br></p><p>Option A is CORRECT because it creates 3 roles according to the need inside the production account and adds the permissions to each of the IAM User in development account to assume those roles accordingly.</p><p>Option B is incorrect because you should be creating IAM Roles in the production account and the development users should assume those roles. This option is suggesting to create 3 separate users in production account which is incorrect.</p><p>Option C is incorrect because creation of encryption keys is totally unnecessary and will not work in this scenario.</p><p>Option D is incorrect because creation of the IAM user accounts in the production account is unnecessary. You should be creating IAM Roles instead.</p><p><br></p><p>For more information on "Delegating Access Across AWS Accounts Using IAM Role" - please refer to the below link:</p><p><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html" target="_blank">https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html</a><br></p><p></p><br><p></p>	Create 3 new users on the production account with the various levels of permissions needed. Give each of the 20 users the login for whichever one of the 3 users they need depending on the level of access required. <br>  プロダクションアカウントに3人の新規ユーザーを作成し、必要な権限レベルを設定します。必要なアクセスレベルに応じて、必要な3人のユーザーのうち、20人のユーザーのそれぞれにログインを与えます。	Create encryption keys for each of the resources that need access and provide those keys to each user depending on the access required. <br>  アクセスが必要なリソースごとに暗号化キーを作成し、必要なアクセスに応じてそれらのキーを各ユーザーに提供します。	Copy the 20 users IAM accounts from the development account to the production account. Then change the access levels for each user on the production account. <br>  20ユーザーのIAMアカウントを開発アカウントから運用アカウントにコピーします。その後、本番アカウントの各ユーザーのアクセスレベルを変更します。
Test4-24. <p>A user has created a mobile application which makes calls to DynamoDB to fetch certain data. The application is using the DynamoDB SDK and root account access/secret access key to connect to DynamoDB from mobile. Which of the below-mentioned statements is true with respect to the best practice for security in this scenario?</p> | <p> DynamoDBを呼び出して特定のデータを取得するモバイルアプリケーションを作成しました。アプリケーションは、DynamoDB SDKとrootアカウントのアクセス/秘密のアクセスキーを使用して、モバイルからDynamoDBに接続しています。このシナリオでのセキュリティのベストプラクティスに関して、下記のステートメントのどれが当てはまるのですか？</p>	sa:	The application should use an IAM role with web identity federation which validates calls to DynamoDB with identity providers, such as Google, Amazon, and Facebook. <br>  アプリケーションは、Google、Amazon、FacebookなどのIDプロバイダを使用してDynamoDBへの呼び出しを検証するWeb IDフェデレーションでIAMロールを使用する必要があります。|<p><br></p><p>Option A is incorrect because creating a separate user for each application user is not a feasible, secure, and recommended solution.</p><p><span style="font-size: 1rem;">Option B is incorrect because the mobile users may not all be AWS users. You need to give access to the mobile application via federated identity provider.</span></p><p><span style="font-size: 1rem;">Option C is CORRECT because it creates a role for Federated Users which enables the users to sign in to the app using their Amazon, Facebook, or Google identity and authorize them to seamlessly access DynamoDB.</span></p><p><span style="font-size: 1rem;">Option D is incorrect because creating IAM Role is not sufficient. You need to authenticate the users of the application via web identity provider, then get the temporary credentials via a Security Token Service (STS) and then access DynamoDB.</span></p><p><br></p><p><b>More information on Web Identity Federation:</b></p><p><span style="font-size: 1rem;">With Web Identity Federation, you don't need to create custom sign-in code or manage your own user identities. Instead, users of your app can sign in using a well-known identity provider (IdP) —such as Login with Amazon, Facebook, Google, or any other OpenID Connect (OIDC)-compatible IdP, receive an authentication token, and then exchange that token for temporary security credentials in AWS that map to an IAM role with permissions to use the resources in your AWS account.</span></p><p><br></p><p><span style="font-size: 1rem;">For more information on Web Identity Federation, please visit the link</span></p><p><span style="font-size: 1rem;"><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html" target="_blank">http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html</a></span></p><p><br></p><p></p>	The user should create an IAM role with DynamoDB and EC2 access. Attach the role with EC2 and route all calls from the mobile through EC2. <br>  ユーザーは、DynamoDBおよびEC2アクセスを使用してIAMロールを作成する必要があります。EC2でロールを添付し、モバイルからのすべてのコールをEC2にルーティングします。	The user should create a separate IAM user for each mobile application and provide DynamoDB access with it. <br>  ユーザーは、モバイルアプリケーションごとに個別のIAMユーザーを作成し、DynamoDBにそのアプリケーションにアクセスする必要があります。	Create an IAM Role with DynamoDB access and attach it with the mobile application. <br>  DynamoDBアクセスを使用してIAMロールを作成し、モバイルアプリケーションに添付します。
Test4-25. <p>A user has launched an EC2 instance store-backed instance in the us-east-1a zone. The user created AMI #1 and copied it to the eu-west-1 region. After that, the user made a few updates to the application running in the us-east-1a zone. The user makes an AMI #2 after the changes. If the user launches a new instance in Europe from the AMI #1 copy, which of the below-mentioned statements is true?</p> | <p>ユーザーがus-east-1aゾーンにEC2インスタンスストアを使用したインスタンスを起動しました。ユーザーはAMI＃1を作成し、それをeu-west-1領域にコピーしました。その後、ユーザーはus-east-1aゾーンで実行されているアプリケーションを少し更新しました。ユーザは、変更後にAMI＃2を作成する。ユーザーがAMI＃1のコピーからヨーロッパの新しいインスタンスを起動した場合、以下のステートメントのどちらが当てはまりますか？</p>	sa:	The new instance in the eu-west-1 region will not have the changes made after the AMI copy. <br>  eu-west-1地域の新しいインスタンスは、AMIコピー後に変更されません。|<p><br></p><p>Option A is incorrect because (a) the changes made to the instance will not automatically get updated in the AMI in US-East-1, and (b) the already copied AMI will not have any reference to the AMI in the US-East-1 region.</p><p><span style="font-size: 1rem;">Option B is incorrect because AWS does not automatically update the AMIs. It needs to be done manually.</span></p><p><span style="font-size: 1rem;">Option C is incorrect because you can copy the instance store AMI between different regions.</span></p><p><span style="font-size: 1rem;">Option D is CORRECT because the instance in the EU region will not have any changes made after copying the AMI. You will need to copy the AMI#2 to eu-west-1 and then launch the instance again to have all the changes.</span></p><p><br></p><p><span style="font-size: 1rem;">For the entire details to copy AMI’s, please visit the link –</span></p><p><span style="font-size: 1rem;"><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html" target="_blank">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html</a><br></span></p><p><br></p><ul></ul><p></p>	The new instance will have the changes made after the AMI copy since AWS keeps updating the AMI. <br>  新しいインスタンスは、AWSがAMIを更新し続けるので、AMIコピー後に変更が加えられます。	It is not possible to copy the instance store backed AMI from one region to another. <br>  1つのリージョンから別のリージョンにバックアップされたインスタンス・ストアのAMIをコピーすることはできません。	The new instance will have the changes made after the AMI copy as AWS just copies the reference of the original AMI during the copying. Thus, the copied AMI will have all the updated data. <br>  新しいインスタンスは、AWSがコピー中に元のAMIの参照をコピーするだけなので、AMIコピー後に変更が加えられます。したがって、コピーされたAMIは、すべての更新されたデータを有することになる。
Test4-26. <p>A user has created a VPC with the public and private subnets using the VPC wizard. The VPC has CIDR 20.0.0.0/16. The public subnet uses CIDR 20.0.1.0/24. The user is planning to host a web server in the public subnet with port 80 and a Database server in the private subnet with port 3306. The user is configuring a security group for the public subnet (WebSecGrp) and the private subnet (DBSecGrp). Which of the below-mentioned entries is required in the private subnet database security group DBSecGrp?</p> | <p>ユーザーは、VPCウィザードを使用してパブリックサブネットとプライベートサブネットを持つVPCを作成しました。VPCのCIDRは20.0.0.0/16です。パブリックサブネットはCIDR 20.0.1.0/24を使用します。ユーザーは、パブリックサブネット（WebSecGrp）とプライベートサブネット（DBSecGrp）のセキュリティグループを構成しています。ポート80を使用してパブリックサブネットにWebサーバーを、プライベートサブネットにデータベースサーバーをホストする予定です。プライベートサブネットデータベースセキュリティグループDBSecGrpには、以下のエントリのどれが必要ですか？</p>	sa:	Allow Inbound on port 3306 for the source Web Server Security Group WebSecGrp. <br>  ソースWebサーバーセキュリティグループWebSecGrpのポート3306の受信を許可する。|<p><br></p><p>The important point in this question is to allow the incoming traffic to the private subnet on port 3306 only for the instances in the private subnet.</p><p><br></p><p><span style="font-size: 1rem;">Option A is CORRECT because (a) it allows the inbound traffic only for the required port 3306, and (b) it allows only the traffic from the instances in the public subnet (WebSecGrp).</span></p><p><span style="font-size: 1rem;">Option B is incorrect because it is allowing the inbound traffic to all the instances in the VPC which is not the requirement.</span></p><p><span style="font-size: 1rem;">Option C is incorrect because defining outbound traffic will not ensure the incoming traffic from the public subnet. Also, since the security groups are stateful, you just need to define the inbound traffic for the public subnet only (WebSecGrp). The outbound traffic would be automatically allowed.</span></p><p><span style="font-size: 1rem;">Option D is incorrect because you do not need to open the port 80 in this case.</span></p><p><br></p><p><span style="font-size: 1rem;"><b>More information on Web Server and DB Server Security Group settings:</b></span></p><p><span style="font-size: 1rem;">Since the Web server needs to talk to the database server on port 3306 that means that the database server should allow incoming traffic on port 3306. The below table from the AWS documentation shows how the security groups should be set up.</span></p><p><img src="https://s3.amazonaws.com/awssap/4_26_1.png" alt="" width="628" height="357" role="presentation" class="img-responsive atto_image_button_text-bottom"><br></p><p><br></p><p>For more information on security groups please visit the below link</p><p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario2.html" target="_blank">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario2.html</a><br></p><p><br></p><ul></ul><p></p>	Allow Inbound on port 3306 from source 20.0.0.0/16. <br>  送信元20.0.0.0/16からのポート3306の受信を許可します。	Allow Outbound on port 3306 for destination Web Server Security Group WebSecGrp. <br>  宛先WebサーバーセキュリティグループWebSecGrpのポート3306の送信を許可します。	Allow Outbound on port 80 for destination NAT instance IP. <br>  宛先NATインスタンスIPのポート80での送信を許可します。
Test4-27. <p>An organization (Account ID 123412341234). has attached the below-mentioned IAM policy to a user. What does this policy statement entitle the user to perform?</p><p>{</p><p>&nbsp;&nbsp; “Version”: “2012-10-17”,</p><p>&nbsp;&nbsp;&nbsp; “Statement”: [{</p><p>&nbsp;&nbsp;&nbsp; “Sid”: “AllowUsersAllActionsForCredentials”,</p><p>&nbsp;&nbsp;&nbsp; “Effect”: “Allow”,</p><p>&nbsp;&nbsp;&nbsp; “Action”: [</p><p>&nbsp;&nbsp;&nbsp; “iam:*LoginProfile”,</p><p>&nbsp;&nbsp;&nbsp; “iam:*AccessKey*”,</p><p>&nbsp;&nbsp;&nbsp; “iam:*SigningCertificate*”</p><p>],</p><p>&nbsp;&nbsp; “Resource”: [“arn:aws:iam::123412341234:user/${aws:username}”]</p><p>&nbsp;} ]</p><p>}</p> | <p>組織（アカウントID 123412341234）。下記のIAMポリシーをユーザに添付しています。このポリシー声明では、ユーザーに実行権限が与えられますか？</p> <p> {</p> <p>＆nbsp; "バージョン"： "2012-10-17"、</p> <p>＆nbsp;＆nbsp;＆nbsp; "声明"：[{</p> <p>＆nbsp;＆nbsp;＆nbsp; "Sid"： "AllowUsersAllActionsForCredentials"、</p> <p>＆nbsp;＆nbsp;＆nbsp; "効果"： "許可"、</p> <p>＆nbsp;＆nbsp;＆nbsp; "アクション"：[</p> <p>＆nbsp;＆nbsp;＆nbsp; "iam：* LoginProfile"、</p> <p>＆nbsp;＆nbsp;＆nbsp; "iam：* AccessKey *"、</p> <p>＆nbsp;＆nbsp;＆nbsp; "iam：* SigningCertificate *" </p> <p>]、</p> <p>＆nbsp;＆nbsp; "リソース"：["arn：aws：iam ::	sa:	The policy allows the user to modify the IAM user’s password, sign in certificates and access keys only. <br>  このポリシーにより、ユーザーはIAMユーザーのパスワードを変更し、サインイン証明書とアクセスキーのみを変更できます。|<p><br></p><p>First, in order to give a user a certain set of policies, you need to mention the following line. The aws:username will apply to the AWS logged in user.</p><p>Resource": "arn:aws:iam::<i>account-id-without-hyphens</i>:user/${aws:username}</p><p>Next, the policies will give the permissions to modify the IAM user’s password, sign in certificates and access keys&nbsp;</p><p>“iam:*LoginProfile”,</p><p>“iam:*AccessKey*”,</p><p>“iam:*SigningCertificate*”</p><p>&nbsp;</p><p>For information on IAM security policies, please visit the link:</p><p></p><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html</a><br><br><p></p>	The policy will give an invalid resource error. <br>  ポリシーによって無効なリソースエラーが発生します。	The policy allows the IAM user to modify all credentials using only the console. <br>  このポリシーにより、IAMユーザーはコンソールのみを使用してすべての資格情報を変更できます。	The policy allows the IAM user to modify all IAM user’s credentials using the console, SDK, CLI or APIs. <br>  このポリシーにより、IAMユーザーは、コンソール、SDK、CLI、またはAPIを使用して、すべてのIAMユーザーの資格情報を変更できます。
Test4-28. <p>You have an Auto Scaling group associated with an Elastic Load Balancer (ELB). You have noticed that instances launched via the Auto Scaling group are being marked unhealthy due to an ELB health check, but these unhealthy instances are not being terminated. What do you need to do to ensure trial instances marked unhealthy by the ELB will be terminated and replaced?</p> | <p> Elastic Load Balancer（ELB）に関連付けられたAuto Scalingグループがあります。Auto Scalingグループを介して起動されたインスタンスは、ELBのヘルスチェックのために不健康にマークされていますが、これらの不健全なインスタンスは終了していません。ELBによって健康でないとされた試行のインスタンスが終了され、置き換えられるようにするためには、何をする必要がありますか？</p>	sa:	Add an Elastic Load Balancing health check to your Auto Scaling group. <br>  Auto ScalingグループにElastic Load Balancingヘルスチェックを追加します。|<p><br></p><p>To discover the availability of your EC2 instances, an ELB periodically sends pings, attempts connections, or sends requests to test the EC2 instances. These tests are called health checks. The status of the instances that are healthy at the time of the health check is InService. The status of any instances that are unhealthy at the time of the health check is OutOfService.</p><p><br></p><p>When you allow the Auto Scaling group (ASG) to receive the traffic from the ELB, it gets notified when the instance becomes unhealthy and then it terminates it. See the images in the "More information..." section for more details.</p><p><br></p><p><span style="font-size: 1rem;">Option A is incorrect because changing the threshold will not enable ASG to know about the unhealthy instances.</span></p><p><span style="font-size: 1rem;">Option B is CORRECT because when you associate the ELB with ASG, you allow the ASG to receive the traffic from that ELB. As a result, the ASG will get aware about the unhealthy instances and it terminates them.</span></p><p><span style="font-size: 1rem;">Option C is incorrect because increasing the interval will still not communicate the information about the unhealthy instances to the ASG.</span></p><p><span style="font-size: 1rem;">Option D is incorrect because this setting will not communicate the information about the unhealthy instances to the ASG either.</span></p><p><br></p><p>More information on ELB with Auto Scaling Group:</p><p><img src="https://s3.amazonaws.com/awssap/4_28_1.png" alt="" width="612" height="482" role="presentation" class="img-responsive atto_image_button_text-bottom"><br></p><p><img src="https://s3.amazonaws.com/awssap/4_28_2.png" alt="" width="1097" height="792" role="presentation" class="img-responsive atto_image_button_text-bottom"><br></p><p><br></p><p>For more information on ELB, please visit the below URL:</p><p><a href="https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-load-balancer.html" target="_blank">https://docs.aws.amazon.com/autoscaling/ec2/userguide/autoscaling-load-balancer.html</a><br></p><p><br></p><ul></ul><p></p>	Change the thresholds set on the Auto Scaling group health check. <br>  自動スケーリンググループヘルスチェックで設定したしきい値を変更します。	Increase the value for the Health check interval set on the Elastic Load Balancer. <br>  Elastic Load Balancerで設定されたヘルスチェック間隔の値を増やします。	Change the health check set on the Elastic Load Balancer to use TCP rather than HTTP checks. <br>  HTTP検査ではなくTCPを使用するようにElastic Load Balancerで設定されたヘルスチェックを変更します。
Test4-29. <p>You have two Elastic Compute Cloud (EC2) instances inside a Virtual Private Cloud (VPC) in the same Availability Zone (AZ) but in different subnets. One instance is running a database and the other instance an application that will interface with the database. You want to confirm that they can talk to each other for your application to work properly. Which two things do we need to confirm in the VPC settings so that these EC2 instances can communicate inside the VPC?</p><p>Choose 2 answers from the below options:</p> | <p>同一の可用性ゾーン（AZ）内の異なるサブネットにある仮想プライベートクラウド（VPC）内に2つのEC2インスタンスがあります。1つのインスタンスはデータベースを実行し、もう1つのインスタンスはデータベースとインターフェースするアプリケーションです。アプリケーションが正しく動作するためには、お互いに話すことができるかどうかを確認する必要があります。これらのEC2インスタンスがVPC内で通信できるように、VPC設定で確認する必要があるのはどちらですか？</p> <p>以下のオプションから2つの回答を選択してください：</p>	ma:	o:A network ACL that allows communication between the two subnets. <br>  2つのサブネット間の通信を可能にするネットワークACL。|<p><br></p><p>In order to have the instances communicate with each other, you need to properly configure both Security Group and Network access control lists (NACLs). For the exam, remember that Security Group operates at the instance level; where as, the NACL operates at subnet level.</p><p><br></p><p>Option A is CORRECT because the security groups must be defined in order to allow web server to communicate with the database server. An example image from the AWS documentation is given below:</p><p><img src="https://s3.amazonaws.com/awssap/4_29_1.png" alt="" role="presentation" class="img-responsive atto_image_button_text-bottom" height="369" width="462"></p><p>Option B is incorrect because it is not necessary to have the two instances of the same type or be using same key-pair.</p><p><span style="font-size: 1rem;">Option C incorrect is because configuring NAT instance or NAT gateway will not enable the two servers to communicate with each other. NAT instance/NAT gateway are used to enable the communication between instances in the private subnets and internet.</span></p><p><span style="font-size: 1rem;">Option D is CORRECT because the two servers are in two separate subnets. In order for them to communicate with each other, you need to have the NACL’s configured as shown below:</span></p><p><span style="font-size: 1rem;"><br></span></p><p>&nbsp;<img src="https://s3.amazonaws.com/awssap/4_29_2.png" alt="" role="presentation" class="img-responsive atto_image_button_text-bottom" height="445" width="398"></p><p><br></p><p>For more information on VPC and Subnets, please visit the below URL</p><p></p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html</a><br><p></p>	x:Both instances are the same instance class and using the same Key-pair. <br>  両方のインスタンスが同じインスタンスクラスで、同じキーペアを使用しています。	x:That the default route is set to a NAT instance or internet Gateway (IGW) for them to communicate. <br>  既定のルートがNATインスタンスまたはインターネットゲートウェイ（IGW）に設定されて通信すること。	o:Security groups are set to allow the application host to talk to the database on the right port/protocol. <br>  セキュリティグループは、アプリケーションホストが正しいポート/プロトコルでデータベースと通信できるように設定されています。
Test4-30. <p>Your team is excited about the use of AWS because now they have access to "programmable Infrastructure”. You have been asked to manage your AWS infrastructure In a manner similar to the way you might manage application code You want to be able to deploy exact copies of different versions of your infrastructure, stage changes into different environments, revert back to previous versions, and identify what versions are running at any particular time (development test QA . production). Which approach addresses this requirement?</p> | <p>あなたのチームは、「プログラム可能なインフラストラクチャ」にアクセスできるようになり、AWSの使用に興奮しています。あなたはAWSインフラストラクチャの管理を依頼されています。インフラストラクチャの異なるバージョンの正確なコピーを展開し、さまざまな環境に変更を加え、以前のバージョンに戻し、特定の時点で実行されているバージョンを特定します（開発テストQA生産）。	sa:	Use AWS CloudFormation and a version control system like GIT to deploy and manage your infrastructure. <br>  AWS CloudFormationとGITなどのバージョン管理システムを使用して、インフラストラクチャを導入および管理します。|<p><br></p><p>You can use AWS Cloud Formation’s sample templates or create your own templates to describe the AWS resources, and any associated dependencies or runtime parameters, required to run your application. You don’t need to figure out the order for provisioning AWS services or the subtleties of making those dependencies work. CloudFormation takes care of this for you. After the AWS resources are deployed, you can modify and update them in a controlled and predictable way, in effect applying version control to your AWS infrastructure the same way you do with your software. You can also visualize your templates as diagrams and edit them using a drag-and-drop interface with the AWS CloudFormation Designer.</p><p><br></p><p><span style="font-size: 1rem;">Option A is incorrect because Cost Allocation Reports is not helpful for the purpose of the question.</span></p><p><span style="font-size: 1rem;">Option B is incorrect because CloudWatch is used for monitoring the metrics pertaining to different AWS resources.</span></p><p><span style="font-size: 1rem;">Option C is incorrect because it does not have the concept of programmable Infrastructure.</span></p><p><span style="font-size: 1rem;">Option D is CORRECT because AWS CloudFormation gives developers and systems administrators an easy way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion.</span></p><p><br></p><p>For more information on CloudFormation, please visit the link:</p><p><a href="https://aws.amazon.com/cloudformation/" target="_blank">https://aws.amazon.com/cloudformation/</a><br></p><p><br></p><ul></ul><p></p>	Use AWS CloudWatch metrics and alerts along with resource tagging to deploy and manage your infrastructure. <br>  AWS CloudWatchのメトリックとアラートをリソースタギングとともに使用して、インフラストラクチャを導入および管理します。	Use AWS Beanstalk and a version control system like GIT to deploy and manage your infrastructure. <br>  AWS BeanstalkとGITのようなバージョン管理システムを使用して、インフラストラクチャを展開および管理します。	Use cost allocation reports and AWS Opsworks to deploy and manage your infrastructure. <br>  コスト割り当てレポートとAWS Opsworkを使用して、インフラストラクチャを展開および管理します。
Test4-31. <p>What are some of the best practices when managing permissions for OpsWork?</p><p>Choose 3 answers from the below options:<br></p> | <p> OpsWorkのアクセス許可を管理する際のベストプラクティスは何ですか？</p> <p>以下のオプションから3つの回答を選択します：<br> </p>	ma:	o:Create IAM User for each of your users and attach policies that provide appropriate access. <br>  ユーザーごとにIAMユーザーを作成し、適切なアクセスを提供するポリシーを添付します。|<p><br></p><p>Option A is CORRECT because instead of using root credentials, it is a better practice is to create an IAM User with appropriate policies attached to it.</p><p>Option B is incorrect because using the root account credentials is not a secure and recommended practice.</p><p>Option C is CORRECT because developers should not have access to stacks pertaining to any other applications than the ones they should be working on.</p><p>Option D is CORRECT because users should have access to only those resources that pertain to the application they are working on.</p><p>&nbsp;</p><p>For more information on OpsWork best practices, please visit the link –</p><p></p><a href="http://docs.aws.amazon.com/opsworks/latest/userguide/best-practices-permissions.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/opsworks/latest/userguide/best-practices-permissions.html</a><br><p></p>	x:Use the root account for managing the resources attached to OpsWork. <br>  OpsWorkに接続されたリソースを管理するためにrootアカウントを使用します。	o:Application developers need to access only the stacks that run their applications. <br>  アプリケーション開発者は、アプリケーションを実行するスタックにのみアクセスする必要があります。	o:Users should only have access permission to the resources they need as part of the OpsWork stack. <br>  ユーザーは、OpsWorkスタックの一部として必要なリソースへのアクセス権のみを持つ必要があります。
Test4-32. <p>Which of the following are best practices that need to be followed when updating Opswork stack instances with the latest security patches?</p><p>Choose 2 correct options from the below:<br></p> | <p> Opsworkスタックインスタンスを最新のセキュリティパッチで更新する際に実行する必要があるベストプラクティスはどれですか？</p> <p>以下の2つの正しいオプションを選択してください：<br> </p>	ma:	o:Create and start new instances to replace your current online instances. <br>  新しいインスタンスを作成して起動し、現在のオンラインインスタンスを置き換えます。|<p><br></p><p>The best practices for updating your OpsWork stacks instances with the latest security patches:</p> <ul><li>Create and start new instances to replace your current online instances. Then delete the current instances.&nbsp;<span style="font-size: 1rem;">The new instances will have the latest set of security patches installed during setup.</span></li><li>On Linux-based instances in Chef 11.10 or older stacks, run the Update Dependencies stack command&nbsp;<span style="font-size: 1rem;">which installs the current set of security patches and other updates on the specified instances.</span></li> </ul>  <p>&nbsp;</p><p>For more information on OpsWork Linux security updates best practices, please visit the link –</p><p><a href="https://docs.aws.amazon.com/opsworks/latest/userguide/workingsecurity-updates.html" target="_blank">https://docs.aws.amazon.com/opsworks/latest/userguide/workingsecurity-updates.html</a><br></p><br><p></p>	o:run the Update Dependencies stack command for Linux based instances. <br>  Linuxベースのインスタンスに対してUpdate Dependenciesスタックコマンドを実行します。	x:Delete the entire stack and create a new one. <br>  スタック全体を削除して新しいスタックを作成します。	x:Use Cloudformation to deploy the security patches. <br>  雲の情報を使用してセキュリティパッチを展開します。
Test4-33. <p>While managing your instances in the current Opswork stack, you suddenly started getting the following error:</p><p>ws::CharlieInstanceService::Errors::UnrecognizedClientException - The security token included in the request is invalid.</p><p>Which of the below 2 check can be done to rectify this error?</p><p><br></p> | <p>現在のOpsworkスタックでインスタンスを管理しているうちに、突然次のエラーが発生しました。 ws :: CharlieInstanceService :: Errors :: UnrecognizedClientException  - リクエストに含まれるセキュリティトークンが無効です</p><p>このエラーを修正するために、以下の2つのチェックのどちらを実行できますか？</p> <p> <br> </p>	ma:	o:Check the IAM role which was attached to the instance. <br>  インスタンスに接続されているIAMの役割を確認します。|<p><br></p><p>This can occur if a resource outside AWS OpsWorks on which the instance depends was edited or deleted. The following are examples of resource changes that can break communications with an instance.</p> <ul> <li>An IAM user or role associated with the instance has been deleted accidentally, outside of AWS OpsWorks Stacks. This causes a communication failure between the AWS OpsWorks agent that is installed on the instance and the AWS OpsWorks Stacks service. The IAM user that is associated with an instance is required throughout the life of the instance.</li> <li>Editing volume or storage configurations while an instance is offline can make an instance unmanageable.</li> <li>Adding EC2 instances to an EIP manually. AWS OpsWorks reconfigures an assigned Elastic Load Balancing load balancer each time an instance enters or leaves the online state. AWS OpsWorks only considers instances it knows about to be valid members; instances that are added outside of AWS OpsWorks, or by some other process, are removed. Every other instance is removed.</li> </ul> <p>&nbsp;</p><p>For more information on troubleshooting Opswork, please visit the link:</p><p></p><a href="http://docs.aws.amazon.com/opsworks/latest/userguide/common-issues-troubleshoot.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/opsworks/latest/userguide/common-issues-troubleshoot.html</a><br><br><p></p>	o:Check if the EIP have been added to the EC2 instances manually. <br>  EIPがEC2インスタンスに手動で追加されているかどうかを確認します。	x:Check if the stack is configured properly. <br>  スタックが正しく構成されているかどうかを確認します。	x:Check if the Opswork client is configured properly. <br>  Opsworkクライアントが正しく設定されているかどうかを確認します。
Test4-34. <p>There is a requirement for an application hosted on AWS to work with DynamoDB tables. Which of the following is the best option for the application hosted on an EC2 instance to work with the data in the DynamoDB table? Choose the correct answer from the below options.</p> | <p> AWSにホストされているアプリケーションでDynamoDBテーブルを操作する必要があります。DynamoDBテーブルのデータを操作するために、EC2インスタンスでホストされるアプリケーションに最適なオプションはどれですか？以下のオプションから正解を選んでください。</p>	sa:	Create an IAM role with the proper permission policy to communicate with the DynamoDB table. Use web identity federation, which assumes the IAM role using AssumeRoleWithWebIdentity. when the user signs in, granting temporary security credentials using STS. <br>  適切なアクセス権ポリシーを使用してIAMロールを作成し、DynamoDBテーブルと通信します。AssumeRoleWithWebIdentityを使用してIAMロールを使用するWeb IDフェデレーションを使用します。ユーザーがサインインすると、STSを使用して一時的なセキュリティ資格情報を付与します。|<p><br></p><p>Option A is incorrect because IAM Roles are preferred over IAM Users, because IAM Users have to access the AWS resources using access and secret keys, which is a security concern.</p><p><span style="font-size: 1rem;">Option B is this is not a feasible configuration.</span></p><p><span style="font-size: 1rem;">Option C is CORRECT because it (a) creates an IAM Role with the needed permissions to connect to DynamoDB, (b) it authenticates the users with Web Identity Federation, and (c) the application accesses the DynamoDB with temporary credentials that are given by STS.</span></p><p><span style="font-size: 1rem;">Option D is incorrect because the step to create the Active Directory (AD) server and using AD for authenticating is unnecessary and costly.</span></p><p><span style="font-size: 1rem;"><br></span></p><p><span style="font-size: 1rem;">See the image below for more information on AssumeRoleWithWebIdentity API.</span></p><p><img src="https://s3.amazonaws.com/awssap/4_34_1.png" alt="" width="638" height="359" role="presentation" class="img-responsive atto_image_button_text-bottom"><br></p><p><br></p><p>For more information on web identity federation please refer to the below link:</p><p><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html" target="_blank">http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html</a><br></p><p><br></p><ul></ul><p></p>	Create an IAM group that only gives access to your application and to the DynamoDB tables. Then, when writing to DynamoDB, simply include the unique device ID to associate the data with that specific user. <br>  アプリケーションとDynamoDBテーブルにのみアクセスできるIAMグループを作成します。次に、DynamoDBに書き込むときは、固有のデバイスIDを指定して、その特定のユーザーとデータを関連付けるだけです。	Create an IAM user and assign the IAM user to a group with proper permissions to communicate with DynamoDB. <br>  IAMユーザーを作成し、DynamoDBと通信するための適切な権限を持つグループにIAMユーザーを割り当てます。	Create an Active Directory server and an AD user for each mobile application user. When the user signs in to the AD sign-on, allow the AD server to federate using SAML 2.0 to IAM and assign a role to the AD user which is the assumed with AssumeRoleWithSAML. <br>  モバイルアプリケーションユーザーごとにActive DirectoryサーバーとADユーザーを作成します。ユーザーがADサインオンにサインインすると、ADサーバーはSAML 2.0を使用してIAMにフェデレートし、AssumeRoleWithSAMLで想定されているADユーザーに役割を割り当てます。
Test4-35. <p>Your fortune 500 company has undertaken a TCO analysis evaluating the use of Amazon S3 versus acquiring more hardware. The outcome was that all employees would be granted access to use Amazon S3 for storage of their personal documents. Which of the following will you need to consider so you can set up a solution that incorporates single sign-on from your corporate AD or LDAP directory and restricts access for each user to a designated user folder in a bucket?</p><p><br></p><p>Choose 3 options from the below:</p> | <p>あなたのFortune 500企業は、Amazon S3の使用と、より多くのハードウェアの購入を評価するTCO分析を実施しました。その結果、すべての従業員に、Amazon S3を使用して個人用ドキュメントを保管するためのアクセス権が付与されました。企業のADディレクトリまたはLDAPディレクトリからのシングルサインオンを組み込んだソリューションを設定し、各ユーザーのアクセスをバケット内の指定されたユーザーフォルダに限定するソリューションを設定できるよう、次のうちどれを検討する必要がありますか？</p> <p > <br> </p> <p>下記の3つのオプションを選択してください：</p>	ma:	o:Setting up a federation proxy or identity provider. <br>  フェデレーションプロキシまたはアイデンティティプロバイダを設定する。|<p><br></p><p>In questions like this where an application, or user needs to be given access using Single Sign On (SSO), following steps are very important:</p><p><span style="font-size: 1rem;">(i) setting up a identity provider for federated access</span></p><p><span style="font-size: 1rem;">(ii) authenticating users using corporate data store / active directory-user-attributes/</span></p><p><span style="font-size: 1rem;">(iii) getting temporary access tokens / credentials using AWS STS</span></p><p><span style="font-size: 1rem;">(iv) creating the IAM Role that has the access to the needed AWS Resources</span></p><p><br></p><p>Option A is CORRECT because as mentioned above, setting up a identity provider for federated access is needed.</p><p><span style="font-size: 1rem;">Option B is CORRECT because as mentioned above, getting temporary access tokens / credentials using AWS STS is needed.</span></p><p><span style="font-size: 1rem;">Option C is incorrect because tagging each folder in bucket does not help in this scenario.</span></p><p><span style="font-size: 1rem;">Option D is CORRECT because as mentioned above, creating the IAM Role that has the access to the needed AWS Resources is needed.</span></p><p><span style="font-size: 1rem;">Option E is incorrect because you should be creating IAM Roles rather than IAM Users.&nbsp;</span></p><p><br></p><p>The diagram below showcases how authentication is carried out when having an identity broker. This is an example of a SAML connection , but the same concept holds true for getting access to an AWS resource.</p><p><span style="font-size: 1rem;">&nbsp;</span><img src="https://s3.amazonaws.com/awssap/4_35_1.png" alt="" role="presentation" class="img-responsive atto_image_button_text-bottom" height="380" width="765" style="font-size: 1rem;"></p><p><br></p><p>For more information on federated access, please visit the below link</p><p></p><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_federated-users.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_federated-users.html</a><br><br><p></p>	o:Using AWS Security Token Service to generate temporary tokens. <br>  AWSセキュリティトークンサービスを使用して一時的なトークンを生成する。	x:Tagging each folder in the bucket. <br>  バケット内の各フォルダにタグを付けます。	o:Configuring IAM role. <br>  IAMロールの設定。	x:Setting up a matching IAM user for every user in your corporate directory that needs access to a folder in the bucket. <br>  バケット内のフォルダにアクセスする必要のある社内ディレクトリ内のすべてのユーザーに対して、一致するIAMユーザーを設定します。
Test4-36. <p>Your company is running a website on EC2 instances deployed across multiple Availability Zones with a Multi-AZ RDS MySQL Extra Large DB Instance. The site performs a high number of small reads and writes per second and relies on an eventual consistency model. After comprehensive tests, you discover that there is read contention on RDS MySQL. Which are the best approaches to meet these requirements?</p><p>Choose 2 answers from the below options:</p> | <p>貴社では、複数のAZゾーンのRDS MySQL Extra Large DBインスタンスを使用して複数の可用性ゾーンに展開されたEC2インスタンスでWebサイトを実行しています。このサイトは、毎秒の読み取りと書き込みの回数が非常に多く、最終的な一貫性モデルに依存しています。包括的なテストが終わったら、RDS MySQLに関する読解競合があることがわかります。これらの要件を満たすための最良の方法はどれですか？</p> <p>以下のオプションから2つの回答を選択してください：</p>	ma:	o:Deploy ElasticCache in-memory cache running in each availability zone. <br>  各可用性ゾーンで実行中のElasticCacheインメモリキャッシュをデプロイします。|<p><br></p><p>The main point to note in this question is that there is a read contention on RDS MySQL. Your should be looking for the options which will improve upon the "read" contention issues. Hint: Always see if any of the options contain (1) caching solution such as ElastiCache, (2) CloudFront, or (3) Read Replicas.&nbsp;</p><p><br></p><p>Option A is CORRECT because ElastiCache is a in-memory caching solution which reduces the load on the database and improves the read performance.</p><p><span style="font-size: 1rem;">Option B is incorrect because sharding does not improve read performance; however, it improves write performance, but write contention is not the issue here.</span></p><p><span style="font-size: 1rem;">Option C is incorrect because improving the instance size may improve the read performance, but only up to a specific limit. It is not a reliable solution.</span></p><p><span style="font-size: 1rem;">Option D is CORRECT because Read Replicas are used to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. Hence, improving the read performance.</span></p><p><br></p><p>See more information on Read Replicas and ElastiCache below.</p><p><span style="font-size: 1rem;"><b><br></b></span></p><p><span style="font-size: 1rem;"><b>Read Replicas</b></span></p><p><span style="font-size: 1rem;">Amazon RDS Read Replicas provide enhanced performance and durability for database (DB) instances. This replication feature makes it easy to elastically scale out beyond the capacity constraints of a single DB Instance for read-heavy database workloads. You can create one or more replicas of a given source DB Instance and serve high-volume application read traffic from multiple copies of your data, thereby increasing aggregate read throughput.</span></p><p><span style="font-size: 1rem;">For more information on Read Replica’s, please visit the below link:</span></p><p><span style="font-size: 1rem;"><a href="https://aws.amazon.com/rds/details/read-replicas/" target="_blank">https://aws.amazon.com/rds/details/read-replicas/</a></span></p><p><b><br></b></p><p><b>ElastiCache</b></p><p><span style="font-size: 1rem;">Amazon ElastiCache is a web service that makes it easy to deploy, operate, and scale an in-memory data store or cache in the cloud. The service improves the performance of web applications by allowing you to retrieve information from fast, managed, in-memory data stores, instead of relying entirely on slower disk-based databases.&nbsp;</span></p><p><span style="font-size: 1rem;">For more information on Amazon ElastiCache, please visit the below link:</span></p><p><span style="font-size: 1rem;"><a href="https://aws.amazon.com/elasticache/" target="_blank">https://aws.amazon.com/elasticache/</a></span></p><p><br></p><ul></ul><p></p>	x:Implement sharding to distribute load to multiple RDS MySQL instances. <br>  複数のRDS MySQLインスタンスに負荷を分散するシャーディングを実装します。	x:Increase the RDS MySQL Instance size and Implement provisioned IOPS. <br>  RDS MySQLインスタンスサイズを大きくし、プロビジョニングされたIOPSを実装します。	o:Add an RDS MySQL read replica in each availability zone. <br>  各可用性ゾーンにRDS MySQL読み取りレプリカを追加します。
Test4-37. <p>A company is running a batch analysis every hour on their main transactional DB running on an RDS MySQL instance to populate their central Data Warehouse running on Redshift. During the execution of the batch, their transactional applications are very slow. When the batch completes they need to update the top management dashboard with the new data. The dashboard is produced by another system running on-premises that is currently started when a manually-sent email notifies that an update is required. The on-premises system cannot be modified because is managed by another team.</p><p>How would you optimize this scenario to solve performance issues and automate the process as much as possible?</p> |  <p>ある会社は、RDS MySQLインスタンス上で稼動するメインのトランザクションDBで1時間ごとにバッチ分析を実行して、Redshiftで稼働する中央データウェアハウスにデータを移入します。 バッチの実行中、トランザクションアプリケーションは非常に遅いです。 バッチが完了すると、トップマネジメントダッシュボードを新しいデータで更新する必要があります。 ダッシュボードは、手動で送信された電子メールで更新が必要であることが通知されたときに現在開始されているオンプレミスを実行している別のシステムによって生成されます。 </ p> <p>このシナリオを最適化してパフォーマンスの問題を解決し、できるだけプロセスを自動化するにはどうすればよいでしょうか。</p>	sa:	Create an RDS Read Replica for the batch analysis and SNS to notify the on-premises system to update the dashboard. <br>  バッチ分析用にRDS読み取りレプリカを作成し、オンプレミスシステムにダッシュボードを更新するように通知するSNSを作成します。|<p><br></p><p>There are two architectural considerations here. (1) you need to improve read performance by reducing the load on the RDS MySQL instance, and (2) automate the process of notifying to the on-premise system.</p><p><span style="font-size: 1rem;">When the scenario asks you to improve the read performance of a DB instance, always look for options such as ElastiCache or Read Replicas. And when the question asks you to automate the notification process, always think of using SNS.&nbsp;</span></p><p><br></p><p>Option A is incorrect because Redshift is used for OLAP scenarios whereas RDS is used for OLTP scenarios. Hence, replacing RDS with Redshift is not a solution.&nbsp;</p><p><span style="font-size: 1rem;">Option B is incorrect because Redshift is used for OLAP scenarios whereas RDS is used for OLTP scenarios. Hence, replacing RDS with Redshift is not a solution.</span></p><p><span style="font-size: 1rem;">Option C is CORRECT because (a) it uses Read Replicas which improves the read performance, and (b) it uses SNS which automates the process of notifying the on-premise system to update the dashboard.</span></p><p><span style="font-size: 1rem;">Option D is incorrect because SQS is not a service to be used for sending the notification.</span></p><p><br></p><p>For more information on Read Replica’s, please visit the below link</p><p></p><a href="https://aws.amazon.com/rds/details/read-replicas/" target="_blank" style="font-size: 1rem;">https://aws.amazon.com/rds/details/read-replicas/</a><br><br><p></p>	Replace RDS with Redshift for the batch analysis and SQS to send a message to the on-premises system to update the dashboard. <br>  バッチ分析でRDSをRedshiftに、SQSを使用してオンプレミスシステムにメッセージを送信してダッシュボードを更新します。	Replace RDS with Redshift for the batch analysis and SNS to notify the on-premises system to update the dashboard. <br>  バッチ分析とSNSでRDSをRedshiftに置き換えて、オンプレミスシステムにダッシュボードを更新するように通知します。	Create an RDS Read Replica for the batch analysis and SQS to send a message to the on-premises system to update the dashboard. <br>  バッチ分析用にRDS読み取りレプリカを作成し、オンプレミスシステムにメッセージを送信してダッシュボードを更新するSQSを作成します。
Test4-38. <p>How can you ensure the scalability of the application developed in Java interfacing with DynamoDB to reduce the load on the DynamoDB database? <br></p><p>Choose an answer from the below options:<br></p> | <p> DynamoDBデータベースへの負荷を軽減するためにJavaで開発されたアプリケーションのスケーラビリティをDynamoDBでどのように確保できますか？<br> </p> <p>以下のオプションから回答を選択します：<br> </p>	sa:	Use SQS to hold the database requests instead of overloading the DynamoDB database. Then have a service that asynchronously pull the messages and write them to DynamoDB. <br>  SQSを使用して、DynamoDBデータベースのオーバーロードではなく、データベース要求を保持します。次に、メッセージを非同期にプルしてDynamoDBに書き込むサービスを用意します。|<p><br></p><p>This question is asking for an option that can be used to reduce the load on DynamoDB database. The option has to be scalable.</p><p><span style="font-size: 1rem;">In such scenario, the best option to use is SQS, because it is scalable and cost efficient as well.</span></p><p><br></p><p><span style="font-size: 1rem;">Option A is incorrect because adding more databases is not going to reduce the load on existing DynamoDB database. Also, this is not a cost efficient solution.</span></p><p><span style="font-size: 1rem;">Option B is incorrect because increasing the write capacity is an expensive option.</span></p><p><span style="font-size: 1rem;">Option C is CORRECT because it uses SQS to assist in taking over the load from storing the data in DynamoDB, and it is scalable as well as cost efficient.</span></p><p><span style="font-size: 1rem;">Option D is incorrect because MultiAZ configuration is not going to help reduce the load, in fact it will affect the performance as the records in DynamoDB would get replicated in multiple availability zones.</span></p><p><br></p><p><b>More information on SQS:</b></p><p><span style="font-size: 1rem;">When the idea comes for scalability then SQS is the best option. Normally DynamoDB is scalable, but since one is looking for a cost effective solution, the messaging in SQS can assist in managing the situation mentioned in the question.</span></p><p><span style="font-size: 1rem;">Amazon Simple Queue Service (SQS) is a fully-managed message queuing service for reliably communicating among distributed software components and microservices - at any scale. Building applications from individual components that each perform a discrete function improves scalability and reliability, and is best practice design for modern applications. SQS makes it simple and cost-effective to decouple and coordinate the components of a cloud application. Using SQS, you can send, store, and receive messages between software components at any volume, without losing messages or requiring other services to be always available</span></p><p><br></p><p><span style="font-size: 1rem;">For more information on SQS, please refer to the below URL:</span></p><a href="https://aws.amazon.com/sqs/" target="_blank" style="font-size: 1rem;">https://aws.amazon.com/sqs/</a><br><br> <p></p>	Increase write capacity of Dynamo DB to meet the peak loads. <br>  ピーク負荷を満たすためにDynamo DBの書き込み容量を増やします。	Add more DynamoDB databases to handle the load. <br>  DynamoDBデータベースを追加して負荷を処理します。	Launch DynamoDB in Multi-AZ configuration with a global index to balance writes. <br>  グローバルインデックスを使用して複数のAZ構成でDynamoDBを起動し、書き込みのバランスをとります。
Test4-39. <p>Which of the following HTTP methods are supported by Amazon CloudFront?</p><p>Choose 3 options from the below:</p> | <p> Amazon CloudFrontでサポートされている次のHTTPメソッドはどれですか？</p> <p>以下の3つのオプションを選択してください：</p>	ma:	o:GET <br>  GET|<p><br></p><p>Amazon CloudFront supports the following HTTP methods: GET, HEAD, POST, PUT, DELETE, OPTIONS, and PATCH. This means you can improve the performance of dynamic websites that have web forms, comment, and login boxes, “add to cart” buttons or other features that upload data from end users.</p><p><br></p><p>For more information on CloudFront Dynamic content, please refer to the below URL:<br></p><a href="https://aws.amazon.com/cloudfront/dynamic-content/" target="_blank" style="font-size: 1rem;">https://aws.amazon.com/cloudfront/dynamic-content/</a><br><br> <p></p>	o:POST <br>  または：POST	o:DELETE <br>  または：DELETE	x:UPDATE <br>  UPDATE
Test4-40. <p>What are some of the common types of content that are supported by a web distribution via CloudFront?</p><p>Choose 3 options from the below:</p> | <p> CloudFront経由のWeb配信でサポートされている一般的なコンテンツの種類は何ですか？</p> <p>以下の3つのオプションを選択してください：</p>	ma:	o:Static content <br>  静的コンテンツ|<p><br></p><p>You can use web distributions to serve the following content over HTTP or HTTPS:</p> <ul> <li>Static and dynamic download content, for example, .html, .css, .php, and image files, using HTTP or HTTPS.</li> <li>Multimedia content on demand using progressive download and Apple HTTP Live Streaming (HLS).&nbsp;</li><li>A live event, such as a meeting, conference, or concert, in real time. For live streaming, you create the distribution automatically by using an AWS CloudFormation Stack.</li></ul> <p>Hence, options A, B, and C are CORRECT.</p><p><br></p><p>For more information on CloudFront distribution, please refer to the below URL:<br></p><a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-overview.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-overview.html</a><br><br> <p></p>	o:Live events <br>  ライブイベント	o:Multimedia content <br>  マルチメディアコンテンツ	x:Peer to peer networking <br>  ピアツーピアネットワーク
Test4-41. <p>A client is using CloudFront with a source which normally serves dynamic content. There is a requirement that as soon the content is changed in the source, it is delivered to the client. Which of the following configuration can be made to fulfill this requirement?</p> | <p>クライアントは通常、動的コンテンツを提供するソースとともにCloudFrontを使用しています。ソースでコンテンツが変更されるとすぐに、クライアントに配信されるという要件があります。この要件を満たすためにどのような構成が可能なのですか？</p>	sa:	Set TTL to 0 seconds. <br>  TTLを0秒に設定します。|<p><br></p><p>In CloudFront, to enforce the delivery of content to the user as soon as it gets changed by the origin, the time to live (TTL) should be set to 0.</p><p><span style="font-size: 1rem;"><br></span></p><p><span style="font-size: 1rem;">Option A is incorrect because invalidate is used to remove the content from CloudFront edge locations cache before it expires. The next time a viewer requests the object, CloudFront fetches the content from the origin; whereas, setting TTL to 0 enforces CloudFront to deliver the latest content as soon as origin updates it.</span></p><p><span style="font-size: 1rem;">Option B is incorrect because setting TTL to 10 will keep the content in cache for some time even though origin updates it.</span></p><p><span style="font-size: 1rem;">Option C is CORRECT because setting TTL to 0 will enforce the delivery of content to the user as soon as it gets changed by the origin.</span></p><p><span style="font-size: 1rem;">Option D is incorrect as CloudFront surely serves dynamic content.</span></p><p><span style="font-size: 1rem;">Option E is incorrect as you do not have to contact AWS support center for this scenario.</span></p><p><br></p><p><b>More information on TTL in CloudFront:</b></p><p><span style="font-size: 1rem;">You can control how long your objects stay in a CloudFront cache before CloudFront forwards another request to your origin. Reducing the duration allows you to serve dynamic content. The low TTL is also given in the AWS documentation.</span></p><p><span style="font-size: 1rem;">&nbsp;</span><img src="https://s3.amazonaws.com/awssap/4_41_1.png" alt="" role="presentation" class="img-responsive atto_image_button_text-bottom" height="152" width="766" style="font-size: 1rem;"></p><p><br></p><p>For more information on CloudFront dynamic content, please refer to the below URL:<br></p><a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html</a><br><br> <p></p>	Set TTL to 10 seconds. <br>  TTLを10秒に設定します。	Use fast invalidate feature provided in CloudFront. <br>  CloudFrontで提供される高速無効化機能を使用します。	Dynamic content cannot be served from the CloudFront. <br>  動的コンテンツをCloudFrontから配信することはできません。	You have to contact AWS support center to enable this feature. <br>  この機能を有効にするには、AWSサポートセンターに連絡する必要があります。
Test4-42. <p><span id="docs-internal-guid-846a0cce-556c-441e-66f0-b8886f8edbbc">You are responsible for a web application that consists of an Elastic Load Balancer (ELB) in front of an Auto Scaling group of Amazon Elastic Compute Cloud (EC2) instances. For a recent deployment of a new version of the application, a new Amazon Machine Image (AMI) was created, and the Auto Scaling group was updated with a new launch configuration that refers to this new AMI. During the deployment, you received complaints from users that the website was responding with errors. All instances passed the ELB health checks. What should you do in order to avoid errors for future deployments? (Choose 2 answers) </span></p> | <span id = "docs-internal-guid-846a0cce-556c-441e-66f0-b8886f8edbbc">あなたは、Auto Scalingグループの前にElastic Load Balancer（ELB）で構成されたWebアプリケーションを担当しています。 Amazon Elastic Compute Cloud（EC2）インスタンス。最近のアプリケーションの新しいバージョンの展開では、新しいAmazon Machine Image（AMI）が作成され、Auto Scalingグループがこの新しいAMIを参照する新しい起動設定で更新されました。展開中に、Webサイトがエラーで応答しているという苦情がユーザーから届きました。すべてのインスタンスがELBヘルスチェックをパスしました。今後の展開でエラーが発生しないようにするにはどうすればよいですか？（2つの回答を選択）</ span> </p>	ma:	x:Add an Elastic Load Balancing health check to the Auto Scaling group. Set a short period for the health checks to operate as soon as possible in order to prevent premature registration of the instance to the load balancer. <br>  Elastic Load BalancingヘルスチェックをAuto Scalingグループに追加します。ロードバランサへのインスタンスの早期登録を防止するため、ヘルスチェックができるだけ早く動作するように短期間を設定します。|<br><p dir="ltr" style="">In this scenario, the ELB health check was passed which implies that the instances were successfully deployed using the new AMIs by the launch configuration and auto scaling group. The deployment was successful, but as the users started using the application, they started receiving the error. So, it implies that the errors are related to the application itself, not the setup.</p><br><p dir="ltr" style="">Option A is incorrect because setting the short period of health check will not be useful in this scenario.</p><p dir="ltr" style="">Option B is incorrect because you cannot change the launch configuration based on the CloudWatch alert.</p><p dir="ltr" style="">Option C is CORRECT because, the current health check might be just checking if the application/web site is reachable or not. I.e. It may not be currently checking whether the application is fully functioning. If the health check is configured to test the part of the application that fully tests it, it would stop deploying the instances with the faulty application.</p><p dir="ltr" style="">Option D is CORRECT because doubling the auto scaling size will give some lead time for instances to become healthy while the AMI with old update gets terminated (kind of Blue/Green Deployment).</p><p dir="ltr" style="">Option E is incorrect because increasing the unhealthy threshold will not help in this scenario since it does not prevent unhealthy instances from being deployed.</p></span><br><br> <p></p>	x:Enable EC2 instance CloudWatch alerts to change the launch configuration AMI to the previous one. Gradually terminate instances that are using the new AMI. <br>  EC2インスタンスのCloudWatchアラートを有効にして、起動構成AMIを前のものに変更します。新しいAMIを使用しているインスタンスを徐々に終了します。	o:Set the Elastic Load Balancing health check configuration to target a part of the application that fully tests application health and returns an error if the tests fail. <br>  Elastic Load Balancingのヘルスチェック構成を設定して、アプリケーションの正常性を完全にテストするアプリケーションの一部を対象とし、テストが失敗した場合はエラーを返します。	o:Create a new launch configuration that refers to the new AMI, and associate it with the group. Double the size of the group, wait for the new instances to become healthy, and reduce back to the original size. If new instances do not become healthy, associate the previous launch configuration. <br>  新しいAMIを参照する新しい起動構成を作成し、それをグループに関連付けます。グループのサイズを倍にして、新しいインスタンスが正常になるのを待って元のサイズに戻します。新しいインスタンスが正常にならない場合は、以前の起動設定を関連付けます。	x:Increase the Elastic Load Balancing Unhealthy Threshold to a higher value to prevent an unhealthy instance from going into service behind the load balancer. <br>  Elastic Load Balancing不健全しきい値を高くして、不健全なインスタンスがロードバランサの背後で動作しないようにします。
Test4-43. <p></p><span id="docs-internal-guid-846a0cce-310f-4a17-dcf2-3e2b6aec2f89"><p dir="ltr" style="">You have deployed a web application targeting a global audience across multiple AWS Regions under the domain name example.com. You decide to use Route53 Latency-Based Routing to serve web requests to the users from the region closest to them. To provide business continuity in the event of server downtime you configure weighted record sets associated with two web servers in separate Availability Zones per region.</p><p dir="ltr" style="">During a DR test you notice that when you disable all web servers in one of the regions Route53 does not automatically direct all users to the other region. What could be happening? (Choose 2 answers)</p></span><br><p></p> | <p dir = "ltr" style = "">ドメイン名example.comのもとで、複数のAWSリージョンにまたがってグローバルなオーディエンスをターゲットにしたWebアプリケーションをデプロイしました。 Route53 Latency-Based Routingを使用して、ユーザーに最も近い地域からのWeb要求を処理します。 <p dir = "ltr" style = "">サーバーのダウンタイムが発生した場合にビジネス継続性を提供するには、2つのWebサーバーに関連付けられた加重レコードセットをリージョンごとに別々の可用性ゾーンに構成します。 地域のいずれかですべてのWebサーバーを無効にすると、Route53は自動的にすべてのユーザーを他の地域に誘導しません。 何が起こっているのでしょうか？ （2つの回答を選択）</p> </ span> <br>	ma:	x:Latency resource record sets cannot be used in combination with weighted resource record sets. <br>  レイテンシリソースレコードセットは、重み付きリソースレコードセットと組み合わせて使用​​することはできません。|<br><p dir="ltr" style="">Option A is incorrect because you can setup weighted record sets as the failover or secondary record set.</p><p dir="ltr" style="">Option B is CORRECT because if the HTTP health check is not set with the weighted resource record sets of the disabled web servers, Route 53 will consider them healthy, and will continue to forward the traffic to them. Once the health check is enabled, the DNS queries will get a response indicating that the web servers are disabled, and then the requests would get routed to the other region.</p><p dir="ltr" style="">Option C is incorrect because even if the weight is lower for the region with disabled web servers, Route 53 will continue forwarding the requests of the users closest to that region because it will evaluate the latency record set first.</p><p dir="ltr" style="">Option D is incorrect because, even if one of the servers fail, the other server will still work and the traffic should get the traffic.</p><p dir="ltr" style="">Option E is CORRECT because if the “Evaluate Target Health” is not set to “Yes” for the region containing the disabled web servers, the Route 53 will consider the health of the record set as healthy and will continue to route the traffic to it.</p><br><p dir="ltr" style="">For more information on How Amazon Route 53 chooses records when Health Checking is configured, please visit the link below:</p></span><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/health-checks-how-route-53-chooses-records.html" target="_blank">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/health-checks-how-route-53-chooses-records.html</a><br><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html#dns-failover-complex-configs-eth-no" target="_blank">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html#dns-failover-complex-configs-eth-no</a><br><br><p></p>	o:You did not setup an HTTP health check to one or more of the weighted resource record sets associated with the disabled web servers. <br>  無効なWebサーバーに関連付けられている1つ以上の重み付きリソースレコードセットにHTTPヘルスチェックを設定していません。	x:The value of the weight associated with the latency alias resource record set in the region with the disabled servers is higher than the weight for the other region. <br>  無効なサーバーがある領域で設定されたレイテンシエイリアスリソースレコードに関連付けられた重みの値が、他の領域の重みよりも大きい。	x:One of the two working web servers in the other region did not pass its HTTP health check. <br>  他の地域の2つの稼働中のWebサーバの1つがHTTPヘルスチェックをパスしなかった。	o:You did not set “Evaluate Target Health” to “Yes” on the latency alias resource record set associated with example.com in the region where you disabled the servers. <br>  サーバーを無効にした地域のexample.comに関連付けられたレイテンシエイリアスリソースレコードセットで、「評価対象の正常性」を「はい」に設定していませんでした。
Test4-44. <p>A company is in the evaluation phase of deploying a Redshift cluster. Which of the following types of instances should the company think of deploying for their Redshift cluster during this phase? <br></p><p>Choose an answer from the options given below:</p> | <p> Redshiftクラスタを導入する評価段階にあります。この段階でRedshiftクラスタに導入すると考えられるのは、次のタイプのインスタンスのどれですか？<br> </p> <p>下記のオプションから回答を選択します：</p>	sa:	On-Demand <br>  オンデマンド|<p><br></p><p>Option A is incorrect because if the instances are reserved, the company would be in a contract for paying for the instances irrespective whether they utilize all the instances or only some of them.</p><p>Option B is CORRECT because in<span style="font-size: 1rem;">&nbsp;the evaluation phase of your project or when you’re developing a proof of concept, on-demand pricing gives you the flexibility to pay as you go, to pay only for what you use, and to stop paying at any time by shutting down or deleting clusters. After you have established the needs of your production environment and begin the implementation phase, you may consider reserving compute nodes by purchasing one or more offerings.</span></p><p><span style="font-size: 1rem;">Option C is incorrect because even though the spot instances are cheapest, they involve in risk of shutting down with a very short notice and the price depends upon their current availability. Also, spot instances are recommended only if the application is tolerant of interruptions.</span></p><p><span style="font-size: 1rem;">Option D is incorrect because as mentioned above, the reserved instances may not be the best choice since there is no mention of the duration of the evaluation period, and the spot instances cannot be used since there is no mention of the company or its application being tolerant of the interruption risk that are associated with purchasing the spot instances.</span></p><p><span style="font-size: 1rem;"><br></span></p><p><span style="font-size: 1rem;">For more information on the type of instances to choose for the Redshift cluster please refer to the below URL:</span></p><p></p><a href="http://docs.aws.amazon.com/redshift/latest/mgmt/purchase-reserved-node-instance.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/redshift/latest/mgmt/purchase-reserved-node-instance.html</a><br><br><p></p>	Reserved instances because they are cost effective <br>  予約されたインスタンスは費用効果が高いため	Spot Instances because they are the least cost option <br>  スポットインスタンスはコストが最も低いオプションであるため	Combination of all 3 types of instances <br>  3つのタイプすべてのインスタンスの組み合わせ
Test4-45. <p>There is a requirement for a high availability and disaster recovery plan for an organization.</p><p>Below are the key points for this plan</p><ul><li>Once stored successfully,&nbsp; the data should not be lost.&nbsp;This is the key requirement.</li><li>Recovery time can be long as this could save on cost.</li></ul><p>&nbsp;Which of the following options would be the best one for this corporation, given the concerns that they have outlined to you above? <br></p><p>Choose the correct answer from the below options:<br></p> | <p>組織の高可用性と災害復旧計画の要件があります。</p> <p>この計画のポイントは以下のとおりです。</p> <ul> <li> </ li> <li>リカバリ時間がかかるため、コストを削減できます。</ li> <p>＆nbsp;上記のような懸念を抱いて、この法人にとって最良の選択肢は次のとおりです。<br> </p> <p>以下のオプションから正解を選択します：<br> </p>	sa:	Backup and restoring with S3 should be considered due to the low cost of S3 storage. Backup up frequently and the data can be sent to S3 using either Direct Connect or Storage Gateway, or over the Internet. <br>  S3でのバックアップと復元は、S3ストレージの低コストのために考慮する必要があります。頻繁にバックアップを取ってください。データは、Direct ConnectまたはStorage Gatewayを使用して、またはインターネット経由でS3に送信できます。|<p><br></p><p>Option A is incorrect because it can help in maintaining data, but is not low on cost and is a high-cost option since you need to maintain a multi-AZ environment. Hence we need to count this option out.</p><p>Option B is incorrect because it does not talk about data loss avoidance and is more of network avoidance.</p><p>Option C is CORRECT because S3 provides durable, highly available, low cost and more secure storage solution.</p><p>Option D is incorrect because it talks about AMI’s but not about the underlying data on EBS storage which will need to be backed up.</p><p><br></p><p><b>More information about Amazon S3:</b></p><p>Amazon S3 is storage for the Internet. It’s a simple storage service that offers software developers a highly-scalable, reliable, and low-latency data storage infrastructure at very low costs.</p><p><br></p><p>For more information on S3 please refer to the below link</p><p></p><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html</a><br><br><p></p>	Set up a number of smaller instances in a different region, which all have Auto Scaling and Elastic Load Balancing enabled. If there is a network outage, then these instances will auto scale up. As long as spot instances are used and the instances are small this should remain a cost effective solution. <br>  異なる領域にいくつかの小さなインスタンスを設定します。これらのインスタンスは、すべて自動スケーリングとエラスティックロードバランスが有効になっています。ネットワークが停止している場合、これらのインスタンスは自動的にスケールアップされます。スポットインスタンスが使用され、インスタンスが小さい限り、これは費用対効果の高いソリューションのままでなければなりません。	Make sure you have RDS set up as an asynchronous Multi-AZ deployment, which automatically provisions and maintains an asynchronous “standby” replica in a different Availability Zone. <br>  異なるアベイラビリティゾーンに非同期の「スタンバイ」レプリカを自動的にプロビジョニングして管理する非同期マルチAZ配備としてRDSを設定していることを確認してください。	Set up pre-configured servers using Amazon Machine Images. Use an Elastic IP and Route 53 to quickly switch over to your new infrastructure if there are any problems when you run your health checks. <br>  Amazon Machine Imageを使用して事前設定済みのサーバーを設定します。Elastic IPとRoute 53を使用して、ヘルスチェックを実行するときに問題が発生した場合は、新しいインフラストラクチャにすばやく切り替えることができます。
Test4-46. <p>Your company would be assigning an auditor that would view all the logs of your AWS environment. <br></p><p>Which of the below option would be the best solution for the auditor to ensure that they can view the logs in the AWS environment?</p> | <p>あなたの会社は、AWS環境のすべてのログを表示する監査人を割り当てます。<br> </p> <p>監査人がAWS環境でログを閲覧できるようにするには、以下のうちどれが最適なソリューションですか？</p>	sa:	Enable CloudTrail logging and create an IAM user who has read-only permissions to the required AWS resources, including the bucket containing the CloudTrail logs. <br>  CloudTrailログを有効にし、CloudTrailログを含むバケットを含む、必要なAWSリソースへの読み取り専用アクセス権を持つIAMユーザーを作成します。|<p><br></p><p>Option A is incorrect because just creating a role in not sufficient. CloudTrail logging needs to be enabled as well.</p><p><span style="font-size: 1rem;">Option B is incorrect because sending the logs via email is not a good architecture.</span></p><p><span style="font-size: 1rem;">Option C is incorrect because granting the auditor access to AWS resources is not AWS's responsibility. It is the AWS user or account owner's responsibility.</span></p><p><span style="font-size: 1rem;">Option D is CORRECT because you need to enable the CloudTrail logging in order to generate the logs with information about all the activities related to the AWS account and resources. It also creates an IAM user that has permissions to read the logs that are stored in the S3 bucket.</span></p><p><br></p><p><b>More information on AWS CloudTrail:</b></p><p><span style="font-size: 1rem;">AWS CloudTrail is a service that enables governance, compliance, operational auditing, and risk auditing of your AWS account. With CloudTrail, you can log, continuously monitor, and retain events related to API calls across your AWS infrastructure. CloudTrail provides a history of AWS API calls for your account, including API calls made through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. This history simplifies security analysis, resource change tracking, and troubleshooting.</span></p><p><br></p><p>For more information on CloudTrail, please visit the below URL:</p><p></p><a href="https://aws.amazon.com/cloudtrail/" target="_blank" style="font-size: 1rem;">https://aws.amazon.com/cloudtrail/</a><br><br><p></p>	Create an SNS notification that sends the CloudTrail log files to the auditor's email when CloudTrail delivers the logs to S3, but do not allow the auditor access to the AWS environment. <br>  CloudTrailがS3にログを配信するが、監査人がAWS環境にアクセスすることを許可していないときに、CloudTrailログファイルを監査人の電子メールに送信するSNS通知を作成する。	The company should contact AWS as part of the shared responsibility model, and AWS will grant required access to the third-party auditor. <br>  会社は共有責任モデルの一環としてAWSに連絡し、AWSは第三者監査人に必要なアクセス権を付与します。	Create a role that has the required permissions for the auditor. <br>  監査人に必要な権限を持つ役割を作成します。
Test4-47. <p>A company has setup a Direct Connect connection between their on-premise location and their AWS VPC. They want to setup redundancy in case the Direct Connect connection fails. What can they do in this regard?</p><p>Choose 2 options from the below:<br></p> | <p>企業では、社内のロケーションとAWS VPCの間にダイレクトコネクト接続を設定しています。ダイレクトコネクトの接続が失敗した場合に備えて、冗長性を設定する必要があります。この点で何ができますか？</p> <p>以下の2つのオプションを選択してください：<br> </p>	ma:	o:Setup another Direct Connect connection. <br>  別のダイレクトコネクト接続をセットアップします。|<p><br></p><p>Option A and B are CORRECT because with A, you can have a redundant Direct Connect setup as a backup if the main Direct Connect connection fails (even though it is an expensive solution, it will work), and with B, VPN is an alternate way for the connection between AWS and on-premises infrastructure (even though it is a slower connectivity, it will work).</p><p><br></p><p><b>More information on Direct Connect:</b></p><p>If you have established a second AWS Direct Connect connection, traffic will failover to the second link automatically. We recommend enabling Bidirectional Forwarding Detection (BFD) when configuring your connections to ensure fast detection and failover. If you have configured a backup IPsec VPN connection instead, all VPC traffic will failover to the VPN connection automatically. Traffic to/from public resources such as Amazon S3 will be routed over the Internet. If you do not have a backup AWS Direct Connect link or an IPSec VPN link, then Amazon VPC traffic will be dropped in the event of a failure. Traffic to/from public resources will be routed over the Internet.</p><p><br></p><p>For more information on Direct Connect FAQ’s, please visit the below URL:</p><p></p><a href="https://aws.amazon.com/directconnect/faqs/" target="_blank" style="font-size: 1rem;">https://aws.amazon.com/directconnect/faqs/</a><br><br><p></p>	o:Setup an IPSec VPN Connection. <br>  IPSec VPN接続をセットアップします。	x:Setup S3 connection. <br>  セットアップS3接続。	x:Setup a connection via EC2 instances. <br>  EC2インスタンス経由で接続を設定します。
Test4-48. <p><span id="docs-internal-guid-846a0cce-3113-4fa3-814b-898748f72360">Your company is storing millions of sensitive transactions across thousands of 100-GB files that must be encrypted in-transit and at-rest. Analysts concurrently depend on subsets of files, which can consume up to 5 TB of space, to generate simulations that can be used to steer business decisions. You are required to design an AWS solution that can cost effectively accommodate the long-term storage and in-flight subsets of data. Which one would you choose?&nbsp;</span></p> | あなたの会社は、100 GBの何千ものファイルに何百万もの重要なトランザクションを格納しています。これらのファイルは、輸送中や休憩中に暗号化する必要があります。 アナリストは同時に、ファイルのサブセットに依存します。ファイルのサブセットは、最大5 TBのスペースを消費し、ビジネス上の意思決定を助けるためのシミュレーションを生成します。 長期間のストレージおよび飛行中のデータサブセットに費用対効果の高いAWSソリューションを設計する必要があります。 どちらを選択しますか？ </ span> </p>	sa:	Use HDFS on Amazon Elastic MapReduce (EMR), and run simulations on subsets in-memory on Amazon Elastic Compute Cloud (EC2). <br>  Amazon Elastic MapReduce（EMR）でHDFSを使用し、Amazon Elastic Compute Cloud（EC2）のメモリ内のサブセットでシミュレーションを実行します。|<br><p dir="ltr" style="">The main considerations of this scenario are: (1) the solution must be cost-effective, (2) provide long-term storage, and (3) encrypt in-transit as well as at-rest data.</p><br><p dir="ltr" style="">Option A is incorrect because, (a) server side encryption does not apply to in-transit data, and (b) ephemeral volumes are not encrypted at rest.</p><p dir="ltr" style="">Option B is incorrect because, it does not support encryption of in-transit data.</p><p dir="ltr" style="">Option C is incorrect because, ephemeral drive is not a long term storage.</p><p dir="ltr" style="">Option D is CORRECT because, (a) EMR supports both in-transit and at-rest data encryption, and (b) HDFS provides the long term storage.</p><p dir="ltr" style="">Option E is incorrect because, this is not a cost-effective solution.</p><br><p dir="ltr" style="">For more information on EMR, please visit the link below:</p></span><a href="https://aws.amazon.com/blogs/aws/new-at-rest-and-in-transit-encryption-for-amazon-emr/" target="_blank">https://aws.amazon.com/blogs/aws/new-at-rest-and-in-transit-encryption-for-amazon-emr/</a><br><a href="https://d0.awsstatic.com/whitepapers/aws-amazon-emr-best-practices.pdf" target="_blank">https://d0.awsstatic.com/whitepapers/aws-amazon-emr-best-practices.pdf</a><br><br><p></p>	Use Amazon S3 with server-side encryption, and run simulations on subsets in-memory on Amazon EC2. <br>  サーバー側の暗号化でAmazon S3を使用し、Amazon EC2のメモリ内のサブセットでシミュレーションを実行します。	Use HDFS on Amazon EMR, and run simulations on subsets in ephemeral drives on Amazon EC2. <br>  Amazon EC2でHDFSを使用し、Amazon EC2の一時ドライブ内のサブセットでシミュレーションを実行します。	Use Amazon Simple Storage Service (S3) with server-side encryption, and run simulations on subsets in ephemeral drives on Amazon EC2. <br>  Amazon Simple Storage Service（S3）をサーバー側の暗号化で使用し、Amazon EC2の一時ドライブのサブセットでシミュレーションを実行します。	Store the full data set in encrypted Amazon Elastic Block Store (EBS) volumes, and regularly capture snapshots that can be cloned to EC2 workstations. <br>  暗号化されたAmazon Elastic Block Store（EBS）ボリュームに完全なデータセットを格納し、定期的にEC 2ワークステーションに複製できるスナップショットを取得します。
Test4-49. <p>As an IT administrator, you have been tasked to ensure that SQL injection attacks are kept at bay.&nbsp; You currently maintain a set of applications hosted on AWS which consists of a fleet of EC2 instances. Which of the below approach provides a cost-effective scalable mitigation to this kind of attack?</p> | <p> IT管理者は、SQLインジェクション攻撃が確実に行われないようにする必要があります。＆nbsp; 現在、AWSにホストされている一連のアプリケーションを管理しています。これらのアプリケーションは、EC2インスタンス群から構成されています。以下のアプローチのどれが、この種の攻撃に対する費用効果の高いスケーラブルな軽減策ですか？</p>	sa:	Add a WAF tier by creating a new ELB and an AutoScaling group of EC2 Instances running a host-based WAF. They would redirect Route 53 to resolve to the new WAF tier ELB. The WAF tier would pass the traffic to the current web tier. The web tier Security Groups would be updated to only allow traffic from the WAF tier Security Group. <br>  ホストベースのWAFを実行している新しいELBと自動スケーリンググループのEC2インスタンスを作成して、WAF層を追加します。彼らはRoute 53を新しいWAF層ELBに解決するようにリダイレクトします。WAF層は、トラフィックを現在のWeb層に渡します。Web層セキュリティグループは、WAF層セキュリティグループからのトラフィックのみを許可するように更新されます。|<p><br></p><p>In such scenarios where you are designing a solution to prevent the DDoS attack, always think of using Web Access Firewall (WAF).</p><p><span style="font-size: 1rem;">AWS WAF is a web application firewall that helps protect your web applications from common web exploits that could affect application availability, compromise security, or consume excessive resources. AWS WAF gives you control over which traffic to allow or block to your web applications by defining customizable web security rules. You can use AWS WAF to create custom rules that block common attack patterns, such as SQL injection or cross-site scripting, and rules that are designed for your specific application. New rules can be deployed within minutes, letting you respond quickly to changing traffic patterns.&nbsp;</span></p><p><br></p><p><span style="font-size: 1rem;">Option A is incorrect because, although this option could work, the setup is very complex and it is not a cost effective solution.</span></p><p><span style="font-size: 1rem;">Option B is incorrect because, (a) even though blocking certain IPs will mitigate the risk, the attacker could maneuver the IP address and circumvent the IP check by NACL, and (b) it does not prevent the attack from the new source of threat.</span></p><p><span style="font-size: 1rem;">Option C is CORRECT because (a) WAF Tiers acts as the first line of defense, it filters out the known sources of attack and blocks common attack patterns, such as SQL injection or cross-site scripting, (b) the ELB of the application is not exposed to the attack, and most importantly (c) this pattern - known as "WAF Sandwich" pattern - has WAF layer with EC2 instances are placed between two ELBs - one that faces the web, receives all the traffic, and sends them to WAF layer to filter out the malicious requests, and sends the filtered non-malicious requests, another ELB - which receives the non-malicious requests and send them to the EC2 instances for processing. See the image below:</span></p><p><span style="font-size: 1rem;"><img src="https://s3.amazonaws.com/awssap/4_49_1.png" alt="" width="1261" height="702" role="presentation" class="img-responsive atto_image_button_text-bottom"><br></span></p><p>Option D is incorrect because there is no such thing as Advanced Protocol Filtering feature for ELB.</p><p><br></p><p><span style=""></span></p><p>For more information on WAF, please visit the below URL:</p><p><a href="https://aws.amazon.com/waf/" target="_blank">https://aws.amazon.com/waf/</a><br></p><p><br></p><p></p>	Add previously identified host file source IPs as an explicit INBOUND DENY NACL to the web tier subnet. <br>  以前に識別されたホストファイルのソースIPを明示的なINBOUND DENY NACLとしてWeb層サブネットに追加します。	Recommend that they lease space at a DirectConnect partner location and establish a 1G DirectConnect? connection to their VPC. Then they would establish Internet connectivity into their space, filter the traffic in hardware Web Application Firewall (WAF) and then pass the traffic through the DirectConnect connection into their application running in their VPC. <br>  DirectConnectパートナーの場所でスペースをリースし、1G DirectConnectを確立することを推奨しますか？VPCへの接続 その後、インターネット接続を確立し、ハードウェアWebアプリケーションファイアウォール（WAF）でトラフィックをフィルタリングし、DirectConnect接続を介してトラフィックをVPCで動作するアプリケーションに渡します。	Remove all but TLS 1 & 2 from the web tier ELB and enable Advanced Protocol Filtering. This will enable the ELB itself to perform WAF functionality. <br>  Web層ELBからTLS 1および2を除くすべてを削除し、Advanced Protocol Filteringを有効にします。これにより、ELB自体がWAF機能を実行できるようになります。
Test4-50. <p>As an IT administrator, you have been requested to manage the CloudFormation stacks for a set of developers in your company. A set of web and database developers will be working on the application. How would you design the CloudFormation stacks in the best way possible?</p> | <p> IT管理者は、企業内の一連の開発者向けにCloudFormationスタックを管理するように要求されています。Webおよびデータベース開発者のセットがアプリケーションで作業します。可能な限り最良の方法でCloudFormationスタックをどのように設計しますか？</p>	sa:	Create separate stacks for the web and database developers. <br>  Web開発者とデータベース開発者用に別々のスタックを作成します。|<p><br></p><p>Option A is incorrect because CloudFormation is best for creating and maintaining all the infrastructure resources in the cloud environment.</p><p>Option B is incorrect because as your stack grows in scale and broadens in scope, managing a single stack can be cumbersome and time consuming. Also, coordinating and communicating updates can become difficult.</p><p>Option C is CORRECT because (a) having multiple (or sub) stacks is easier to maintain, (b) there is a clear separation of ownership and concerns, (c) better chances of you staying within the limit for 'Template body size' which happens to be 460,800 bytes, and (d) you can reuse common template patterns. See "More information..." section for more details.</p><p>Option D is incorrect because you can provision and maintain the infrastructure if the CloudFormation templates are created correctly.</p><p><br></p><p><b>More information on CloudFormation Best Practices:</b></p><p>The following use case scenario is given in the AWS documentation to support the answer:</p><p>For example, imagine a team of developers and engineers who own a website that is hosted on autoscaling instances behind a load balancer. Because the website has its own lifecycle and is maintained by the website team, you can create a stack for the website and its resources. Now imagine that the website also uses back-end databases, where the databases are in a separate stack that is owned and maintained by database administrators. Whenever the website team or database team needs to update their resources, they can do so without affecting each other's stack. If all resources were in a single stack, coordinating and communicating updates can be difficult.</p><p>For more information on Cloudformation best practices, please visit the below URL</p><p></p><a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/best-practices.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/best-practices.html</a><br><br><p></p>	Create one stack for the web and database developers. <br>  Webおよびデータベース開発者向けに1つのスタックを作成します。	CloudFormation is not the right fit, use OpsWork instead. <br>  CloudFormationは適切ではありませんが、代わりにOpsWorkを使用してください。	Define separate EC2 instances since defining CloudFormation can get cumbersome. <br>  CloudFormationの定義が煩雑になる可能性があるため、別々のEC2インスタンスを定義します。
Test4-51. <p></p><span id="docs-internal-guid-846a0cce-311b-cffa-bfb0-04c8fdc3875b">You need a persistent and durable storage to trace call activity of an IVR (Interactive Voice Response) system. Call duration is mostly in the 2-3 minutes time-frame. Each traced call can be either active or terminated. An external application needs to know each minute the list of currently active calls, which are usually a few calls/second. Put once per month there is a periodic peak up to 1000 calls/second for a few hours. The system is open 24/7 and any downtime should be avoided. Historical data is periodically archived to files. Cost saving is a priority for this project. What database implementation would better fit this scenario, keeping the costs as low as possible?</span><p></p> | <p> </p> <span id = "docs-internal-guid-846a0cce-311b-cffa-bfb0-04c8fdc3875b"> IVR（Interactive Voice Response）システムのコールアクティビティを追跡するには、永続的で耐久性のあるストレージが必要です。通話時間は、ほとんどの場合、2〜3分の時間枠内です。トレースされた各コールは、アクティブまたは終了のいずれかになります。外部アプリケーションは、現在アクティブなコールのリストを毎分知る必要があります。通常は、数コール/秒です。1ヶ月に1回、定期的なピークが最大1000コール/秒で数時間送信されます。システムは24時間365日開いており、ダウンタイムは避けてください。履歴データはファイルに定期的にアーカイブされます。コスト削減はこのプロジェクトの優先事項です。このシナリオに適したデータベースの実装は、コストを可能な限り低く抑えますか？</ span> <p> </p>	sa:	Use DynamoDB with a "Calls" table and a Global Secondary Index on a "IsActive" attribute that is present for active calls only. In this way, the Global Secondary index is sparse and more effective. <br>  アクティブなコールに対してのみ存在する「IsActive」アトリビュートで、「Calls」テーブルとグローバルセカンダリインデックスを持つDynamoDBを使用します。このようにして、グローバル・セカンダリ・インデックスは疎で効果的です。|<br><p dir="ltr" style="">The important consideration in this scenario is that the application needs to know each minute the list of <b>currently active calls</b>.i.e. The application does not need to know about the terminated calls. The idea behind sparse indexes is that only items with IsActive = "Y" will be in the index, so require less storage and processing than your main table.</p><br><p dir="ltr" style="">Option A is incorrect because keeping the information about the terminated calls is not needed. So, having a table for that would not be an optimized or cost-effective solution.</p><p dir="ltr" style="">Option B is CORRECT because (a) it keeps the information about active calls via "IsActive" attribute only for the active calls, (b) it has a GSI which is optimally utilized for active calls only, keeping the use of it to minimum; hence, saving the cost, and (c) in this scenario, setting up DynamoDB is more cost saving solution than RDS.</p><p dir="ltr" style="">Option C is incorrect because (a) keeping the information about the terminated calls is not needed, and (b) setting a GSI on all items will not be an optimized and cost-effective solution.</p><p dir="ltr" style="">Option D is incorrect because (a) keeping the information about the terminated calls is not needed, and (b) in this scenario, setting up RDS is more costly solution than DynamoDB.</p><br><p dir="ltr" style="">More information on Best Practices for DynamoDB:</p></span><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/best-practices.html#GuidelinesForGSI.SparseIndexes" target="_blank">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/best-practices.html#GuidelinesForGSI.SparseIndexes</a><br><br><p></p>	Use RDS Multi-AZ with two tables, one for "Active calls" and one for "Terminated calls". In this way, the "Active calls" table is always small and effective to access. <br>  2つのテーブル、1つは「アクティブなコール」、もう1つは「終了したコール」のRDSマルチAZを使用します。このように、「アクティブコール」テーブルは常に小さく、アクセスに効果的です。	Use DynamoDB with a "Calls" table and a Global secondary Index on a "State" attribute that can equal to "active" or "terminated". In this way, the Global Secondary index can be used for all Items in the table. <br>  「アクティブ」または「終了」に等しい「状態」属性の「コール」テーブルとグローバルセカンダリインデックスを持つDynamoDBを使用します。このようにして、テーブル内のすべてのアイテムに対してグローバルセカンダリインデックスを使用できます。	Use RDS Multi-AZ with a "Calls" table and an indexed "State" field that can be equal to "Active" or "Terminated". In this way, the SQL query Is optimized by the use of the Index. <br>  「通話」テーブルと、「アクティブ」または「終了」と等しいことができる索引付けされた「状態」フィールドを持つRDSマルチAZを使用します。このようにして、SQLクエリはインデックスの使用によって最適化されます。
Test4-52. <p>A customer is hosting their company website on a cluster of web servers that are behind a public-facing load balancer. The customer also uses Amazon Route 53 to manage their public DNS. How should the customer configure the DNS zone apex record to point to the load balancer?</p> | <p>顧客は​​、パブリックに面したロードバランサの背後にあるWebサーバーのクラスタ上で、自社のWebサイトをホストしています。また、Amazon Route 53を使用してパブリックDNSを管理します。顧客がロードバランサを指すようにDNSゾーンの頂点レコードを構成する方法は？</p>	sa:	Create an A record aliased to the load balancer DNS name. <br>  ロードバランサのDNS名にエイリアスされたAレコードを作成します。|<p><br></p><p>Option A is incorrect because it suggests to create A record pointing to the IP address of the ELB; but, ELB's don't have predefined IP addresses.</p><p>Option B and C are incorrect because you should preferably create ALIAS record rather than CNAME record. See the "More information..." section for more details.</p><p>Option D is CORRECT because it creates an A record, but instead of pointing to an IP address, it ALIASES it to the DNS of the ELB.</p><p><br></p><p><b>More information on ALIAS Record:</b></p><p>Alias resource record sets are virtual records that work like CNAME records. But they differ from CNAME records in that they are not visible to resolvers. Resolvers only see the A record and the resulting IP address of the target record. As such, unlike CNAME records, alias resource record sets are available to configure a zone apex (also known as a root domain or naked domain) in a dynamic environment.</p><p><br></p><p>For more information on the zone apex, please refer to the link below:</p><p><a href="http://docs.aws.amazon.com/govcloud-us/latest/UserGuide/setting-up-route53-zoneapex-elb.html">http://docs.aws.amazon.com/govcloud-us/latest/UserGuide/setting-up-route53-zoneapex-elb.html</a></p><p>For more information on choosing between ALIAS and Non-ALIAS records, please refer to the link below:</p><p><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html?console_help=true" target="_blank">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html?console_help=true</a><br></p><p><br></p>	Create a CNAME record pointing to the load balancer DNS name. <br>  ロードバランサのDNS名を示すCNAMEレコードを作成します。	Create a CNAME record aliased to the load balancer DNS name. <br>  ロードバランサのDNS名にエイリアスされたCNAMEレコードを作成します。	Create an A record pointing to the IP address of the load balancer. <br>  ロードバランサのIPアドレスを示すAレコードを作成します。
Test4-53. <p>By default, when an EBS volume is attached to a Windows instance, it may show up as any drive letter on the instance. For which services can you use to change the settings of the drive letters of the EBS volumes per your specifications?</p> | <p>既定では、EBSボリュームがWindowsインスタンスに接続されている場合、そのインスタンス上のドライブ文字として表示されることがあります。あなたの仕様に従ってEBSボリュームのドライブ文字の設定を変更するサービスはどれですか？</p>	sa:	EC2Config Service <br>  EC2Configサービス|<p><br></p><p>Windows AMIs include an optional service called the EC2Config service (EC2Config.exe). EC2Config starts when the instance boots and performs tasks during startup and each time you stop or start the instance. EC2Config can also perform tasks on demand. Some of these tasks are automatically enabled, while others must be enabled manually. Although optional, this service provides access to advanced features that aren't otherwise available. This service runs in the LocalSystem account.</p><p><br></p><p>For more information on EC2 Config service, please visit the link</p><p></p><a href="http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/UsingConfig_WinAMI.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/UsingConfig_WinAMI.html</a><br><p></p>	AMIConfig Service <br>  AMIConfigサービス	EBSConfig Service <br>  EBSConfigサービス	EC2-AMIConfig Service <br>  EC2-AMIConfigサービス
Test4-54. <p></p><span id="docs-internal-guid-846a0cce-3122-e715-bd95-21afd08d1462">You are designing the network infrastructure for an application server in Amazon VPC. Users will access all the application instances from the Internet as well as from an on-premises network. The on-premises network is connected to your VPC over an AWS Direct Connect link. How would you design routing to meet the above requirements?</span><p></p> | </p> <span id = "docs-internal-guid-846a0cce-3122-e715-bd95-21afd08d1462"> Amazon VPCでアプリケーションサーバーのネットワークインフラストラクチャを設計しています。ユーザーは、インターネットとオンプレミスネットワークからすべてのアプリケーションインスタンスにアクセスします。オンプレミスネットワークは、AWS Direct Connectリンクを介してVPCに接続されています。どのように上記の要件を満たすためにルーティングを設計しますか？</ span> <p> </p>	sa:	Configure a single routing table with a default route via the Internet gateway. Propagate specific routes for the on-premises networks via BGP on the AWS Direct Connect customer router. Associate the routing table with all VPC subnets. <br>  インターネットゲートウェイ経由で既定のルートを使用して単一のルーティングテーブルを構成します。オンプレミスネットワークの特定のルートをBGP経由でAWS Direct Connectカスタマールータに伝播します。ルーティングテーブルをすべてのVPCサブネットに関連付けます。|<br><p dir="ltr" style="">Option A and C are incorrect because, two default routes cannot be configured in the route table.</p><p dir="ltr" style="">Option B is CORRECT because with this setup, the route via the BGP(which is specific) will be preferred over the one via Internet gateway (default).</p><p dir="ltr" style="">Option D is incorrect because the subnet in which the instances are placed, can have a single routing table associated with them.</p><br><p dir="ltr" style="">More information on Route Tables and VPN Route Priority::</p></span><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#route-tables-priority" target="_blank">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#route-tables-priority</a><br><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.html#vpn-route-priority" target="_blank">https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.html#vpn-route-priority</a><br><br><p></p>	Configure a single routing table with a default route via the Internet gateway. Propagate a default route via BGP on the AWS Direct Connect customer router. Associate the routing table with all VPC subnets. <br>  インターネットゲートウェイ経由で既定のルートを使用して単一のルーティングテーブルを構成します。AWSダイレクトコネクトカスタマールータのBGP経由でデフォルトルートを伝播します。ルーティングテーブルをすべてのVPCサブネットに関連付けます。	Configure a single routing table with two default routes: one to the Internet via an Internet gateway the other to the on-premises network via the VPN gateway. Use this routing table across all subnets in your VPC. <br>  単一のルーティングテーブルを2つのデフォルトルートで構成します.1つはインターネットゲートウェイ経由でインターネットに接続し、もう1つはVPNゲートウェイ経由で構内ネットワークに接続します。VPCのすべてのサブネットでこのルーティングテーブルを使用します。	Configure two routing tables: one that has a default route via the Internet gateway, and another that has a default route via the VPN gateway. Associate both routing tables with each VPC subnet. <br>  2つのルーティングテーブルを構成します.1つはインターネットゲートウェイ経由で既定のルートを持ち、もう1つはVPNゲートウェイ経由で既定のルートを持っています。両方のルーティングテーブルを各VPCサブネットに関連付けます。
Test4-55. <p>Which of the following can be done by Auto scaling?</p><p>Choose 2 answers from the options given below:</p> | <p>自動スケーリングでは次のうちどれを実行できますか？</p> <p>下記のオプションから2つの回答を選択します：</p>	ma:	o:Start up EC2 instances when CPU utilization is above threshold. <br>  CPU使用率がしきい値を超えた場合にEC2インスタンスを起動します。|<p><br></p><p>Option A and B are CORRECT because AutoScaling can start or terminate instances based on CPU utilization.</p><p>Option C and D are incorrect because AutoScaling cannot increase or decrease the instance size based on CPU utilization. It will launch the instances based on the launch configuration.</p><p><br></p><p>As per the AWS documentation, below is what can be done with Auto Scaling. You can only scale horizontally and not vertically.</p> <ul> <li>Scale-out Amazon EC2 instances seamlessly and automatically when demand increases.</li> <li>Shed unneeded Amazon EC2 instances automatically and save money when demand subsides.</li> <li>Scale dynamically based on your&nbsp;Amazon CloudWatch&nbsp;metrics, or predictably according to a schedule that you define.</li> <li>Replace unhealthy or unreachable instances to maintain the higher availability of your applications.</li> <li>Receive notifications via&nbsp;Amazon Simple Notification Service&nbsp;(Amazon SNS) to be alerted when you use Amazon CloudWatch alarms to initiate Auto Scaling actions, or when Auto Scaling completes an action.</li> <li>Run On-Demand or Spot Instances, including those inside your&nbsp;virtual private cloud (VPC) or&nbsp;high performance computing&nbsp;(HPC) clusters.</li> <li>If you’re signed up for the Amazon EC2 service, you’re already registered to use Auto Scaling and can begin using the feature via the API or command line interface.</li> </ul> <p>&nbsp;</p><p>For more information on Auto scaling please visit the link</p><p></p><a href="https://aws.amazon.com/autoscaling/" target="_blank" style="font-size: 1rem;">https://aws.amazon.com/autoscaling/</a><br><br><p></p>	o:Release EC2 instances when CPU utilization is below threshold. <br>  CPU使用率がしきい値を下回ったときにEC2インスタンスを解放します。	x:Increase the instance size when utilization is above threshold. <br>  使用率がしきい値を超えると、インスタンスのサイズを増やします。	x:Decrease the instance size when utilization is below threshold. <br>  使用率がしきい値を下回ると、インスタンスのサイズが小さくなります。
Test4-56. <p>There is a requirement to create EMR jobs that shift through all of the web server logs and error logs to pull statistics on click stream and errors based off of client IP address. Given the requirements what would be the best method for collecting the log data and analyzing it automatically? <br></p><p>Choose the correct answer from the below options:<br></p> | <p>クライアントのIPアドレスに基づいてクリックストリームとエラーに関する統計情報を取得するために、すべてのWebサーバーログとエラーログを移行するEMRジョブを作成する必要があります。要件を前提として、ログデータを収集して自動的に分析するための最良の方法は何ですか？<br> </p> <p>以下のオプションから正解を選択します：<br> </p>	sa:	If the application is using TCP, configure proxy protocol to pass the client IP address in a new TCP header. If the application is using, HTTP modify the application code to pull the client IP into the x-forward-for header so the web servers can parse it. <br>  アプリケーションがTCPを使用している場合、新しいTCPヘッダーにクライアントIPアドレスを渡すようにプロキシプロトコルを構成します。アプリケーションが使用している場合は、アプリケーションコードを変更して、クライアントIPをx-forward-forヘッダーにプルして、Webサーバーが解析できるようにします。|<p><br></p><p>Option A is incorrect because (a) if the protocol is TCP, you can use&nbsp; <span id="docs-internal-guid-3dc1c6ea-7d0b-ec91-3459-307b44ec05e8">proxy protocol to pass the client IP address in a new TCP header, and (b)&nbsp;</span>x-forward-for header is to be used only if the protocol is HTTP.</p><p>Option B is incorrect because it does not specify how error logs would be configured and analyzed.</p><p>Option C is CORRECT because (a) t<span id="docs-internal-guid-3dc1c6ea-7d09-e4c8-ab87-18ed6863932a">he requirement is to scan both the web server logs and error logs, and (b) the webserver being behind the ELB would not receive the client IP address and would need proxy protocol for TCP or x-forward-for header for HTTP traffic.</span></p><p>Option D is incorrect because it does not specify how access logs would be configured and analyzed.</p><p><br></p><p>For more information on HTTP Headers and Classic ELB, please refer to the links below:</p><p><a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/x-forwarded-headers.html" target="_blank">https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/x-forwarded-headers.html</a><br></p><p><br></p>	Configure ELB access logs then create a Data Pipeline job which imports the logs from an S3 bucket into EMR for analyzing and output the EMR data into a new S3 bucket. <br>  ELBアクセスログを設定し、S3バケットからEMRにログをインポートしてEMRデータを解析して新しいS3バケットに出力するデータパイプラインジョブを作成します。	If the application is using HTTP, you need to configure proxy protocol to pass the client IP address in a new HTTP header. If the application is using TCP, modify the application code to pull the client IP into the x-forward-for header so the web servers can parse it. <br>  アプリケーションがHTTPを使用している場合、新しいHTTPヘッダーにクライアントIPアドレスを渡すようにプロキシプロトコルを設定する必要があります。アプリケーションがTCPを使用している場合は、アプリケーションコードを変更して、クライアントIPをx-forward-forヘッダーにプルして、Webサーバーが解析できるようにします。	Configure ELB error logs then create a Data Pipeline job which imports the logs from an S3 bucket into EMR for analyzing and outputs the EMR data into a new S3 bucket. <br>  ELBエラーログを設定し、S3バケットからEMRにログをインポートしてEMRデータを新しいS3バケットに出力するデータパイプラインジョブを作成します。
Test4-57. <p>Which of the following benefits does adding Multi-AZ deployment in RDS provide?</p><p>Choose 2 answers from the options given below:</p> | <p> RDSにMulti-AZを追加する利点はどれですか？</p> <p>以下のオプションから2つの回答を選択してください：</p>	ma:	o:Multi-AZ deployed database can tolerate an Availability Zone failure. <br>  複数AZ配備データベースは、可用性ゾーンの障害に耐えることができます。|<p><br></p><p>Option A is CORRECT because in Multi-AZ deployment, if an availability zone (AZ) goes down, the automatic failover occurs and the DB instance CNAME gets pointed to the synchronously updated secondary instance in another AZ.</p><p>Option B is incorrect because Multi-AZ deployment does not affect the latency of the application's DB access.</p><p>Option C is incorrect because DB access time does not get affected by Multi-AZ deployment.</p><p>Option D is CORRECT because during the maintenance tasks, the DB instance CNAME can point to the secondary instance in another AZ to carry out the DB tasks.&nbsp;</p><p><br></p><p>Some of the advantages of Multi-AZ rds deployments are given below</p> <ul> <li>If an Availability Zone failure or DB Instance failure occurs, your availability impact is limited to the time automatic failover takes to complete.</li> <li>The availability benefits of Multi-AZ deployments also extend to planned maintenance and backups. In the case of system upgrades like OS patching or DB Instance scaling, these operations are applied first on the standby, prior to the automatic failover. As a result, your availability impact is, again, only the time required for automatic failover to complete.</li> <li>If a storage volume on your primary fails in a Multi-AZ deployment, Amazon RDS automatically initiates a failover to the up-to-date standby.</li> </ul> <p><br></p><p>For more information on Multi-AZ rds deployments please visit the link</p><p></p><a href="https://aws.amazon.com/rds/details/multi-az/" target="_blank" style="font-size: 1rem;">https://aws.amazon.com/rds/details/multi-az/</a><br><br><p></p>	x:Decrease latencies if app servers accessing database are in multiple Availability zones. <br>  データベースにアクセスするアプリケーションサーバーが複数の可用性ゾーンにある場合、レイテンシを短くします。	x:Make database access times faster for all app servers. <br>  すべてのアプリケーションサーバーのデータベースアクセス時間を短縮します。	o:Make database more available during maintenance tasks. <br>  保守作業中にデータベースをより使いやすくする。
Test4-58. <p>What of the following is true about the features Lambda@Edge in AWS? <br></p><p>Choose an answer from the options given below:</p> | <p> AWSのLambda @ Edgeの機能については、次のどれが当てはまりますか？<br> </p> <p>下記のオプションから回答を選択します：</p>	sa:	It is used for running Lambda functions at edge locations used by CloudFront. <br>  CloudFrontで使用されるエッジ位置でラムダ関数を実行するために使用されます。|<p><br></p><p>Option A is incorrect as it is not used for Edge based programming.</p><p>Option B is incorrect because edge locations are part of CloudFront setup, not S3.</p><p>Option C is CORRECT because Lambda@Edge allows you to run Lambda functions at the AWS edge locations in response to CloudFront events. Without Lambda@Edge, customized processing requires requests to be forwarded back to compute resources at the centralized servers. This slows down the user experience.</p><p>Option D is incorrect because Lambda@Edge supports only Node.js, which is a server-side JavaScript framework.</p><p><br></p><p>For more information on Lambda@Edge please visit the link:</p><p></p><a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/what-is-lambda-at-edge.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/what-is-lambda-at-edge.html</a><br><br><p></p>	It is used for running Lambda functions at edge locations defined by S3. <br>  これは、S3で定義されたエッジ位置でラムダ関数を実行するために使用されます。	It is used specifically for the Edge based programing language. <br>  特にEdgeベースのプログラミング言語で使用されます。	It can support any type of programming language. <br>  あらゆるタイプのプログラミング言語をサポートできます。
Test4-59. <p>Which of the following reports in CloudFront can help find out the most popular requested objects at an edge location?<br></p><p>Choose an answer from the options given below</p> | <p> CloudFrontの次のレポートのどれが、最も人気のあるリクエストされたオブジェクトをエッジ位置で見つけるのに役立ちますか？</p> <p>下記のオプションから回答を選択します。</p>	sa:	Popular Object <br>  人気のあるオブジェクト|<p><br></p><p>The Amazon CloudFront console can display a list of the 50 most popular objects for a distribution during a specified date range in the previous 60 days.</p><p>Data for the Popular Objects report is drawn from the same source as CloudFront access logs. To get an accurate count of the top 50 objects, CloudFront counts the requests for all of your objects in 10-minute intervals beginning at midnight and keeps a running total of the top 150 objects for the next 24 hours.&nbsp;</p><p><img src="https://s3.amazonaws.com/awssap/4_59_1.png" alt="" width="909" height="287" role="presentation" class="img-responsive atto_image_button_text-bottom"><br></p><p>For more information on the popular objects report please visit the link</p><p></p><a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/popular-objects-report.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/popular-objects-report.html</a><br><p></p>	Most requested <br>  最もリクエストの多い	Most Referred <br>  最も参考になった	Top Referrers <br>  トップの紹介者	Cache Statistics <br>  キャッシュ統計
Test4-60. <p>Which of the following media servers can be used for live media streaming with CloudFront?</p><p> Choose 3 options from the below:<br></p> | <p> CloudFrontでのライブメディアストリーミングに使用できるメディアサーバーはどれですか？</p> <p>以下の3つのオプションを選択してください：<br> </p>	ma:	o:Adobe Media Server <br>  o:Adobe Media Server|<p><br></p><p><span>You can use following live media servers for streaming media via CloudFront:</span></p><p></p><ul><li>&nbsp;Adobe Flash Media Server</li><li>&nbsp;Windows IIS Media Services&nbsp;</li><li>&nbsp;Wowza Streaming Engine</li></ul><p></p><p><span>&nbsp;</span></p><p><span>Hence, options A, B, and D are CORRECT.</span></p><p><span><br></span></p><p><span>For more information please refer to the links below:</span><span style="font-size: 1rem;">&nbsp;</span></p><p><span><a href="https://aws.amazon.com/blogs/aws/live-streaming-with-amazon-cloudfront-and-adobe-flash-media-server/" target="_blank">https://aws.amazon.com/blogs/aws/live-streaming-with-amazon-cloudfront-and-adobe-flash-media-server/</a></span></p><p><span><a href="https://aws.amazon.com/blogs/aws/smooth-streaming-with-cloudfront-and-windows-media-services/" target="_blank">https://aws.amazon.com/blogs/aws/smooth-streaming-with-cloudfront-and-windows-media-services/</a></span></p><p><span><a href="https://aws.amazon.com/cloudfront/streaming/" target="_blank">https://aws.amazon.com/cloudfront/streaming/</a></span></p><p></p><br><p></p>	o:IIS Media services <br>  ああ、IISメディアサービス	x:Atlassian Media Servers <br>  アトラシアンメディアサーバー	o:Wowza streaming engine <br>  Wowzaストリーミングエンジン
Test4-61. <p>You are moving an existing traditional system to AWS. During migration, you discover that the master server is the single point of failure. Having examined the implementation of the master server you realize that there is not enough time during migration to re-engineer it to be highly available. You also discover that it stores its state in local MySQL database.</p><p>In order to minimize downtime, you select RDS to replace the local database and configure the master to use it. What steps would best allow you to create a self-healing architecture?</p> | <p>既存の従来のシステムをAWSに移行しています。移行中に、マスターサーバーが単一障害点であることがわかります。マスターサーバーのインプリメンテーションを検討したところ、高可用性になるようにリエンジニアリングするために、移行中に十分な時間がないことを認識しています。</p> <p>停止時間を最小限に抑えるには、RDSを選択してローカルデータベースを置き換え、マスターがそれを使用するように構成する必要があります。自己修復アーキテクチャを作成するにはどのような手順が最適でしょうか？</p>	sa:	Migrate the local database into Multi-AZ database. Place the master node into a multi-AZ auto-scaling group with a minimum of one and maximum of one with health checks. <br>  ローカルデータベースをマルチAZデータベースに移行します。マスターノードを複数のAZ自動スケーリンググループに配置し、最小1つ、最大1つのヘルスチェックを行います。|<p><br></p><p>Option A is CORRECT because (i) for database, Multi-AZ architecture provides high availability and can meet shortest of RTO and RPO requirements in case of failures, since it uses synchronous replication and maintains standby instance which gets promoted to primary, and (ii) for master server, it uses auto scaling which ensures that at least one server is always running.</p><p><span style="font-size: 1rem;">Option B is incorrect because ELB cannot ensure the minimum or maximum number of instances running.</span></p><p><span style="font-size: 1rem;">Option C is incorrect because (i) read replicas do not provide high availability, and (ii) ELB cannot ensure the minimum or maximum number of instances running.</span></p><p><span style="font-size: 1rem;">Option D is incorrect because read replicas do not provide high availability.</span></p><p><br></p><p><span style="font-size: 1rem;"><b>More information on Multi-AZ RDS architecture:</b></span></p><p><span style="font-size: 1rem;">Multi-AZ is used for highly available architecture. If a failover happens, the secondary DB which is a synchronous replica will have the data, and it’s just the CNAME which changes. For Read replica, it’s primarily used for distributing workloads.</span></p><p><br></p><p>For&nbsp; more information on Multi-AZ RDS, please refer to the below link</p><p></p><a href="https://aws.amazon.com/rds/details/multi-az/" target="_blank" style="font-size: 1rem;">https://aws.amazon.com/rds/details/multi-az/</a><br><br><p></p>	Migrate the local database into Multi-AZ database. Place the master node into a Cross Zone ELB with a minimum of one and maximum of one with health checks. <br>  ローカルデータベースをマルチAZデータベースに移行します。マスターノードを最小1個、最大1個のクロスゾーンELBに配置し、ヘルスチェックを行います。	Replicate the local database into a RDS Read Replica. Place the master node into a Cross Zone ELB with a minimum of one and maximum of one with health checks. <br>  ローカルデータベースをRDS読み取りレプリカにレプリケートします。マスターノードを最小1個、最大1個のクロスゾーンELBに配置し、ヘルスチェックを行います。	Replicate the local database into a RDS Read Replica. Place the master node into a multi-AZ auto-scaling group with a minimum of one and maximum of one with health checks. <br>  ローカルデータベースをRDS読み取りレプリカにレプリケートします。マスターノードを複数のAZ自動スケーリンググループに配置し、最小1つ、最大1つのヘルスチェックを行います。
Test4-62. <p>You have created an OpsWorks stack to create EC2 instances along with an ELB. You have now been asked to change the region in which the EC2 instances will be registered. Can you change the region value in the OpsWork stack?</p> | <p> ELBとともにEC2インスタンスを作成するためのOpsWorksスタックを作成しました。これで、EC2インスタンスが登録される地域を変更するように求められました。OpsWorkスタックの領域値を変更できますか？</p>	sa:	FALSE <br>  偽|<p><br></p><p>After you create a layer, some properties (such as AWS region) are immutable, but you can change most of the layer configuration at any time.&nbsp;</p><p><br></p><p>For&nbsp; more information on working with OpsWork layers, please refer to the below link</p><p></p><a href="http://docs.aws.amazon.com/opsworks/latest/userguide/workinglayers-basics-edit.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/opsworks/latest/userguide/workinglayers-basics-edit.html</a><br><p></p>	TRUE <br>  真
Test4-63. <p>What are the steps that get carried out by OpsWork when you attach a load balancer to a layer in OpsWork?</p><p>Choose 3 options from the below:</p> | <p> OpsWorkのレイヤにロードバランサを接続するときにOpsWorkが実行する手順は何ですか？</p> <p>以下の3つのオプションを選択します。</p>	ma:	x:Terminates the EC2 Instances. <br>  EC2インスタンスを終了します。|<p><br></p><p></p><p>For the exam remember that, after you attach a load balancer to a layer, AWS OpsWorks Stacks does the following:</p><div><ul type="disc"><li><p>Deregisters any currently registered instances.&nbsp;</p></li><li><p>Automatically registers the layer's instance's when they come online and deregisters instances when they leave the online state, including load-based and time-based instances.</p></li><li><p>Automatically activates and deactivates the instances' Availability Zones.</p></li></ul></div><br><p></p><p>Hence, options B, C, and D are CORRECT.</p><p><br></p><p>For more information on working with Opswork layer ELB’s, please refer to the below link</p><p></p><a href="http://docs.aws.amazon.com/opsworks/latest/userguide/layers-elb.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/opsworks/latest/userguide/layers-elb.html</a><br><br><p></p>	o:Deregisters any currently registered instances. <br>  現在登録されているインスタンスを登録解除します。	o:Automatically registers the layer's instance's when they come online and deregisters instances when they leave the online state, including load-based and time-based instances. <br>  レイヤーのインスタンスがオンラインになったときにレイヤーのインスタンスを自動的に登録し、ロードベースのインスタンスや時間ベースのインスタンスなど、オンライン状態から離れるときにインスタンスの登録を解除します。	o:Automatically activates and deactivates the instances' Availability Zones. <br>  インスタンスの可用性ゾーンを自動的に有効化および無効化します。
Test4-64. <p>You have created an Elastic Load Balancer with Duration-Based sticky sessions enabled in front of your six EC2 web application instances in US-West-2. For High Availability, there are three web application instances in Availability Zone 1 and three web application instances in Availability Zone 2. To load test, you set up a software-based load tester in Availability Zone 2 to send traffic to the Elastic Load Balancer, as well as letting several hundred users browse to the ELB’s hostname.</p><p><span style="font-size: 1rem;">After a while, you notice that the users’ sessions are spread evenly across the EC2 instances in both AZ’s, but the software-based load tester’s traffic is hitting only the instances in Availability Zone 2. What steps can you take to resolve this problem?</span></p><p><br></p><p>Choose 2 correct options from the below:</p> | <p> US-West-2の6つのEC2 Webアプリケーションインスタンスの前にDuration-Basedスティッキセッションを有効にしたElastic Load Balancerを作成しました。ハイアベイラビリティの場合、可用性ゾーン1に3つのWebアプリケーションインスタンスがあり、可用性ゾーン2に3つのWebアプリケーションインスタンスがあります。テストをロードするには、可用性ゾーン2にソフトウェアベースのロードテスターを設定して、Elastic Load Balancer、 ELBのホスト名を数百人のユーザーがブラウズできるようにします。<p> <span style = "font-size：1rem;">しばらくすると、ユーザーのセッションがEC2両方のAZのインスタンスが含まれていますが、ソフトウェアベースの負荷テスターのトラフィックは、可用性ゾーン2のインスタンスのみに当たっています。この問題を解決するにはどのような手順が必要ですか？</ span> </p> <	ma:	x:Create a software-based load tester in US-East-1 and test from there. <br>  US-East-1にソフトウェアベースの負荷テスターを作成し、そこからテストします。|<p><br></p><p>When you create an elastic load balancer, a default level of capacity is allocated and configured. As Elastic Load Balancing sees changes in the traffic profile, it will scale up or down. The time required for Elastic Load Balancing to scale can range from 1 to 7 minutes, depending on the changes in the traffic profile. When Elastic Load Balancing scales, it updates the DNS record with the new list of IP addresses. To ensure that clients are taking advantage of the increased capacity, Elastic Load Balancing uses a TTL setting on the DNS record of 60 seconds. It is critical that you factor this changing DNS record into your tests. If you do not ensure that DNS is re-resolved or use multiple test clients to simulate increased load, the test may continue to hit a single IP address when Elastic Load Balancing has actually allocated many more IP addresses. Because your end users will not all be resolving to that single IP address, your test will not be a realistic sampling of real-world behavior.</p><p><br></p><p><span style="font-size: 1rem;">Option A is incorrect because creating load tester in US-East-1 will face the same problem of traffic hitting only the instances in that AZ.</span></p><p><span style="font-size: 1rem;">Option B is CORRECT because if you do not ensure that DNS is re-resolved the test may continue to hit the single IP address.</span></p><p><span style="font-size: 1rem;">Option C is CORRECT because if the requests come from globally distributed users, the DNS will not be resolved to a single IP address and the traffic would be distributed evenly across multiple instances.</span></p><p><span style="font-size: 1rem;">Option D is incorrect because the traffic will be routed to the same back-end instances as the users continue to access your application. The load will not be evenly distributed across the AZs.</span></p><p><br></p><p>Please refer to the below article for more information:</p><p></p><a href="http://aws.amazon.com/articles/1636185810492479" target="_blank" style="font-size: 1rem;">http://aws.amazon.com/articles/1636185810492479</a><br><br><p></p>	o:Force the software-based load tester to re-resolve DNS before every request. <br>  ソフトウェアベースの負荷テスト担当者がすべての要求の前にDNSを再解決するように強制します。	o:Use a third party load-testing service to send requests from globally distributed clients. <br>  サードパーティの負荷テストサービスを使用して、グローバルに分散しているクライアントから要求を送信します。	x:Switch to application-controlled sticky sessions. <br>  アプリケーション制御のスティッキセッションに切り替えます。
Test4-65. <p>There are currently multiple applications hosted in a VPC. During monitoring, it has been noticed that multiple port scans are coming in from a specific IP Address block. The internal security team has requested that all offending IP Addresses be denied for the next 24 hours. Which of the following is the best method to quickly and temporarily deny access from the specified IP Addresses?</p> | <p>現在、VPCでホストされている複数のアプリケーションがあります。監視中、特定のIPアドレスブロックから複数のポートスキャンが到着していることに気付きました。社内のセキュリティチームは、問題となっているすべてのIPアドレスが今後24時間は拒否されるように要求しています。指定したIPアドレスからのアクセスを迅速かつ一時的に拒否する最も良い方法はどれですか？</p>	sa:	Modify the Network ACLs associated with all public subnets in the VPC to deny access from the IP Address block. <br>  VPC内のすべてのパブリックサブネットに関連付けられたネットワークACLを変更して、IPアドレスブロックからのアクセスを拒否します。|<p><br></p><p>A network access control list (ACL) is an optional layer of security for your VPC that acts as a firewall for controlling traffic in and out of one or more subnets.</p><p><br></p><p>Option A and D are incorrect because (a)it will only work for windows-based instances, and (b)better approach is to block the traffic at the subnet layer via NACL rather than instance layer (windows firewall).</p><p><span style="font-size: 1rem;">Option B is CORRECT because the best way to allow or deny IP address-based access to the resources in the VPC is to configure rules in the Network access control list (NACL) which are applied at the subnet level.</span></p><p><span style="font-size: 1rem;">Option C is incorrect because (a)you cannot explicitly deny access to particular IP addresses via security group, and (b)better approach is to block the traffic at the subnet layer via NACL rather than instance layer (security group).</span></p><p><br></p><p>For more information on Network ACL’s please refer to the below link:</p><p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html" target="_blank">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html</a><br></p><p><br></p>	Create an AD policy to modify the Windows Firewall settings on all hosts in the VPC to deny access from the IP Address block. <br>  ADポリシーを作成して、VPC内のすべてのホストのWindowsファイアウォール設定を変更し、IPアドレスブロックからのアクセスを拒否します。	Add a rule to all of the VPC Security Groups to deny access from the IP Address block. <br>  すべてのVPCセキュリティグループにルールを追加して、IPアドレスブロックからのアクセスを拒否します。	Modify the Windows Firewall settings on all AMI's that your organization uses in that VPC to deny access from the IP address block. <br>  組織がそのVPC内でIPアドレスブロックからのアクセスを拒否するために使用するすべてのAMIのWindowsファイアウォール設定を変更します。
Test4-66. <p>A user has created a VPC with CIDR 20.0.0.0/24. The user has created a public subnet with CIDR 20.0.0.0/25 and a private subnet with CIDR 20.0.0.128/25. The user has launched one instance each in the private and public subnet. Which of the below-mentioned options cannot be the correct IP address (private IP) assigned to an instance in the public or private subnet?</p> | <p>ユーザーがCIDR 20.0.0.0/24のVPCを作成しました。ユーザーは、CIDR 20.0.0.0/25のパブリックサブネットと、CIDR 20.0.0.128/25のプライベートサブネットを作成しました。ユーザーは、プライベートおよびパブリックサブネットでそれぞれ1つのインスタンスを起動しました。以下のオプションのうち、パブリックまたはプライベートサブネット内のインスタンスに割り当てられた正しいIPアドレス（プライベートIP）を指定できないものはどれですか？</p>	sa:	20.0.0.255 <br>  20.0.0.255|<p><br></p><p><span style="font-size: 1rem;">In Amazon VPC, the first four IP addresses and the last IP address in each subnet CIDR block are not available for the user to assign to an instance. For example, in this VPC, the following five IP addresses are reserved:</span></p> <ul> <li>20.0.0.0: Network address.</li> <li>20.0.0.1: Reserved by AWS for the VPC router.</li> <li>20.0.0.2: Reserved by AWS. The IP address of the DNS server is always the base of the VPC network range plus two; however, we also reserve the base of each subnet range plus two. 20.0.0.3: Reserved by AWS for future use.</li> <li>20.0.0.255: Network broadcast address. We do not support broadcast in a VPC, therefore we reserve this address.</li> </ul> <p>&nbsp;</p><p>For more information on IP Reservation, please visit the link</p><p></p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html</a><br><br><p></p>	20.0.0.132 <br>  20.0.0.132	20.0.0.122 <br>  20.0.0.122	20.0.0.55 <br>  20.0.0.55
Test4-67. <p>You've been working on a CloudFront whole site CDN. After configuring the whole site CDN with a custom CNAME and supported HTTPS custom domain (i.e., https://domain.com) you open domain.com and are receiving the following error:</p><p>“CloudFront wasn't able to connect to the origin.”</p><p>What might be the most likely cause of this error and how would you fix it?</p><p> Choose the correct answer from the below options:<br></p> | <p> あなたはCloudFrontの全サイトCDNで作業しています。 カスタムCNAMEとサポートされているHTTPSカスタムドメイン（つまり、https://domain.com）でサイト全体のCDNを設定した後、domain.comを開き、次のエラーが表示されます。</ p> <p> "CloudFrontは </ p> <p>このエラーの原因としてはどのようなものがありますか？どのように修正しますか？</ p> <p>以下のオプションから正しい答えを選択してください：<br> > </p>	sa:	The Origin Protocol Policy is set to Match Viewer and HTTPS isn't configured on the origin. <br>  オリジンプロトコルポリシーがMatch Viewerに設定され、HTTPSがオリジン上で設定されていません。|<p><br></p><p>Option A,B, and C are all incorrect because in these scenarios, the CloudFront returns HTTP status code 502 (Bad Gateway).</p><p>Option D is CORRECT because this error occurs when the Origin Protocol Policy is set to Match Viewer but HTTPS isn't configured on the origin.</p><p><br></p><p><span style="font-size: 1rem;">For more information on CloudFront CDN please see the below link</span></p><p></p><a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html</a><br><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/http-502-bad-gateway.html#ssl-certificate-expired" target="_blank">https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/http-502-bad-gateway.html#ssl-certificate-expired</a><br><p></p>	HTTPS isn't configured on the CloudFront distribution but is configured on the CloudFront origin. <br>  HTTPSはCloudFrontディストリビューションでは設定されていませんが、CloudFront起点で設定されています。	The origin on the CloudFront distribution is the wrong origin. <br>  CloudFrontディストリビューションの起源は間違った起源です。	The HTTPS certificate is expired or missing a third party signer. To resolve this purchase and add a new SSL certificate. <br>  HTTPS証明書が期限切れになっているか、サードパーティの署名者がありません。この購入を解決し、新しいSSL証明書を追加します。
Test4-68. <p>A user is using a small MySQL RDS DB. The user is experiencing high latency due to the Multi-AZ feature. Which of the below-mentioned options may not help the user in this situation?</p> | <p>ユーザーは小さなMySQL RDS DBを使用しています。Multi-AZ機能により、ユーザーの待ち時間が長くなっています。次のオプションのどれがこの状況でユーザーを助けないでしょうか？</p>	sa:	Take a snapshot from standby Replica <br>  スタンバイレプリカからスナップショットを取る|<p><br></p><p>Option A is incorrect because scheduling the automated backups in non-working hours will reduce the load on the DB instance and will help reducing the latency.</p><p>Option B is incorrect because using a larger instance would help processing the queries and carry out load efficiently, thus reducing the overall latency.</p><p>Option C is incorrect because using the provisioned IOPS, the users would get high throughput from the DB instance.</p><p>Option D is CORRECT because taking the snapshots from the read replica is not going to affect the RDS instance. Hence, the users will keep experiencing the high latency as they currently are.&nbsp;</p><p><br></p><p><b>More information on Multi-AZ deployment:</b></p><p>In a Multi-AZ deployment, Amazon RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone. The primary DB instance is synchronously replicated across Availability Zones to a standby replica to provide data redundancy, eliminate I/O freezes, and minimize latency spikes during system backups</p><p>As per AWS, the below are the best practices for multiAZ.</p><p>For production workloads, we recommend you use Provisioned IOPS and DB instance classes (m1.large and larger) that are optimized for Provisioned IOPS for fast, consistent performance. Hence option B and C are valid.</p><p>Also if backups are scheduled during working hours, then I/O can be suspended and increase the latency of the DB, hence it is better to schedule outside of office hours.</p><p><br></p><p>For more information on Multi-AZ RDS, please visit the link:</p><p></p><a href="http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html</a><br><p></p>	Use a large or higher size instance <br>  大きいサイズ以上のインスタンスを使用する	Use Provisioned IOPS storage <br>  プロビジョニングされたIOPSストレージを使用する	Schedule the automated back up in non-working hours <br>  営業時間内に自動バックアップをスケジュールする
Test4-69. <p>A user has created a public subnet with VPC and launched an EC2 instance within it. The user is trying to delete the subnet. What will happen in this scenario?</p> | <p>ユーザーがVPCを使用してパブリックサブネットを作成し、その中にEC2インスタンスを起動しました。ユーザーがサブネットを削除しようとしています。このシナリオではどうなるでしょうか？</p>	sa:	It will not allow the user to delete the subnet until the instances are terminated. <br>  インスタンスが終了するまで、ユーザーはサブネットを削除できません。|<p><br></p><p>In AWS, when you try to delete a subnet which has instances it will not allow to delete it. The below error message will be shown when u try to delete a subnet with instances. Hence, option B is the CORRECT answer.</p><p>&nbsp;<img src="https://s3.amazonaws.com/awssap/4_69_1.png" alt="" role="presentation" class="img-responsive atto_image_button_text-bottom" height="283" width="700"></p><p>For more information on VPC and subnets please visit the link</p><p></p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html</a><br><p></p>	It will delete the subnet and make the EC2 instance as a part of the default subnet. <br>  サブネットが削除され、EC2インスタンスがデフォルトのサブネットの一部として作成されます。	It will delete the subnet as well as terminate the instances. <br>  サブネットを削除し、インスタンスを終了します。	The subnet can never be deleted independently, but the user has to delete the VPC first. <br>  サブネットは個別に削除することはできませんが、まずVPCを削除する必要があります。
Test4-70. <p>A user has created a VPC with public and private subnets using the VPC wizard &nbsp;by selecting&nbsp;<span>NAT Instance for internet&nbsp;Access</span>. The user has not launched any instance manually and is trying to delete the VPC. What will happen in this scenario?</p> | <p> VPCウィザードを使用して＆nbsp; <span>インターネットアクセス用のNATインスタンス</ span>を選択して、公開サブネットとプライベートサブネットを持つVPCを作成しました。ユーザーは手動でインスタンスを起動しておらず、VPCを削除しようとしています。このシナリオではどうなるでしょうか？</p>	sa:	It will not allow to delete the VPC since it has a running NAT instance. <br>  実行中のNATインスタンスがあるため、VPCを削除することはできません。|<p><br></p><p>Since the VPC will contain a NAT instance because of the private/public subnet combination, when you try to delete the VPC you will get the below error message. Hence, option D is CORRECT.</p><p>&nbsp;<p>For more information on VPC and subnets please visit the link</p><p></p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html</a><br><br><p></p>	It will not allow to delete the VPC since it has a running route instance. <br>  VPCには実行中のルートインスタンスがあるため、VPCを削除することはできません。	It will terminate the VPC along with all the instances launched by the wizard. <br>  ウィザードによって起動されたすべてのインスタンスと共にVPCが終了します。	It will not allow to delete the VPC as it has subnets with route tables. <br>  ルートテーブルを持つサブネットを持つため、VPCを削除することはできません。
Test4-71. <p>A user is planning to set up-the Multi-AZ feature of RDS. Which of the below-mentioned conditions won’t take advantage of the Multi-AZ feature?</p> | <p>ユーザーはRDSのマルチAZ機能を設定する予定です。下記の条件のうちマルチAZ機能を利用しないものはどれですか？</p>	sa:	Region outage <br>  地域の停電|<p><br></p><p></p><p>Amazon RDS handles failovers automatically so you can resume database operations as quickly as possible without administrative intervention. The primary DB instance switches over automatically to the standby replica if any of the following conditions occur:</p><div><ul type="disc"><li><p>An Availability Zone outage</p></li><li><p>The primary DB instance fails</p></li><li><p>The DB instance's server type is changed</p></li><li><p>The operating system of the DB instance is undergoing software patching</p></li><li><p>A manual failover of the DB instance was initiated using&nbsp;<span>Reboot with failover</span></p></li></ul><p><br></p><p>Hence, option A, B and D are incorrect. Option C is CORRECT because if there is a region-wide failure, the Multi-AZ feature may not work.</p></div><p></p><p><span style="font-size: 1rem;"><br></span></p><p><span style="font-size: 1rem;">For more information on multiAZ RDS please visit the link:</span></p><p></p><a href="https://aws.amazon.com/rds/details/multi-az/" target="_blank" style="font-size: 1rem;">https://aws.amazon.com/rds/details/multi-az/</a><br><p></p>	A manual failover of the DB instance using Reboot with failover option <br>  フェールオーバーオプション付きのRebootを使用したDBインスタンスの手動フェールオーバー	Availability zone outage <br>  可用性ゾーンの停止	When the user changes the DB instance’s server type <br>  ユーザーがDBインスタンスのサーバータイプを変更すると
Test4-72. <p>A user has created a VPC with public and private subnets using the VPC wizard. Which of the below-mentioned statements is not true in this scenario?</p> | <p>ユーザーがVPCウィザードを使用してパブリックサブネットとプライベートサブネットを持つVPCを作成しました。このシナリオでは、以下のステートメントのどれが当てはまりませんか？</p>	sa:	The VPC will create a routing instance and attach it with a public subnet. <br>  VPCはルーティングインスタンスを作成し、パブリックサブネットに接続します。|<p><br></p><p>Option A is CORRECT because VPC wizard does not create any routing instance in the public subnet.</p><p><span style="font-size: 1rem;">Below is the general diagram of what is created when you have a private and public subnet used when using the VPC wizard. So you will get the below options</span></p><p></p><ul><li>2 subnets – one private and one public</li><li>One&nbsp;NAT Gateway to route traffic from the public to private subnet</li><li>One internet gateway attached to the VPC.</li></ul><p></p><p>&nbsp;<span style="font-size: 1rem;">&nbsp;</span><img src="https://s3.amazonaws.com/awssap/4_72_1.png" alt="" role="presentation" class="img-responsive atto_image_button_text-bottom" height="503" width="713" style="font-size: 1rem;"></p><p><br></p><p>For more information on VPC and subnets, please visit the URL:</p><p></p><a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario2.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario2.html</a><br><p></p>	The VPC will create two subnets. <br>  VPCは2つのサブネットを作成します。	The VPC will create one internet gateway and attach it to VPC. <br>  VPCは1つのインターネットゲートウェイを作成し、VPCに接続します。	The VPC will launch one NAT Gateway with an elastic IP. <br>  VPCは、弾性IPを持つ1つのNATゲートウェイを起動します。
Test4-73. <p>Which of the following types of servers would this CloudFormation template be most appropriate for? Choose a correct answer from the below options:<br></p><p>{</p><p>&nbsp; "AWSTemplateFormatVersion" : "2010-09-09",</p><p>&nbsp; "Description" : "My CloudFormation Template",</p><p>&nbsp;</p><p>&nbsp; "Resources" : {</p><p>&nbsp;&nbsp;&nbsp;&nbsp; "MyInstance" : {</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Type" : "AWS::EC2::Instance",</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Properties" : {</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "InstanceType" : "t2.micro",</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "ImageId" : "ami-030f4133",</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; "NetworkInterfaces" : [{</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "AssociatePublicIpAddress" : "true",</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "DeviceIndex" : "0",</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "DeleteOnTermination" : "true",</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "SubnetId" : "subnet-0c2c0855",</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "GroupSet" : ["sg-53a4e434"]</p><p>&nbsp; &nbsp; &nbsp; &nbsp; }</p><p>&nbsp;&nbsp;&nbsp;&nbsp; ]</p><p>&nbsp;&nbsp; }&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p>&nbsp; }</p><p>&nbsp;}</p>} | <p>このCloudFormationテンプレートが最も適切なサーバのタイプはどれですか？以下のオプションから正しい答えを選択してください：<br> </p> <p> {</p> <p>＆nbsp; "AWSTemplateFormatVersion"： "2010-09-09"、</p> <p>＆nbsp; "説明"： "My CloudFormationテンプレート"、</p> <p>＆nbsp; </p> <p>＆nbsp; "リソース"：{</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp; "MyInstance"：{</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "タイプ"： "AWS :: EC2 ::インスタンス"、</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "プロパティ"：{</p> <p>＆nbsp; ＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "InstanceType"： "t2.micro"、</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "ImageId"： "ami-030f4133"、</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; ＆nbsp; "NetworkInterfaces"：[{</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "AssociatePublicIpAddress"： "true"、</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "DeviceIndex"： "0"、</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "DeleteOnTermination"： "true"、</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "SubnetId"： "subnet-0c2c0855"、</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "GroupSet"：["sg-53a4e434"] </p> <p>＆nbsp; ＆nbsp; ＆nbsp; ＆nbsp; } </p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp; ] </p> <p>＆nbsp;＆nbsp; }＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; </p> <p>＆nbsp; } </p> <p>＆nbsp;	sa:	Bastion host <br>  バスティオンホスト|<p><br></p><p>The bastion host needs a minimum configuration and a public IP address. The above CloudFormation template best fits this.</p><p><br></p><p>For more information on CloudFormation please visit the below link</p><p></p><a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-whatis-concepts.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-whatis-concepts.html</a><br><p></p>	Log collection server <br>  ログ収集サーバー	Database server <br>  データベースサーバー	Domain Controller <br>  ドメインコントローラ
Test4-74. <p>A recent increase in a number of users of an application hosted on an EC2 instance that you manage has caused the instance’s OS to run out of CPU resources and crash. The crash caused several users’ unsaved data to be lost and your supervisor wants to know how this problem can be avoided in the future. Which of the following would you not recommend? <br></p><p>Choose the correct answer from the below options:<br></p> | <p>管理しているEC2インスタンスでホストされているアプリケーションのユーザー数が最近増加したため、インスタンスのOSにCPUリソースが不足しクラッシュしました。このクラッシュにより、保存されていないユーザーのデータが失われ、管理者はこの問題を今後どのように回避できるかを知りたいと考えました。次のうち推奨しないものはどれですか？<br> </p> <p>以下のオプションから正解を選択します：<br> </p>	sa:	Take frequent snapshots of the EBS volume during business hours to ensure users’ data is backed up. <br>  営業時間中にEBSボリュームのスナップショットを頻繁に取得して、ユーザーのデータが確実にバックアップされるようにします。|<p><br></p><p>Option A is incorrect because this option would ensure that the user's unsaved data gets preserved just in case the instance crashes.</p><p>Option B is CORRECT because taking frequent snapshots of the EBS volume during business hours may cause data loss (losing the data that is not yet written to the volume that is being backed up via snapshot) . It is strongly recommended by AWS to either detach the volume or freeze all writes before taking the snapshot to prevent data loss. Hence, this option&nbsp;is certainly not recommended.</p><p>Option C is incorrect because using larger instance type can mitigate the problem of instance running out CPU.</p><p>Option D is incorrect because AutoScaling will ensure that that at least one (or minimum number of) instance(s) would be running to ensure that the application is always up and running.</p><p><br></p><p>For more information on EBS snapshots, please refer to the below URL:</p><p></p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html</a><br><a href="https://forums.aws.amazon.com/thread.jspa?threadID=92160" target="_blank">https://forums.aws.amazon.com/thread.jspa?threadID=92160</a><br><br><p></p>	Redesign the application so that users’ unsaved data is periodically written to disk. <br>  ユーザーの保存されていないデータが定期的にディスクに書き込まれるように、アプリケーションを再設計します。	Snapshot the EBS volume and re-deploy the application server as a larger instance type. <br>  EBSボリュームをスナップショットし、アプリケーションサーバーをより大きなインスタンスタイプとして再展開します。	Use autoscaling to deploy additional application server instances when load is high. <br>  負荷が高い場合、自動拡張を使用して、追加のアプリケーションサーバーインスタンスを展開します。
Test4-75. <p>Why will the following CloudFormation template fail to deploy a stack? <br></p><p>Choose the correct answer from the below options:<br></p><p>&nbsp;</p><p>{</p><p>&nbsp; "AWSTemplateFormatVersion" : "2010-09-09",</p><p>&nbsp;&nbsp; "Parameters" : {</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "VPCId" : {</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Type": "String",</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Description" : "Enter current VPC Id"</p><p>&nbsp;&nbsp;&nbsp;&nbsp; },</p><p>&nbsp;&nbsp;&nbsp; "SubnetId : {</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Type": "String",</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Description" : "Enter a subnet Id"</p><p>&nbsp;&nbsp;&nbsp; }</p><p>},</p><p>&nbsp;</p><p>"Outputs" : {</p><p>&nbsp;&nbsp; "InstanceId" : {</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Value" : { "Ref" : "MyInstance" },</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "Description" : "Instance Id"</p><p>&nbsp; &nbsp;&nbsp; }</p><p>&nbsp;&nbsp; }</p><p>}</p> | <p>次のCloudFormationテンプレートでスタックを展開できないのはなぜですか？<br> </p> <p> <p>以下のオプションから正しい答えを選択します：<br> </p> <p>＆nbsp; </p> <p> {</p> <p> "AWSTemplateFormatVersion"： "2010-09-09"、</p> <p>＆nbsp;＆nbsp; "パラメータ"：{</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "VPCId"：{</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "タイプ"： "文字列"、</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "説明"： "現在のVPC IDを入力してください" </p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp; }、</p> <p>＆nbsp;＆nbsp;＆nbsp; "SubnetId：{</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "タイプ"： "文字列"、</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "説明"： "サブネットIDを入力してください" </p> <p>＆nbsp;＆nbsp;＆nbsp; } </p> <p>＆nbsp; </p> <p> "InstanceId"：{</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "Value"：{"Ref"： "MyInstance"}、</p> <p>＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp;＆nbsp; "説明"： "インスタンスID" </p> <p>＆nbsp; ＆nbsp;＆nbsp; } </p> <p>＆nbsp;＆nbsp; } </p> <p>} </p>	sa:	A “Resources” section is mandatory but is not included <br>  「リソース」セクションは必須ですが、含まれていません|<p><br></p><p>Option C is CORRECT because, the Resources section is mandatory for the CloudFormation template to work; and it is missing in this template.</p><p><br></p><p>For more information on CloudFormation templates, please refer to the below URL:</p><p></p><a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html</a><br><br><p></p>	A “Conditions” section is mandatory but is not included <br>  「条件」セクションは必須ですが、含まれていません	CloudFormation templates do not use a “Parameters” section <br>  CloudFormationテンプレートは「パラメータ」セクションを使用しません	A template description is mandatory but is not included <br>  テンプレートの説明は必須ですが、含まれていません
Test4-76. <p>You are maintaining an application that is spread across multiple web servers and has incoming traffic balanced by ELB. The application allows users to upload pictures. Currently, each web server stores the image and a background task synchronizes the data between servers. However, the synchronization task can no longer keep up with the number of images uploaded.</p><p>What change could you make so that all web servers have a place to store and read images at the same time? <br></p><p>Choose an answer from the below options:</p> | <p>複数のWebサーバーにまたがってELBによって受信トラフィックのバランスがとられているアプリケーションをメンテナンスしています。このアプリケーションでは、ユーザーは写真をアップロードできます。現在、各Webサーバーはイメージを保存し、バックグラウンドタスクはサーバー間でデータを同期させます。しかし、同期タスクではアップロードされた画像の数に追いつくことができなくなりました。</p> <p>すべてのWebサーバが同時に画像を保存して読み取る場所を持つように変更できますか？<br> </p> <p>以下のオプションから回答を選択します：</p>	sa:	Store the images in Amazon S3. <br>  Amazon S3に画像を保存します。|<p><br></p><p>Option A is CORRECT because S3 provides a durable, secure, cost effective, and highly available storage service for the uploaded pictures.</p><p><span style="font-size: 1rem;">Option B is incorrect because the application needs just a storage solution, not a global content distribution service. CloudFront is also costlier solution compared to S3.</span></p><p><span style="font-size: 1rem;">Option C is incorrect because you cannot share EBS volumes among multiple EC2 instances.</span></p><p><span style="font-size: 1rem;">Option D is incorrect because ELB cannot be used as a storage service.</span></p><p><br></p><p>For more information on AWS S3, please refer to the below URL:</p><p></p><a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html</a><br><br><p></p>	Store the images on Amazon CloudFront. <br>  Amazon CloudFrontに画像を保存します。	Store the images on Amazon EBS. <br>  Amazon EBSに画像を保存します。	Store the images on the ELB. <br>  画像をELBに保存します。
Test4-77. <p>Which of the following is an example of a good Amazon DynamoDB hash key schema for provisioned throughput efficiency?</p><p>Choose an answer from the below options:</p> | </p> <p>以下のオプションから回答を選択してください：</p> <p>以下は、プロダクションスループット効率のためのAmazon DynamoDBハッシュキースキーマの例です：	sa:	Student ID where every student has a unique ID. <br>  すべての生徒が一意のIDを持つ生徒ID。|<p><br></p><p>Option A is CORRECT because DynamoDB stores and retrieves each item based on the primary key (hash key) value which must be unique. Every student would surely have Student ID, hence, the data would be partitioned for each ID, which will make the data retrieval efficient.</p><p>Option B is incorrect because the data should spread evenly across all partitions for best throughput. With only two colleges, there would be only two partitions. This will not be as efficient as making Student ID the hash key.&nbsp;</p><p>Option C is incorrect because partitioning on Class ID will not be as efficient as doing so on the Student ID.</p><p>Option D is incorrect because there are only two possible options: in-state and out-of-state. This will not be as efficient as making Student ID the hash key.</p><p><br></p><p>For more information on DynamoDB tables, please visit the URL:</p><p></p><a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithTables.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithTables.html</a><br><p></p>	College ID where there are two colleges in the university. <br>  大学に2つのカレッジがある大学ID。	Class ID where every student is in one of the four classes. <br>  すべての生徒が4つのクラスのいずれかにいるクラスID。	Tuition Plan where the vast majority of students are in state and the rest are out of state. <br>  大部分の学生が州にあり、残りが州外にある授業計画。
Test4-78. <p>Which of the below-mentioned ways can be used to provide additional layers of protection to all your EC2 resources?</p><p>Choose the correct answer from the below options:<br></p> | </p> <p>以下のオプションから正解を選択してください：<br> </p> <p>あなたのEC2リソースに追加保護層を提供するために、	sa:	All actions listed here would provide additional layers of protection. <br>  ここに記載されているすべてのアクションは、追加の保護レイヤーを提供します。|<p><span style="font-size: 1rem;">Tagging allows you to understand which resources below to test, development and production environment if done properly. Tags enable you to categorize your AWS resources in different ways, for example, by purpose, owner, or environment. This is useful when you have many resources of the same type — you can quickly identify a specific resource based on the tags you've assigned to it. Each tag consists of a key and an optional value, both of which you define.</span></p><p>If you have tagging, you can then also allow permissions based on the tags.</p><p><span style="font-size: 1rem;">You can also use IP Address conditions in IAM policies for denying access to AWS resources.</span></p><p>{</p><p>&nbsp; "Version": "2012-10-17",</p><p>&nbsp; "Statement": {</p><p>&nbsp;&nbsp;&nbsp; "Effect": "Deny",</p><p>&nbsp;&nbsp;&nbsp; "Action": "*",</p><p>&nbsp;&nbsp;&nbsp; "Resource": "*",</p><p>&nbsp;&nbsp;&nbsp; "Condition": {"NotIpAddress": {"aws:SourceIp": [</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "192.0.2.0/24",</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "203.0.113.0/24"</p><p>&nbsp;&nbsp;&nbsp; ]}}</p><p>&nbsp; }</p><p>}</p><p><br></p><p>Options A, B, and C all provide additional layer of protection to the EC2 instances. Hence, D is the best answer.</p><p><br></p><p>For more information on tagging please see the below link:</p><p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html" target="_blank">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html</a><br></p>	Ensure that the proper tagging strategies have been implemented to identify all of your EC2 resources. <br>  すべてのEC2リソースを識別するための適切なタグ付け戦略が実装されていることを確認してください。	Add an IP address condition to policies that specify that requests to EC2 instances should come from a specific IP address or CIDR block range. <br>  EC2インスタンスへの要求が特定のIPアドレスまたはCIDRブロック範囲から来るべきであることを指定するポリシーにIPアドレス条件を追加します。	Add policies which have deny and/or allow permissions on tagged resources. <br>  タグ付きリソースに対するアクセス権を拒否または許可するポリシーを追加します。
Test4-79. <p>Which of the following are correct statements with policy evaluation logic in AWS Identity and Access Management?</p><p>Choose 2 answers from the below options:<br></p> | <p> AWS Identity and Access Managementでポリシー評価ロジックを持つ正しいステートメントはどれですか？</p> <p>以下のオプションから2つの回答を選択します：<br> </p>	ma:	x:An explicit deny does not override an explicit allow. <br>  明示的拒否は明示的許可を無効にしません。|<p><br></p><p>Option A is incorrect because explicit deny always override an explicit allow.</p><p>Option B is incorrect because all requests are denied by default.</p><p>Option C is CORRECT because an explicit allow overrides the default deny.</p><p>Option D is incorrect because explicit deny cannot be overridden by an explicit allow.</p><p>Option E is CORRECT because all requests are denied by default.</p><p><br></p><p>The below diagram shows the evaluation logic of IAM policies. And as per the evaluation logic, it is clear that the above scenario leads to a default deny.</p><p>&nbsp;<img src="https://s3.amazonaws.com/awssap/4_79_1.png" alt="" role="presentation" class="img-responsive atto_image_button_text-bottom" height="551" width="571"></p><p><br></p><p>For more information on the IAM policy evaluation logic, please refer to the link</p><p></p><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_evaluation-logic.html" target="_blank" style="font-size: 1rem;">http://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_evaluation-logic.html</a><br><br><p></p>	x:By default, all request are allowed. <br>  デフォルトでは、すべての要求が許可されます。	o:An explicit allow overrides default deny. <br>  明示的な許可は、デフォルトの拒否を無効にします。	x:An explicit allow overrides an explicit deny. <br>  明示的な許可は、明示的な否認を無効にします。	o:By default, all requests are denied. <br>  デフォルトでは、すべての要求が拒否されます。
Test4-80. <p>A company has developed a sensor intended to be placed inside of people's watches, monitoring the number of steps taken every day. There is an expectation of thousands of sensors reporting in every minute and hopes to scale to millions by the end of the year. A requirement for the project is it needs to be able to accept the data, run it through ETL to store in warehouse and archive it on Amazon Glacier, with room for a real-time dashboard for the sensor data to be added at a later date. What is the best method for architecting this application given the requirements? <br></p><p>Choose the correct answer from the below options:<br></p> | <p>企業では、人の腕時計の中に置くことを意図したセンサを開発し、毎日の歩数を監視しています。何千ものセンサーが1分ごとに報告を行い、年末までに何百万にも拡大することを期待しています。プロジェクトの要件は、データを受け入れ、倉庫に保管し、Amazon Glacierに保管するためにETLを使用して実行する必要があり、後でセンサデータを追加するためのリアルタイムダッシュボードが必要なことです。要件を考慮して、このアプリケーションを設計するための最良の方法は何ですか？<br> </p> <p>以下のオプションから正解を選択します：<br> </p>	sa:	Write the sensor data directly to Amazon Kinesis and output the data into Amazon S3 creating a lifecycle policy for Glacier archiving. Also, have a parallel processing application that runs the data through EMR and sends to a Redshift data warehouse. <br>  センサデータをAmazon Kinesisに直接書き込んで、データをAmazon S3に出力し、氷河のアーカイブのライフサイクルポリシーを作成します。また、EMRを介してデータを実行し、Redshiftデータウェアハウスに送信する並列処理アプリケーションを用意してください。|<p><br></p><p>Option A is incorrect because S3 is not ideal for handling huge amount of real time requests.</p><p>Option B is incorrect because Amazon Cognito is not suitable for handling real time data.</p><p>Option C is incorrect because DynamoDB is not suitable for data ingestion and handling.</p><p>Option D is CORRECT because the requirement is real time data ingestion and analytics. The best option is to use Kinesis for storing the real time incoming data. The data can then be moved to S3 and then analyzed using EMR and Redshift. Data can then be moved to Glacier for archival.</p><p><br></p><p><b>More information about the use of Amazon Kinesis:</b></p><p>Amazon Kinesis is a platform for streaming data on AWS, making it easy to load and analyze streaming data, and also providing the ability for you to build custom streaming data applications for specialized needs.</p><p></p><ul><li>Use Amazon Kinesis Streams to collect and process large streams of data records in real time.</li><li>Use Amazon Kinesis Firehose to deliver real-time streaming data to destinations such as Amazon S3 and Amazon Redshift.</li><li>Use Amazon Kinesis Analytics to process and analyze streaming data with standard SQL.</li></ul><p></p><p><br></p><p><span style="font-size: 1rem;"><b>More information about the use of Amazon Cognito:</b></span></p><p>Amazon Cognito lets you easily add user sign-up and sign-in and manage permissions for your mobile and web apps. You can create your own user directory within Amazon Cognito, or you can authenticate users through social identity providers such as Facebook, Twitter, or Amazon; with SAML identity solutions; or by using your own identity system. In addition, Amazon Cognito enables you to save data locally on users' devices, allowing your applications to work even when the devices are offline. You can then synchronize data across users' devices so that their app experience remains consistent regardless of the device they use.</p><p><br></p>	Use Amazon Cognito to accept the data when the user pairs the sensor to the phone, and then have Cognito send the data to Dynamodb. Use Data Pipeline to create a job that takes the DynamoDB table and sends it to an EMR cluster for ETL, then outputs to Redshift and S3 while, using S3 lifecycle policies to archive on Glacier. <br>  Amazon Cognitoを使用して、ユーザーがセンサを電話にペアリングした後でデータを受け取り、CognitoがデータをDynamodbに送信するようにします。データパイプラインを使用してDynamoDBテーブルを取得し、ETLのEMRクラスタに送信し、RedshiftとS3に出力し、S3ライフサイクルポリシーを使用してGlacierにアーカイブするジョブを作成します。	Write the sensor data directly to a saleable DynamoDB; create a data pipeline that starts an EMR cluster using data from DynamoDB and sends the data to S3 and Redshift. <br>  販売可能なDynamoDBにセンサデータを直接書き込みます。DynamoDBからのデータを使用してEMRクラスタを開始し、S3およびRedshiftにデータを送信するデータパイプラインを作成します。	Write the sensor data to Amazon S3 with a lifecycle policy for Glacier, create an EMR cluster that uses the bucket data and runs it through ETL. It then outputs that data into Redshift data warehouse. <br>  Glacierのライフサイクルポリシーを使用してAmazon S3にセンサーデータを書き込み、バケットデータを使用するEMRクラスターを作成してETLで実行します。そのデータをRedshiftデータウェアハウスに出力します。